[
  {
    "title": "User Guide",
    "description": "Rulebricks is a decision automation platform that helps you model important decisions in your business visually as",
    "path": "/",
    "content": "IconCube,\n  IconHammer,\n  IconCode,\n  IconPlug,\n  IconRoute2,\n  IconServer,\n} from '@tabler/icons-react'\n\n# User Guide\n\n  Learn how our visual decision modeling approach can help your business make\n  complex, embedded logic surprisingly accessible.\n\n  }\n    title=\"What is a rule?\"\n    description=\"The building blocks of decision automation.\"\n    href=\"/getting-started/what-is-a-rule\"\n  />\n  }\n    title=\"Start building\"\n    description=\"Create your first rule in under 5 minutes.\"\n    href=\"/getting-started/start-building\"\n  />\n  }\n    title=\"API/SDK Reference\"\n    description=\"Complete API docs and SDK examples.\"\n    href=\"/api-reference\"\n  />\n  }\n    title=\"Integration guide\"\n    description=\"How to use the rules you've built.\"\n    href=\"/getting-started/integration\"\n  />\n  }\n    title=\"Rulebricks Flows\"\n    description=\"Chain rules together for complex workflows.\"\n    href=\"/integrating-rules/rule-flows\"\n  />\n  }\n    title=\"Private deployments\"\n    description=\"Self-host with full control.\"\n    href=\"/private-deployment/quick-start\"\n  />"
  },
  {
    "title": "Condition Priorities",
    "description": "Condition priorities allow you to specify arbitrary subgroup",
    "path": "/advanced-features/condition-priorities",
    "content": "# Condition Priorities\n\nBy default in Rulebricks, conditions are evaluated in the order they are defined in the decision table, from top to bottom, and the first condition row where every comparison is satisfied is the one that is used to calculate the result of the rule.\n\nBut in some more complex scenarios, you may want a single decision table, but certain subgroups of conditions to take precedence over others. This is where condition priorities come in.\n\nPriorities allow you to specify arbitrary subgroup \"flights\" of conditions that should be evaluated before others. This is useful when you have a set of conditions that should be evaluated first, and only if none of those conditions are met, should the other conditions be evaluated, and so on.\n\n## Setting priorities\n\nTo set condition priorities, open the Row Settings menu for the condition row you want to set a priority for, and set a priority number. Higher numbers are evaluated first, and lower numbers are evaluated later. If two rows have the same priority, they are evaluated in the order they appear in the decision table, but in isolation, as if all rows with lower priority numbers do not exist, and so on.\n\n![Settings Menu](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/advanced-features/row-priority.png)\n\nRow priorities cannot be configured if a row is already a member of a group. If you want to set a priority for a row that is already a member of a group, you must first ungroup the row, set the priority, and then regroup the row. Alternatively, you can set the priority for the group itself, which will apply to all rows in the group.\n\nAfter you've set priorities for your rows, you can see the priority number in the row itself, in the indicators on the left.\n\n![Priority Indicator](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/advanced-features/status-symbols.png)\n\nYou might note a new symbol in the row indicator in the above image– a little clock icon. This indicates if a particular condition is in or out of schedule, which we'll cover in the next section."
  },
  {
    "title": "Groups & Hit Policies",
    "description": "Groups in Rulebricks allow you to organize conditions in a decision table in a way that makes sense for your use case. Learn how to create groups and configure hit policies here.",
    "path": "/advanced-features/groups-and-hit-policies",
    "content": "# Groups & Hit Policies\n\nIn Rulebricks, conditions in a decision table can be grouped in various ways. Often, this grouping functionality provides an elegant solution to situations where your decision tables would otherwise become large and unwieldy.\n\nLet's take a look at how groups work in Rulebricks, and how you can use them to organize your decision tables.\n\n---\n\n---\n\nYou can visually identify groups in your decision table by the group indicator, which is a small colored circle that appears to the left of the group's conditions. Different groups are assigned random unique colors.\n\n![Group Indicator](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/advanced-features/group-dots.png)"
  },
  {
    "title": "Scheduled Conditions",
    "description": "Scheduled conditions in Rulebricks allow you to change how you make a particular decision based on the current time of week & time of day. Learn how to set up scheduled conditions here.",
    "path": "/advanced-features/scheduled-conditions",
    "content": "# Scheduled Conditions\n\nDecision tables are a powerful way to make decisions based on data, but what if you need to change how you make a particular decision based on the current time of week & time of day? Scheduled conditions are your answer, and are remarkably easy to set up.\n\n## Configuring a schedule\n\nFirst, open a condition row's settings menu by clicking the gear icon in the left margin of the row. You should see a menu that allows you to configure the row's schedule.\n\n![Settings Menu](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/advanced-features/row-settings.png)\n\nCheck any days of the week you want the condition to be active, and set a start and end time in UTC for the condition.\n\n![Schedule Settings](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/advanced-features/enabling-row-schedule.png)\n\nIf you'd like to disable the schedule for a row, simply uncheck all days of the week.\n\n## Viewing if a condition is in schedule\n\nAfter you've set a schedule for a condition, you can see if it's currently in schedule simply by looking at the row indicator in the left margin of the row. If the row is in schedule, you'll see a green clock icon, and if it's out of schedule, you'll see a red one. Again, **schedule times are in UTC**, so be sure to adjust accordingly for your local time zone, or you may end up confused about why a scheduled condition isn't working as expected.\n\n![Schedule Indicator](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/advanced-features/status-symbols.png)\n\nIn this example, the first condition is out of schedule, and would currently be disregarded if I were to run that Rule, and the last condition is in schedule."
  },
  {
    "title": "Dynamic Values",
    "description": "Store reusable values and write custom JavaScript functions to use across your rules.",
    "path": "/advanced-features/values-and-functions",
    "content": "# Dynamic Values\n\nYour tax rate appears in twelve rules. When it changes from 8% to 8.5%, do you want to update twelve rules—or one value?\n\nDynamic Values solve this problem for you by storing numbers, strings, and other data types centrally. Reference them in any rule, and update them in one place.\n\nChanges to values propagate instantly, and using values doesn't detract from how performant your rules are because values are deeply integrated into our caching infrastructure.\n\n## Ad-hoc values\n\n## Bulk importing\n\nYou'll often want to bring in a large number of values at once to start using vocabulary from your business right away. Rulebricks offers you three ways to do this quickly.\n\nFirst, our values UI allows you to simply import large, potentially nested JSON dictionaries that simply contain key value pairs.\n\nUse the \"From JSON\" tab to continue with this option.\n\n![Bulk Import Values](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/values-and-functions/bulk-import-values.png)\n\nSecond, an API endpoint is also available to create and update dynamic values. Start by looking at our [Dynamic Values API](https://rulebricks.com/docs/api-reference#tag/values).\n\nFinally, if you have JSON Schema on hand, or even a DDL or other similar schema artifact, you can upload your schema as an Object (or use smart import if you're bringing a DDL/non-standard format).\nRulebricks will automatically scan your schema for enums/ranges, and create values based on them in your workspace.\n\n## Functions\n\nFunctions let you write JavaScript that computes results dynamically, calculating results based on input and other output values.\n\nFunctions can be authored here as arrow expressions. Some libraries are available to assist with complex operations.\n\n[Code: ((quantity, price) => (quantity > 100 ? price * 0.9 : price))\n]"
  },
  {
    "title": "Analysis Tools",
    "description": "Rulebricks provides analysis tools to help you understand how your rules perform in production and how changes might affect outcomes.",
    "path": "/analysis-tools",
    "content": "# Analysis Tools\n\nRulebricks provides two powerful analysis tools in the rule editor to help you understand how your rules perform in production and how changes might affect outcomes.\n\n## Available Tools\n\n### Impact Analysis\n\nTest how changes to your rule conditions would affect outputs **before deploying**. Impact analysis replays historical requests through modified conditions to show you exactly what would change.\n\n![Impact Analysis](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/rule-analysis-tools/impact-analysis.png)\n\n**Use it when:**\n\n- You're considering changing a condition value\n- You want to compare the current rule version against a previous one\n- You need to understand the downstream effects of a rule change\n\n[Learn more about Impact Analysis →](/analysis-tools/impact-analysis)\n\n### Reachability Analysis\n\nSee which rows in your decision table are actually being matched by production traffic. Reachability analysis shows you hit frequencies and helps identify dead code or optimization opportunities.\n\n![Reachability Analysis](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/rule-analysis-tools/reachability-analysis.png)\n\n**Use it when:**\n\n- You suspect some rows are never being matched\n- You want to optimize rule evaluation order\n- You need to understand which conditions are causing the most rejections\n\n[Learn more about Reachability Analysis →](/analysis-tools/reachability-analysis)\n\n## Accessing the Tools\n\nBoth tools are available in the **footer bar** of the rule editor and are available on any paid plan. Click **Impact** or **Reachability** to open the respective analysis panel.\n\nFor static analysis of rule structure (without production data), see [Rule Warnings](/warnings)—which examines your rule for potential issues like unreachable rows and coverage gaps."
  },
  {
    "title": "Impact Analysis",
    "description": "See exactly how rule changes would affect your outputs before deploying. Impact Analysis replays historical requests through modified conditions.",
    "path": "/analysis-tools/impact-analysis",
    "content": "# Impact Analysis\n\nYou're about to change your credit score threshold from 700 to 650. How many more applications will get approved? Will your denial reasons shift?\n\nImpact Analysis gives you crystal clear answers to these questions before you deploy anything.\n\n![Impact Analysis](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/rule-analysis-tools/impact-analysis.png)\n\nThe tool replays a configurable sample of real production requests through your modified rule logic and shows you exactly what would change—approval rates, output distributions, everything.\n\n## Analysis Methods\n\nTwo analysis methods are made available, depending on how your organization is using rules in production, and the extent of changes you're trying to simulate.\n\n</Tabs.Tab>\n\n</Tabs.Tab>\n</Tabs>\n\n## Reading the Results\n\nResults show distribution charts for each output field. The visualization adapts to the data type:\n\n</Tabs>\n\nWatch for **null shifts**—when values suddenly become null, it often means requests stopped matching any row. Impact Analysis will surface this in an alert if it detects it.\n\n## Example: Threshold Optimization\n\nSay you want to approve more loan applications by lowering the credit score requirement from 700 to 650.\n\n1. Click the credit score condition cell\n2. Change it to 650\n3. Run analysis against the last 500 requests\n\nThe results might show:\n\n- Approval rate jumps from 62% to 78%\n- Average approved amount drops slightly (riskier applicants qualify for less)\n- Denial reason distribution shifts from \"low credit\" to \"high debt ratio\"\n\nNow you know exactly what you're signing up for before you ship the change."
  },
  {
    "title": "Reachability Analysis",
    "description": "See which rows in your decision table are actually being matched by production traffic. Find dead code and optimization opportunities.",
    "path": "/analysis-tools/reachability-analysis",
    "content": "# Reachability Analysis\n\nYour rule has 47 rows. Which ones actually matter?\n\nReachability Analysis shows you exactly which rows are being hit by real traffic—and which ones might be dead weight. It analyzes your execution logs to surface usage patterns you wouldn't otherwise see.\n\n![Reachability Analysis](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/rule-analysis-tools/reachability-analysis.png)\n\n## What It Shows\n\n</Tabs>\n\nThe panel header shows summary stats: how many requests matched at least one row, how many matched nothing, and how many rows have zero hits.\n\n## Finding Dead Rows\n\nA row with 0% hits over 30 days is probably:\n\n- **Unreachable** — an earlier catch-all row blocks it\n- **Obsolete** — handles an edge case that never actually occurs\n- **Safe to remove** — cleaning up your rule table\n\nBefore deleting, make sure to thoroughly investigate _why_ it's not being hit. Some rows handle rare but critical cases— you don't want to remove your fraud detection row just because it only fires twice a month.\n\n## Performance Optimization\n\nIf one row handles 80% of your traffic but sits at the bottom of your table, moving it up can meaningfully improve evaluation speed at scale. Rulebricks evaluates top-to-bottom, so putting your high-traffic rows near the top reduces unnecessary condition checks.\n\nUse [Impact Analysis](/analysis-tools/impact-analysis) afterward to verify that reordering didn't change your rule's behavior.\n\n## Large Reports\n\nComputation is handled on our servers– but we encourage users to be prudent about the sample sizes they use as particularly large requests may take several minutes to complete and potentially timeout.\n\nWe perform cardinality analysis on your rule internally to optimize reachability reports for massive amounts of data/rows."
  },
  {
    "title": "Creating a Form",
    "description": "Creating a form in Rulebricks is a great way to embed information specific to your business and help users calculate something based on their inputs. Learn how to create a form here.",
    "path": "/building-forms/creating-a-form",
    "content": "# Creating a Form\n\nAs it turns out, rules in Rulebricks also can be used to create forms & quizzes for your business and/or clients remarkably easily.\n\nThis is a particularly good way to **embed information specific to your business** and **help users calculate something** based on their inputs, like a particular pricing quote or eligibility status.\n\nAny form built in Rulebricks can easily be embedded on your website, with your company colors/branding, so it will look right at home when you send it along.\n\n## Video Overview\n\nBelow is a brief video overview of what forms in Rulebricks look like.\n\n  <iframe\n    src=\"https://www.loom.com/embed/043c046f88b14f8f935053e6da797339?sid=27fbf55f-f427-484c-a928-2e7d1e9a6dfa\"\n    frameBorder=\"0\"\n    allowFullScreen\n    className=\"overview-video\"\n    style=}\n  ></iframe>\n\n## Form Guide\n\nLet's walk through creating a form in Rulebricks.\n\n---\n\nYour form is already live and ready to be shared with your users, but you'll probably want to edit the form to make the inputs easier for folks to understand first. In the next section, we'll walk through how to do just that."
  },
  {
    "title": "Editing Form Fields",
    "description": "Editing form fields in Rulebricks is a powerful way to customize the form fields and results fields in your rules. Learn how to do it here.",
    "path": "/building-forms/editing-fields",
    "content": "# Editing Form Fields\n\nIf you're following along, you might've noticed by now that each attribute of your request object is automatically turned into a form field when you click the \"Form\" button in the Rulebricks editor, and each attribute in your response object is automatically turned into a result field, i.e. a field that will be displayed to the user after they submit the form.\n\nThis is a powerful feature that allows you to quickly create forms that collect the data you need, and display the results you want, without having to write any code.\n\nBut how do you customize these form fields? What if you want to change the type of a field, or add a description, or make a field required?\n\nSometimes, this behavior can be really important, for example if you want to collect text from a user, but you want to make sure they enter one of a few specific options, like \"A\" or \"B\". In this case, you might want to change the field type from \"Short Text\" to \"Multiple Choice\", and add the options \"A\" and \"B\".\n\n## Edit Fields\n\nLet's walk through how to do this.\n\n### Edit the field\n\nTo change the field type, click on the dropdown and select the field type you want. You can also add a description, make the field required, or add options for certain field types.\n\nIn this brief example, we're changing the field type from \"Short Text\" to \"Multiple Choice\", and adding a few options.\n\n![Change Field Type](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/building-forms/add-choices.png)\n\n### Return to your form\n\nNow, click the \"Form\" tab to return to the form editor, and you should see your changes reflected in the form. In this particular case, what used to be an open-ended text field is now a multiple choice field with specific options I compare against in my rule.\n\n![Returned to Form](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/building-forms/returned-to-form.png)\n\n</Steps>\n\n## Edit Results\n\nYou can also edit the results fields in the same way, but instead of changing how inputs appear to the user, you're changing how results appear to the user after they submit the form.\n\nThese are useful for displaying the results of your rule in a way that makes visual sense to the user, and are purely for display purposes."
  },
  {
    "title": "Sharing Forms",
    "description": "Sharing forms in Rulebricks is easy, and there are a few ways you can do it. Learn how to share your forms here.",
    "path": "/building-forms/sharing-forms",
    "content": "# Sharing Forms\n\nCongrats– you've created a form! Now it's time to share it with the world. There're a few ways you can do this, and a few things you need to keep in mind, so we'll walk through them here.\n\n## Your form is live\n\nWhen you create a form in Rulebricks, it's automatically public. This means that anyone with the link can access and submit the form. This is great for sharing your form with others, but it also means you need to be careful about who you share the link with.\n\nEach time someone submits your form, the data is sent to your rule, and the result is displayed to the user. This uses up one of your monthly rule executions/runs, so be mindful of this as you share your form. Of course, you can always upgrade your plan if you need more rule executions/runs.\n\n## Sharing your form\n\nTo share your form, you can simply copy the URL from the \"Sharing\" section of the sidebar in the form editor. This URL is unique to your form, and can be shared with anyone you'd like to fill out the form.\n\n![Form Sharing](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/building-forms/try-form.png)\n\n## Three options\n\nThere are three ways you can share/use your Rulebricks forms. Each of the menus below is available in the sidebar of the form editor, so simply scroll down to find them.\n\n  \n  \n</Tabs>"
  },
  {
    "title": "Contexts",
    "description": "Contexts hold your decision together while data arrives from different sources at different times. Progressive rule execution for async business processes.",
    "path": "/contexts",
    "content": "# Contexts\n\nA loan application arrives on Monday. The credit check comes back Wednesday. Employment verification finishes Friday. By the time you have everything you need to make a decision, where did Monday's data go?\n\n**Contexts hold your decision together while the pieces arrive.**\n\n![Contexts Tab](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/contexts/context-tab.png)\n\nInstead of building infrastructure to track what data you have, what's missing, and when to run your rules, Contexts handle it for you. Define the facts you need, submit them as they arrive from different sources, and your rules execute automatically when everything's ready.\n\n## A Useful Reframing\n\nYou should use rules directly when your business already has all the data you need upfront, and you've just been missing the rule piece until now. You should use Contexts when you don't have all the data right away, but you do know the rules that will apply to that data.\n\nContexts allow you to think about rules and decisions from the perspective of _updates to business entities_, which becomes somewhat apparent when you look at how to use the contexts API:\n\n[Code: // Credit score arrives from bureau webhook\nPOST /api/v1/contexts/loan-application/APP-12345\n\n// Response tells you what's still missing\n\n// When the last piece arrives, rules auto-execute\n\n}\n]\n\nAs opposed to:\n\n[Code: // Assumes we have all the data upfront\nPOST /api/v1/solve/approval-rule\n\n// Manual write-back/result storage\n// ...\n]\n\n## When to Use Contexts\n\n- Data arrives from multiple sources at unpredictable times (webhooks, user actions, third-party APIs)\n- You want rules to execute automatically when their inputs are ready\n- Your decision process spans hours, days, or weeks\n- You need to track what's been collected vs what's still missing"
  },
  {
    "title": "Linking Rules & Flows to Contexts",
    "description": "Connect rules to Contexts so they read from context facts and write their outputs back automatically.",
    "path": "/contexts/binding-rules",
    "content": "# Linking Rules & Flows to Contexts\n\nOnce your Context(s) are ready, you're ready to create rules & flows that are \"bound\" to them, priming them to automatically run when your live contexts start receiving data.\n\nOnce bound, the rule reads its inputs from context facts and writes its outputs back—no API calls required on your end. All flows that start from that rule are also considered bound and will fire automatically upon associated context updates.\n\nFlow write-back into contexts is accomplished slightly more explicitly via an \"Context Operations\" step you can find easily from the flow editor.\n\n## Create a Bound Rule\n\n## Cascading Rules\n\nWhen Rule A writes a fact that Rule B needs, B executes automatically after A:\n\n[Code: Facts arrive: credit_score, annual_income\n       ↓\n[Credit Check Rule] executes → writes: risk_tier\n       ↓\n[Pricing Rule] now has all inputs → executes → writes: rate, max_amount\n]\n\nThis happens within a single API response. The `cascaded` array shows what ran:\n\n[Code:  },\n     }\n  ]\n}\n]\n\n## Viewing Bound Rules\n\nFrom the Context dashboard, the **Assets** tab shows all currently bound rules & flows, their execution modes, and which facts they read/write."
  },
  {
    "title": "Getting Started with Contexts",
    "description": "Create your first Context in Rulebricks and see progressive rule execution in action.",
    "path": "/contexts/getting-started",
    "content": "# Getting Started with Contexts\n\nLet's build a Customer Context that tracks customer data across multiple sources and automatically runs your bound rules when the required information is available.\n\n## Using the API\n\nSubmit facts to a context instance via POST:\n\n[Code: curl -X POST \"https://rulebricks.com/api/v1/contexts/customer/c_001\" \\\n  -H \"x-api-key: YOUR_API_KEY\" \\\n  -d ''\n]\n\nThe response shows current state:\n\n[Code: \n]\n\nWhen all required facts are present and a bound rule exists, the response includes rule execution:\n\n[Code: \n    }\n  ]\n}\n]\n\n## Key Concepts\n\n- **[Facts and Schema](/contexts/key-concepts/facts-and-schema)** — Derived facts, history tracking, and schema design\n- **[Execution Mode](/contexts/key-concepts/progressive-execution)** — How auto-execution and cascades work\n- **[Binding Rules](/contexts/binding-rules)** — Connect rules to read from and write to contexts"
  },
  {
    "title": "Gradient",
    "description": "Gradient automatically discovers decision patterns from your Context data and generates rules for you.",
    "path": "/contexts/gradient",
    "content": "# Gradient\n\n_What if your rules could write themselves?_\n\nGradient is a new feature coming to Rulebricks that watches the data flowing through your Contexts and automatically surfaces the decision patterns hiding in it. That credit approval workflow your team runs manually? Gradient sees that 94% of applicants with scores above 720 and debt ratios below 30% get approved—and generates the rule for you.\n\n### From Data to Decisions\n\nYour Contexts already capture the facts that matter: what arrived, when, what was decided. Gradient analyzes this history to find what drives outcomes.\n\n**It discovers patterns like:**\n\n- Orders from gold-tier customers over $500 are always expedited\n- Applications missing employment verification stall 3x longer than others\n- Price adjustments above 15% require manager approval regardless of other factors\n\nThese become draft rules you can review, refine, and publish. The implicit knowledge in your business becomes explicit, auditable logic.\n\n### Finding procedural bottlenecks\n\nBeyond rule generation, Gradient identifies where decisions get stuck. Which facts are most often missing when applications stall? Where would a new integration have the highest ROI?\n\nThis turns operational friction into actionable insights—you see exactly which data gaps cost you the most."
  },
  {
    "title": "Facts and Schema",
    "description": "Understanding base facts, derived facts, and the identity fact in Rulebricks Contexts.",
    "path": "/contexts/key-concepts/facts-and-schema",
    "content": "# Facts and Schema\n\nA Context's schema defines what data it collects. There are three kinds of facts: base facts (the raw data you submit), derived facts (computed automatically), and one special identity fact (what uniquely identifies each instance).\n\n## Base Facts\n\nBase facts are the data points you collect—things like `credit_score`, `annual_income`, or `employment_verified`. They come from API calls, webhooks, user input, or anywhere else in your system.\n\nEach fact has a type (string, number, boolean, date, list, or object) and can be marked as:\n\n- **Required** — Must be present before rules can execute\n- **Output only** — Can only be written by rules, not submitted externally\n- **Track history** — Stores previous values for temporal queries\n\n## The Identity Fact\n\nOne fact must be the **identity fact**—the unique identifier for each context instance. For a loan application context, this might be `application_id`. For transaction processing, `transaction_id`.\n\nThe identity appears in your API URLs:\n\n[Code: POST /api/v1/contexts/loan-application/APP-12345\n                                       ↑ identity value\n]\n\n## Derived Facts\n\nDerived facts compute automatically from other facts using expressions:\n\n[Code: // Debt-to-income ratio\nmonthly_debt / (annual_income / 12)\n\n// Risk category based on score\nifelse(\n  credit_score >= 750,\n  'low',\n  ifelse(credit_score >= 650, 'medium', 'high')\n)\n\n// Aggregate from related contexts\nsum($relations.transaction, 'total')\n\n// Available functions are listed directly in app UI\n]\n\nThey update whenever their dependencies change—no manual recalculation needed.\n\n## Relationships\n\nContexts can relate to each other. A customer context can have many transaction contexts. An transaction context can belong to a customer. These relationships let you build decisions that span multiple entities.\n\n### The Pattern\n\n**Customer** (one) → **Transactions** (many)\n\nA customer context tracks lifetime data: total spend, transaction count, loyalty tier. Each transaction context tracks a single transaction. When an transaction completes, you might want to update the customer's lifetime stats.\n\n![Context Relations](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/contexts/context-relations.png)\n\n### Defining Relationships\n\nIn the Context Editor, add a relationship field:\n\n**On the Customer context:**\n\n[Code: transactions: has_many(Transaction, 'customer_id')\n]\n\n**On the Transaction context:**\n\n[Code: customer_id: string (foreign key)\n]\n\nNow transactions link to their customer, and customers can reference their transactions.\n\n### Using Relationships\n\nDerived facts are required for you to expose and use data from related Contexts.\n\nFor example, on a Customer context, I might use:\n\n[Code: // Total spend across all transactions\ntotal_spend: sum($relations.transaction, 'total')\n\n// Number of completed transactions\ntransaction_count: count($relations.transaction, 'status == \"complete\"')\n\n// Most recent transaction date\nlast_transaction_date: max($relations.transaction, 'created_at')\n]\n\nThese recalculate automatically when any related transaction changes.\n\n### Cascading Across Relationships\n\nWhen an transaction is marked complete, it can trigger rules on the customer context:\n\n1. Transaction context receives `status: \"complete\"`\n2. Customer's `transaction_count` derived fact recalculates\n3. If `transaction_count` crosses a threshold, a loyalty tier rule executes\n4. Customer's `loyalty_tier` fact updates\n\nThis cascade happens automatically based on the relationships and rule bindings you've defined.\n\n### Navigating the Other Direction\n\nFrom an transaction, access the parent customer:\n\n[Code: // Get customer's tier for transaction-level pricing\ncustomer_tier: $relations.customer.loyalty_tier\n]\n\nThis creates a dependency—the transaction context waits for the customer's `loyalty_tier` before derived facts using it can calculate.\n\n## Solvability\n\nA context instance is \"solvable\" when all required facts are present. The API always tells you where you stand:\n\n[Code: \n]\n\nWhen `need` is empty, `status` becomes `complete` and bound rules can execute."
  },
  {
    "title": "Live Contexts",
    "description": "Understanding context instances, their lifecycle, and the have/need pattern for tracking data collection progress.",
    "path": "/contexts/key-concepts/live-contexts",
    "content": "# Live Contexts\n\nWhen you submit data to a Context, you create a **live context**—an instance that accumulates facts over time until rules can execute.\n\n- **Context** = the schema definition (what facts you need for loan approval)\n- **Live context** = a specific instance (loan application APP-12345's data)\n\n## Lifecycle\n\nA live context is created when you first submit data for a new identity:\n\n[Code: POST /api/v1/contexts/loan-application/APP-12345\n\n]\n\nIt persists as you submit more facts over time. Each submission merges into the existing state—new fields are added, existing fields are updated, missing fields are left alone.\n\nWhen all required facts are present, the status changes from `pending` to `complete`, and bound rules can execute.\n\nEventually, live contexts expire based on their TTL (time-to-live) setting. Expired contexts are no longer accessible—POST requests to that identity create a fresh instance.\n\n## The Have/Need Pattern\n\nEvery API response tells you exactly where you stand:\n\n[Code: \n]\n\n- `have` — facts with values\n- `need` — required facts still missing\n- `status` — `pending` until `need` is empty, then `complete`\n\nThis makes it easy to show progress in your UI, decide what to fetch next, or debug why a rule isn't executing.\n\n## TTL and Expiration\n\nSet TTL when creating your context (1 hour to 30 days). The clock starts when the instance is created, not when it's last updated.\n\n## Fetching State\n\nGet the current state of any live context:\n\n[Code: GET /api/v1/contexts/loan-application/APP-12345\n]\n\nThe response includes all facts (base and derived), the have/need arrays, timestamps, and expiration time."
  },
  {
    "title": "Progressive Execution",
    "description": "Rules automatically execute when their inputs are ready. Understand auto-execution and cascading rule chains in Contexts.",
    "path": "/contexts/key-concepts/progressive-execution",
    "content": "# Progressive Execution\n\nThe magic of Contexts is that **decisions run automatically when their inputs are ready.**\n\nYou don't schedule rule execution or poll for completeness. Simply submit facts as they arrive, and the rules that can run will run.\n\n## How It Works\n\nWhen you bind a rule to a context, Rulebricks knows what inputs that rule needs. When you submit a fact:\n\n1. All derived facts that depend on it recalculate\n2. The system checks if any bound rules now have all their required inputs\n3. Rules that are ready execute automatically\n4. Their outputs write back to the context as new facts\n\nThis happens in a single API response—you submit `employment_verified: true`, and you get back the approval decision your rule computed.\n\n## Cascading Execution\n\nRules can write facts that other rules depend on. This creates automatic chains:\n\n[Code: Submit: credit_score = 720\n        ↓\n  [Risk Assessment Rule] executes\n        ↓\nWrites: risk_tier = \"low\"\n        ↓\n  [Pricing Rule] executes (was waiting for risk_tier)\n        ↓\nWrites: rate = 4.5, max_amount = 500000\n]\n\nThe response tells you what ran:\n\n[Code:  },\n     }\n  ]\n}\n]\n\n## Execution Modes\n\nThere are very specific situations where automatic decision evaluation on Contexts may be undesirable. While we make Automatic Execution a default, you can also turn it off, preferring to register pending rules/flows manually.\n\n| Mode        | When it runs                              |\n| ----------- | ----------------------------------------- |\n| **Enabled** | Automatically when all inputs are present |\n| **Manual**  | Only when you explicitly call `/solve`    |\n\n## Deterministic Order\n\nWhen multiple rules can execute, they run in dependency order—a rule that writes `risk_tier` always runs before a rule that reads it. If rules have no dependencies, execution order is stable but arbitrary.\n\nIf a rule fails, the cascade stops and the error is returned. Other facts already written in that request remain—partial progress is preserved."
  },
  {
    "title": "Webhooks",
    "description": "Get notified when contexts are solved or expire via webhook callbacks.",
    "path": "/contexts/webhooks",
    "content": "# Webhooks\n\nContexts can call your endpoints when something happens—a rule executes, a context expires, or an error occurs.\n\n## Events\n\n| Event             | When it fires                      |\n| ----------------- | ---------------------------------- |\n| `context.solved`  | A bound rule executed successfully |\n| `context.expired` | The context's TTL elapsed          |\n| `context.error`   | A rule execution failed            |\n\n## Configuration\n\nIn the Context Editor, add a webhook URL and select which events to send.\n\nRulebricks signs each request with your webhook secret (available in settings). Verify the `X-Rulebricks-Signature` header to ensure requests are authentic.\n\n## Payload Structure\n\n**context.solved:**\n\n[Code: ,\n  \"timestamp\": \"2024-01-15T10:30:00Z\"\n}\n]\n\n**context.expired:**\n\n[Code: ,\n  \"timestamp\": \"2024-01-22T10:30:00Z\"\n}\n]"
  },
  {
    "title": "Why Rulebricks Embedded?",
    "description": "Rulebricks Embedded is for engineering teams who need to deliver **enterprise-grade rule configuration** to their users _now_, without diverting their roadmap for six months to build a rule engine fro",
    "path": "/embedding-rulebricks/about-embedded",
    "content": "# Why Rulebricks Embedded?\n\nRulebricks Embedded is for engineering teams who need to deliver **enterprise-grade rule configuration** to their users _now_, without diverting their roadmap for six months to build a rule engine from scratch.\n\n---\n\nWhen your product needs advanced user-configurable logic—like dynamic pricing, eligibility criteria, or routing rules— many engineering teams face a difficult choice:\n\n1.  **Build it yourself**: You spend a month building a decision table UI/backend. You soon discover that features like undo/redo stacks, copy/paste support, change tracking, caching, and performant execution against large datasets are massive engineering sinks.\n2.  **Use a traditional BRMS**: You get a powerful engine, but you compromise your client experience. Your users are redirected to a third-party dashboard that doesn't look or feel like your product, despite your white-labeling.\n\nRulebricks Embedded eliminates this compromise. Paired with our SDK, it offers you a unique native-component that allows you to **buy an engine, but build the experience.**\n\n## Built with React, Compatible with Everything\n\nWhile we ship primarily as a React component, Rulebricks Embedded is designed to work within any modern frontend stack. The component is self-contained and can be mounted into:\n\n- **Angular & Vue**: Using standard wrapper patterns or mounting helpers.\n- **Next.js / Remix**: Full support for Server Components and SSR.\n- **.NET / Blazor**: Embeddable within Razor pages or Blazor components via JS interop.\n- **Internal Tools**: Easily mountable in Retool (custom component) or plain HTML/JS dashboards."
  },
  {
    "title": "API Reference & Customization",
    "description": "This reference covers the `` component props, the server-side helper, customization options, and troubleshooting.",
    "path": "/embedding-rulebricks/api-reference-and-customization",
    "content": "# API Reference & Customization\n\nThis reference covers the `<Rule>` component props, the server-side helper, customization options, and troubleshooting.\n\n## Component API\n\n### ``\n\nThe main React component for the embedded editor.\n\n[Code: \n]\n\n| Prop              | Type      | Default      | Description                                      |\n| :---------------- | :-------- | :----------- | :----------------------------------------------- |\n| `embedToken`      | `string`  | **Required** | The JWT generated by your backend.               |\n| `height`          | `number`  | `600`        | Height of the editor in pixels.                  |\n| `apiBaseUrl`      | `string`  | (Origin)     | Base URL for API calls (use for self-hosted).    |\n| `showControls`    | `boolean` | `true`       | Show/hide the top toolbar (Undo, Redo, Publish). |\n| `showFooter`      | `boolean` | `true`       | Show/hide the status bar (row count, search).    |\n| `showRowSettings` | `boolean` | `false`      | Show gear icon for row-level settings.           |\n| `requestLabel`    | `string`  | \"Request\"    | Custom label for the input columns section.      |\n| `responseLabel`   | `string`  | \"Response\"   | Custom label for the output columns section.     |\n| `onPublish`       | `func`    | -            | Callback fired after publishing `(e) => {}`.     |\n| `onError`         | `func`    | -            | Callback fired on errors `(e) => {}`.            |\n\n### `createEmbedToken(options)`\n\nServer-side helper to generate tokens.\n\n[Code: \n\nconst  = await createEmbedToken()\n]\n\n## Programmatic Control (Refs)\n\nYou can interact with the component instance using a React Ref. This is useful for building external \"Test\" buttons or custom export flows.\n\n[Code: const ruleRef = useRef(null)\n// ...\n;\n]\n\n### Methods\n\n- **`testRule(payload)`**: Runs a test against the current rule state. Highlights matching rows in the UI.\n  [Code:   const result = await ruleRef.current.testRule()\n  console.log(result.response) // The rule output\n  console.log(result.successIdxs) // Indices of matching rows\n  ]\n- **`clearTestResults()`**: Clears the visual highlighting from a previous test.\n- **`getRule()`**: Returns the current JSON structure of the rule.\n- **`isTestLoading()`**: Returns `true` if a test is currently executing.\n\n## Branding & Customization\n\nThe embed **automatically inherits** branding from your Rulebricks organization settings (Colors, Fonts, Border Radius). No client-side config is needed for this.\n\n### Manual Overrides (CSS)\n\nIf you need to override styles manually or create a dark mode workaround, target the `data-embed-container` attribute to ensure scoped styling.\n\n[Code: /* Override primary color */\n[data-embed-container='true'] \n\n/* Dark mode override example */\n[data-embed-container='true'] .bg-white \n]\n\n## Troubleshooting\n\n| Error                         | Possible Cause                           | Solution                                        |\n| :---------------------------- | :--------------------------------------- | :---------------------------------------------- |\n| **\"No embed token provided\"** | `embedToken` prop is null/undefined.     | Ensure your fetch completes before rendering.   |\n| **HTTP 401 / Invalid Token**  | Token expired or API Key revoked.        | Generate a fresh token; check API key validity. |\n| **HTTP 403 / Access Denied**  | User/Key lacks permission for this rule. | Check Rulebricks permissions for that API key.  |\n| **Styles missing/broken**     | CSS file not imported.                   | Add `import \"@rulebricks/embedded/styles.css\"`. |\n| **Hydration Error (Next.js)** | SSR mismatch.                            | Use `next/dynamic` with ``.       |\n\n### Debugging\n\nPass an `onError` handler to the component to catch and log issues:\n\n[Code: <Rule onError= ... />\n]"
  },
  {
    "title": "Core Concepts & Security",
    "description": "Understanding the architecture, permission model, and security best practices is crucial for a production deployment of Rulebricks Embedded.",
    "path": "/embedding-rulebricks/core-concepts-and-security",
    "content": "# Core Concepts & Security\n\nUnderstanding the architecture, permission model, and security best practices is crucial for a production deployment of Rulebricks Embedded.\n\n## Architecture & Token Flow\n\nRulebricks Embedded uses a **token-based architecture** to ensure your API keys never reach the client.\n\n1.  **Client**: Your app requests access to a rule (e.g., when a user opens the editor).\n2.  **Server**: Your backend authenticates the user and uses your **Rulebricks API Key** to generate a short-lived, scoped `embedToken`.\n3.  **Rulebricks API**: Validates your key and the user's access, then returns a signed JWT.\n4.  **Client**: The `<Rule>` component initializes with this token. All subsequent reads/writes use this token.\n\n[Code: sequenceDiagram\n    participant User as Client App\n    participant Server as Your Backend\n    participant RB as Rulebricks API\n\n    User->>Server: Request Embed Token\n    Server->>RB: POST /embed/token (with API Key)\n    RB-->>Server: Return JWT Token\n    Server-->>User: Return JWT Token\n    User->>RB:  (Direct API calls)\n]\n\n## API Keys & Permissions\n\nPermissions in the embed are **inherited** from the API key used to generate the token.\n\n### Hierarchy\n\n- **Organization Admin Key**: Full access to all rules.\n- **User Key**: Access only to rules owned by or shared with that specific user.\n\n### Roles & Capabilities\n\nThe embed automatically adapts its UI based on the permissions granted:\n\n| Permission      | Effect in Embed                                                                                   |\n| :-------------- | :------------------------------------------------------------------------------------------------ |\n| **Read-Only**   | User can view rules but cannot edit cells or add rows. Controls are hidden.                       |\n| **Editor**      | User can modify values and structure but cannot publish to production.                            |\n| **Publisher**   | User can edit and has access to the \"Publish\" button.                                             |\n| **Schema View** | Controls whether users see technical field names (`customer_id`) or descriptions (`Customer ID`). |\n\n**Example**: To give a customer read-only access to their specific rule:\n\n1.  Use an API key associated with a read-only role (or the specific customer's key).\n2.  Generate a token for that rule ID.\n3.  The embed will render in \"Read-Only\" mode automatically.\n\n## Security Best Practices\n\n### 1. Never Expose API Keys\n\n**Never** use your Rulebricks API key in client-side code. Always generate tokens on your server.\n\n❌ **Bad:**\n\n[Code: // Client-side\nfetch('https://rulebricks.com/api/embed/token', , // EXPOSED!\n})\n]\n\n✅ **Good:**\n\n[Code: // Server-side\ncreateEmbedToken()\n]\n\n### 2. Token Expiration\n\nSet an appropriate expiration time (`expiresIn`). The default is 1 hour (3600s).\n\n- **Short (15m)**: High security, requires refresh logic.\n- **Long (8h)**: Better UX for internal tools.\n\n### 3. Content Security Policy (CSP)\n\nIf your app uses CSP, allow connections to Rulebricks:\n\n[Code: <meta\n  http-equiv=\"Content-Security-Policy\"\n  content=\"connect-src 'self' https://rulebricks.com;\"\n/>\n]"
  },
  {
    "title": "Installation & Setup",
    "description": "Install the package using your preferred package manager:",
    "path": "/embedding-rulebricks/installation-and-setup",
    "content": "# Installation & Setup\n\nInstall the package using your preferred package manager:\n\n[Code: npm install @rulebricks/embedded\n# or\nyarn add @rulebricks/embedded\n# or\npnpm add @rulebricks/embedded\n]\n\n> **Note**: Requires React 18+.\n\n## Quick Start\n\nGetting up and running involves two steps: generating a secure token on your backend, and rendering the component on your frontend.\n\n### 1. Server-Side: Generate an Embed Token\n\nYou must generate an access token on your server to keep your API key secure.\n\n[Code: // Node.js / Next.js API Route\n\nexport async function POST(request)  = await createEmbedToken()\n\n  return Response.json()\n}\n]\n\n### 2. Client-Side: Render the Component\n\nFetch the token and pass it to the `<Rule>` component. Don't forget the CSS import!\n\n[Code: \n\nexport default function RuleEditor() )\n      .then((res) => res.json())\n      .then((data) => setToken(data.token))\n  }, [])\n\n  if (!token) return Loading...\n\n  return (\n    <Rule\n      embedToken=\n      height=\n      onPublish=\n      onError=\n    />\n  )\n}\n]"
  },
  {
    "title": "Using your Rules",
    "description": "Integrating Rulebricks into your workflows is easy, and there are a few ways you can do it. Learn how to integrate Rulebricks here.",
    "path": "/getting-started/integration",
    "content": "# Using your Rules\n\nOnce you’ve finished configuring and testing your rule, it's time to publish your rule, and integrate it into your work.\n\nYou'll need to decide, given the technologies your business already uses, what the best way to connect it to your existing systems looks like.\n\nWe offer many ways to use your rules across different levels of technical expertise– you do not need to learn or employ all of them, merely pick out the one that works best in your situation.\n\n## For Business Users\n\nA great place to start as a less technically-involved Rulebricks user is to think about when you want your rule to actually run/be triggered. This will give you a bunch of relevant information to what's best for you at once– what data will be available, who is actually providing that data/where it's coming from, etcetera.\n\n### Via Forms\n\nIf you want to use your rule to calculate something every once in a while, or help your users do so, forms are perfect for you. You don't actually have to build a form once you have your rule created– we generate the form for you using the logic in your rule! These forms can be embedded on your site and present your company's branding.\n\n[Learn more about using forms →](/building-forms/creating-a-form)\n\n### Via Zapier\n\nThis probably mainly works if you have heard of or are already familiar with Zapier, but we have a pretty powerful \"Make Decision\" action on Zapier that allows you to use Rules in lieu of Paths/Filters to perform complex comparisons/outcome determinations.\n\n![Untitled](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/Go%20live%20and%20integrate%20your%20rule/Untitled.png)\n\nThe action will guide you fully through the process of connecting your Rulebricks account to Zapier, connecting a rule to your Zap, and finally mapping data in your automation to send to the rule. If you ever run into issues with the action that do not seem clear, try deleting and re-creating the entire step, and if you’re still stuck, send us a quick email.\n\n[Find us on Zapier →](https://zapier.com/apps/rulebricks/integrations)\n\n### Developer Handoff\n\nGiven that you've created and published a rule– Rulebricks is incredibly quick for developers to integrate into existing applications, often taking less than half an hour to implement. What's more, they only need to set up each rule for you once– subsequent edits to the rule and changes to the decision table within will take effect seamlessly.\n\n## For Developers\n\n### Via API/SDK\n\nA few API endpoints are made available for developers to effectively integrate a Rulebricks decision from anywhere. We also offer fully-featured SDK's in most programming languages that are dead-easy to install and use.\n\nThe particular endpoints that execute decision making assets are below, and all require the `x-api-key` header (with the API key found on your dashboard).\n\n`/solve/[slug]` – **POST** your JSON request data to this endpoint to run your rule\n\n`/flows/[id]` – **POST** your JSON request data to a Rule Flow you've created using this rule to run it as part of a larger sequence\n\nRead more about these endpoints in our [API Reference](/api-reference), and use the tab there in the top right to switch to our SDK documentation in the language of your choice.\n\n### Via Flows\n\nFlows will still require use of our API/SDK noted above, but contain within them powerful abilities to chain rules, or connect them with databases or internal services.\n\nOne particularly powerful component of Flows is that flows allow you to leverage powerful caching mechanisms on any data fetching you're doing within– meaning you can create high-performance, low-latency Flows that still perform otherwise time consuming tasks like fetching data from an API or querying an SQL database.\n\nFlows also allow you to explode lists and run rules against each object within.\n\n[Learn more about Flow capabilities →](/integrating-rules/rule-flows)"
  },
  {
    "title": "Requests & Responses",
    "description": "Requests and responses are the inputs and outputs to any rule in Rulebricks. Learn how to configure them here.",
    "path": "/getting-started/requests-and-responses",
    "content": "# Requests & Responses\n\n## Inputs and outputs\n\nRequest & Response objects are, respectively, the inputs and outputs to any rule in Rulebricks. Specifically, they are any object in JSON notation, as previewed at the end of the last section.\n\nLet’s look at those one more time:\n\n### Request Object\n\n[Code: ,\n  \"date_form_completed\": \"2022-11-23\"\n}\n]\n\n### Result Object\n\n[Code: \n]\n\n## Inputs → \"Request Columns\"\n\n**To begin configuring any rule in Rulebricks, you require a Request Object**.\n\nRulebricks uses the attributes available in the JSON object provided to initialize the columns of an empty decision table. Most applications will document examples of objects their platform outputs from various API endpoints and integrations on their website, but you're also free to create your own example objects/formats based on your needs for a particular decision point.\n\nEach property in the JSON object corresponds with a column in your decision table, either as a \"Request\" column, within which you can define conditions against data, or a \"Response\" column within which you can define outcome data.\n\nA fresh decision table initialized in Rulebricks using the request object a bit above might look like:\n\n### **Request Columns**\n\n| Industry `industry` | Company Size `company_size` | Location City `location.city` | Location State `location.state` | Location Country `location.country` | Date Form Completed `date_form_completed` |\n| ------------------- | --------------------------- | ----------------------------- | ------------------------------- | ----------------------------------- | ----------------------------------------- |\n|                     |                             |                               |                                 |                                     |                                           |\n\nSomething that isn’t shown here is that the table also identifies what kind of data is in each column, determining whether it contains text, numbers, booleans, dates, or lists.\n\nFrom here, you’re able to hide columns you’d like to ignore, rename columns to make information more meaningful, and set default values for information that is missing from future request objects.\n\n## Outputs → \"Response Columns\"\n\n**To receive any information from a rule, you require a Response Object.**\n\nMuch like the request object, Rulebricks will initialize columns to match any attributes you provide in this object. Unlike the request object, the response object doesn’t come from anywhere– you probably have to create it based on what you're trying to use rules to determine, and you’re free to add or remove any fields as they come to mind.\n\n#### Functions\n\nResponse columns can uniquely also be \"Function\" type, which is a powerful type that essentially lets you create Excel-style formulas that can calculate using any of the input data or other output data. For example, if we override the price response column type in our running example to be a Function type column, we can simply type in something like `50 + company_size / 1.2` into cells in the price response columns."
  },
  {
    "title": "Build your first rule",
    "description": "Build your first rule in Rulebricks. Learn how to create a rule, add conditions, and test your rule here.",
    "path": "/getting-started/start-building",
    "content": "# Build your first rule\n\nLet's get started building a rule. First, go to the [dashboard](https://rulebricks.com/dashboard). If this is your first time creating a rule, it will look something like this:\n\n![Dashboard Entry](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/start-building/app-entry.png)\n\n  IconBrackets,\n  IconCalendar,\n  Icon123,\n  IconAlphabetLatin,\n  IconCheckbox,\n  IconMathFunction,\n} from '@tabler/icons-react'\n\n## Creating Your First Rule\n\n## Understanding the Rule Table\n\nThe **rule table** is the main area where you define your decision logic. It's split into two sections:\n\n- **Request (Conditions)**: The left side contains the conditions that determine which row matches\n- **Response (Results)**: The right side contains the values returned when a row matches\n\nAt the top of each column is the **column header** showing the column name and data type icon.\n\n### Data Types\n\nRulebricks supports several types of data commonly used in decision-making:\n\n[Code: price * 1.08 // Add 8% tax\n]\n\n</Tabs.Tab>\n</Tabs>\n\nWant to see a full list of the operators supported for each type on Rulebricks? Check out our [Operator Index](https://rulebricks.com/operators).\n\n## Setting Up Your Schema\n\nThe schema defines what data your rule accepts (request) and returns (response).\n\n</Tabs>\n\n### Configure the Request Schema\n\nLet's create a simple pricing rule. Set up your request schema with:\n\n[Code: \n]\n\nClick **Set Schema** to apply the changes.\n\n![Set Schema](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/start-building/set-schema.png)\n\n### View Column Details\n\nYou can click on any column header to see and edit its details, including type and display name.\n\n![Column Details](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/start-building/column-details.png)\n\n### Save the Schema\n\nClick **Save** to apply your schema changes.\n\n![Save Schema](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/start-building/save-schema.png)\n\n### Set Up the Response Schema\n\nConfigure what your rule returns. For our example:\n\n[Code: \n]\n\n![Set Response Schema](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/start-building/set-save-response-schema.png)\n\n</Steps>\n\n## Adding Conditions and Results\n\nNow let's add the actual decision logic to your rule.\n\n## Testing Your Rule\n\n## Adding a Catch-All Row\n\nTo handle cases where no specific condition matches, add a catch-all row.\n\n## Final Rule State\n\nYour completed rule should look like this:\n\n![Final Rule State](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/start-building/final-rule-state.png)\n\n**Row 1**: If price > 10 → result: true\n**Row 2**: Catch-all → result: false\n\n## How Row Matching Works\n\nRulebricks evaluates rows **top to bottom**:\n\n1. For each row, all conditions in the request section are checked\n2. If **all** conditions in a row pass, that row \"matches\"\n3. The **first matching row** determines the response\n4. If **no rows match**, an error is returned (unless you have a catch-all)\n\n---\n\nThat's it! You've built and tested your first rule. Continue to the next section to learn how to [publish your rule](/managing-rules/publishing-rules) and call it from your application."
  },
  {
    "title": "What is a rule?",
    "description": "Understanding what a rule is in Rulebricks is the first step to building powerful automations. Learn more about rules here.",
    "path": "/getting-started/what-is-a-rule",
    "content": "# What is a rule?\n\n## A quick example\n\nThe fastest way to understand how rules work is by example.\n\nLet’s say we’re working at a software company and have a few automations on Zapier that help us engage prospects that sign up on our website, follow up with them as potential customers, and add them to our CRM, and we’re looking to start scoring these prospects so we have a better understanding of which are more likely to convert and actually provide us with their business.\n\nOur ideal customer could be anyone, but for the purposes of this example let’s say we’re looking specifically for startups in financial technology– these are the people most likely to buy our software. From some form responses and lead enrichment technologies, we have a bunch of data on each prospect, and we mainly need to look for industry and company size matches.\n\nThere might be some exceptions here, however– if someone from a particularly big company reaches out, we’ll probably at least want to talk with them to understand their needs, so we can score them highly. And our market might be local to the US, so we might like that as well.\n\nFrom what we’ve written down so far, a decision table to score leads for our business might look like the following:\n\n### **Conditions → Results**\n\n| Industry   | Company Size | HQ Location | Last Contact  |     | Score |\n| ---------- | ------------ | ----------- | ------------- | --- | ----- |\n| Fintech    | < 500        | in US       | Any           | →   | 100   |\n| Fintech    | > 2,000      | in US       | < 30 days ago | →   | 90    |\n| Fintech    | Any          | not in US   | < 30 days ago | →   | 80    |\n| Finance    | Any          | in US       | < 30 days ago | →   | 70    |\n| Insurance  | Any          | in US       | < 30 days ago | →   | 50    |\n| Government | Any          | in US       | < 30 days ago | →   | 50    |\n| Any        | Any          | in US       | Any           | →   | 10    |\n| Any        | Any          | Any         | Any           | →   | 0     |\n\nUnpacking this is quite straightforward.\n\nUsing our data on a prospect, we can identify if they meet all the comparisons in a row, looking at each row one at a time, from top to bottom. If we have a large US fintech that’s recently reached out, we’d find they meet all the conditions in the second row and stop there.\n\nWe then look at the results table for that particular row– any values in the second row of the results table are now our output and returned as results of this decision. The decision table above only has one column, so only the number 90 for the score is returned, but we could easily modify it to return other information along with this as well.\n\nAll the “Any” values at the bottom of the table are our catch-all, as we’ll want to return something if none of the rows match our data. In Rulebricks, you’re able to simply provide default values that help eliminate some of the need to explicitly define these rows everywhere.\n\n#### Terminology\n\n- **Comparisons**: The individual logical checks we’re making in our decision table. Each comparison is a single check that must be true for a row (condition) to be considered a match.\n- **Conditions**: Each condition is a row in the table, i.e. a group of comparisons that must all be true for a row to be considered a match.\n- **Request Data (Object)**: The incoming data for each decision we are using our rule to make using the left side of the table, i.e. the data that is being compared to the conditions.\n- **Results/Response Data (Object)**: The outgoing data on the right side of the table, i.e. the data that is returned from our rule when a condition row is considered a match.\n\nSome terminology is used interchangeably, but these are the most common terms you’ll see when working on Rulebricks.\n\n## What this actually looks like\n\nDecision tables are fairly simple conceptually, and can be straightforward enough to set up on Rulebricks, but how do they interact with real world data? The decision above requires a **Request Object** to configure, and return a **Result Object**, further discussed in the next section, and previewed below.\n\n#### Request Object\n\n[Code: ,\n  \"date_form_completed\": \"2022-11-23\"\n}\n]\n\n#### Result Object\n\n[Code: \n]"
  },
  {
    "title": "Flow Functions",
    "description": "Flows are a powerful way to chain together multiple rules, alongside calls to external services, and structure complex decision-making workflows. Explore their latest capabilities here.",
    "path": "/integrating-rules/flow-capabilities",
    "content": "# Flow Functions\n\n  IconRouteAltRight,\n  IconBraces,\n  IconBrandCitymapper,\n  IconCode,\n  IconDatabase,\n  IconApiApp,\n  IconBracketsContain,\n  IconSparkles,\n  IconLock,\n  IconCloud,\n  IconFocusCentered,\n  IconBell,\n} from '@tabler/icons-react'\n\nWhile your configurable rules are undoubtedly the most valuable pieces Flows expose, we offer several built-in functions to help your team collect data from external sources and run logic conditionally.\n\nWe call these \"flow functions\"– special operations you can use in your flows to perform various actions beyond rule execution. Below are all the available flow function node types– but do try our application or reach out to get information on our latest capabilities.\n\n## Continue If\n\n}\n  name=\"Continue If\"\n  description=\"Evaluate if an input property is true/truthy and only proceed with specific data if so.\"\n/>\n\n![Continue If](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/integrating-rules/continue-if.png)\n\nProceed based on one of four selectable conditions:\n\n- If a specific property is **\"truthy\"** (not empty, non-zero, non-null)\n- If a specific property is exactly **`true`**\n- If a specific property is exactly **`false`**\n- If a specific property is **\"falsy\"** (empty list, zero, null, or false)\n\nIf the condition is met, the flow continues along the exiting edges. Use two \"Continue If\" nodes to model if/else logic.\n\n## Result Object\n\n}\n  name=\"Result Object\"\n  description=\"Nest data in a result object within a specific key to better organize the final output of your flow.\"\n/>\n\n![Result Object](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/integrating-rules/result.png)\n\nThe final output of your flow. It collects results from all preceding nodes and returns them as the flow's response.\n\n- You can use multiple Result Object nodes with unique keys\n- **Required**: Every flow must end with at least one Result Object node\n\n## Lookup Table\n\n}\n  name=\"Lookup Table\"\n  description=\"Map an input 'key' to any output 'value' based on a table of key & value pairs.\"\n/>\n\n![Lookup Table](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/integrating-rules/lookup-table.png)\n\nLook up a value in a table and return a corresponding value if an exact match is found. Works well with Continue If nodes by returning true/false based on lookup results.\n\n## Run Code\n\n}\n  name=\"Run Code\"\n  description=\"Execute custom JavaScript to perform operations like computing data, making API calls, or integrating with external services.\"\n/>\n\n![Run Code](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/integrating-rules/code.png)\n\nRun custom JavaScript code using data from your flow. Useful for:\n\n- Making calls to external services\n- Performing complex calculations\n- Custom string formatting or data transformation\n\nAvailable libraries: `fetch`, `moment`, `lodash`, and more.\n\nAccess connected values via the `inputs` dictionary and return values via the `outputs` dictionary.\n\n[Code: // Example: Calculate discount\nconst total = inputs.subtotal\nconst discount = total > 100 ? total * 0.1 : 0\noutputs['discount'] = discount\noutputs['final_total'] = total - discount\n]\n\n## SOAP Request\n\n}\n  name=\"SOAP Request\"\n  description=\"Connect to SOAP/XML web services using WSDL to call operations on enterprise systems.\"\n/>\n\nConnect to SOAP/XML web services to integrate with legacy enterprise systems. Upload a WSDL file to auto-discover available operations.\n\nFeatures:\n\n- WSDL-based service discovery\n- Support for complex XML request/response structures\n- Built-in authentication options\n\n## Database Query\n\n}\n  name=\"Database Query\"\n  description=\"Query a PostgreSQL database to fetch data from an external resource and use it in this flow.\"\n/>\n\n![Database Query](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/integrating-rules/db.png)\n\nQuery a PostgreSQL, MSSQL, or MySQL database, and return results. Variables from your flow can be used in the query.\n\nFeatures:\n\n- Use `rows` with a For Each node or send directly to Result Object\n- Built-in 1-minute caching for performance\n\n## API Request\n\n}\n  name=\"API Request\"\n  description=\"Make an HTTP request to any API to fetch & send data from/to external resources.\"\n/>\n\n![API Request](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/integrating-rules/api.png)\n\nMake HTTP requests to external APIs. Variables from your flow can be used in the URL, headers, and body.\n\nFeatures:\n\n- GET, POST, PUT, DELETE methods\n- Custom headers and authentication\n- Built-in 1-minute caching, customizable cache key\n\n## For Each\n\n}\n  name=\"For Each\"\n  description=\"Perform following operations on each available item in a non-empty list of values/objects, and return a list of results.\"\n/>\n\n![For Each](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/integrating-rules/for-each.png)\n\nIterate over a list of items and apply a rule to each one. Perfect for:\n\n- Transforming collections of objects\n- Processing lists of orders, users, or products\n- Batch operations\n\n## AI Inference\n\n}\n  name=\"AI Inference\"\n  description=\"Intelligently parse out structured properties from text using AI models to evaluate rules against.\"\n/>\n\n![AI Inference](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/integrating-rules/ai-inference.png)\n\nExtract structured data from text using OpenAI. Useful for:\n\n- Parsing emails and reports\n- Extracting specific information from documents\n- NLP preprocessing before rule execution\n\nTo use:\n\n1. Connect a text input\n2. Define target labels to extract\n3. Click \"Run Inference\"\n\n## Vault\n\n}\n  name=\"Vault\"\n  description=\"Connect to secure key vaults to retrieve secrets at runtime without exposing credentials.\"\n/>\n\n![Vault](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/integrating-rules/vault.png)\n\nSecurely retrieve sensitive information from cloud secrets managers (AWS, GCP, Azure).\n\nSecurity features:\n\n- Secrets never appear in clear text in the flow\n- Cannot be logged or returned in output\n- Only accessible within Run Code nodes\n\n## Context Operation\n\n}\n  name=\"Context Operation\"\n  description=\"Read, update, or delete context data. Use for stateful context data operations within flows.\"\n/>\n\nInteract with [Rulebricks Contexts](/contexts) directly from your flow. Perfect for:\n\n- Reading entity data to use in rule evaluation\n- Updating context properties based on flow outcomes\n- Deleting or archiving context records\n\n## Send Notification\n\n}\n  name=\"Send Notification\"\n  description=\"Send multi-channel alerts via Email, Slack, Discord, or PagerDuty based on flow data.\"\n/>\n\nTrigger notifications to your team or external systems based on flow outcomes. Supports multiple channels:\n\n- **Email**: Send templated emails with flow data\n- **Slack**: Post messages to channels or DMs\n- **Discord**: Send webhook messages to Discord servers\n- **PagerDuty**: Create incidents for on-call alerting"
  },
  {
    "title": "Flows in Rulebricks",
    "description": "Flows in Rulebricks are a powerful way to chain together multiple rules, alongside calls to external services, and structure complex decision-making workflows. Learn how to create a Rule Flow here.",
    "path": "/integrating-rules/rule-flows",
    "content": "# Flows in Rulebricks\n\n![Flow Header](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/flows/flow-header.png)\n\nFlows are a powerful way to chain together multiple rules, alongside calls to external services, and structure complex decision-making workflows.\n\n  IconRouteAltRight,\n  IconBraces,\n  IconBrandCitymapper,\n  IconCode,\n  IconDatabase,\n  IconApiApp,\n  IconBracketsContain,\n  IconSparkles,\n  IconLock,\n  IconCloud,\n  IconFocusCentered,\n  IconBell,\n} from '@tabler/icons-react'\n\nThese are particularly useful when you have a series of decisions that need to be made in a specific order, or when you'd like to separate logic into multiple rules for easier maintenance of your decision-making logic.\n\n## Flow Reactivity\n\nUnique to Rulebricks, the Rulebricks Flow editor is **reactive**— as you make changes to rule input fields, the editor automatically visualizes your data flow in real-time. This makes it incredibly easy to see how your flow behaves _as you build it_ without repeated end-to-end build/test cycles.\n\n  <video\n    width=\"1920\"\n    height=\"1080\"\n    autoPlay\n    muted\n    loop\n    preload=\"auto\"\n    className=\"rounded-lg\"\n  >\n    <source src=\"https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/integrating-rules/flow-reactivity.m4v\" />\n    Your browser does not support the video tag\n  </video>\n\nReactivity applies to all sequences of nodes until certain execution or query nodes are reached. These nodes pause execution until you manually click the run button, preventing accidental spam to external services.\n\nWhile this feature exists to help you model your flow while understanding what is happening to the actual data as it moves through, it is not a perfect guarantee of how your Flow will behave _end-to-end_– for that, simply use the \"Try\" or \"Test\" tabs, available in the sidebar.\n\n## Creating a Rule Flow\n\n### Build your flow\n\nYou'll be taken to the Flow editor where you can:\n\n- Drag and drop published rules from the sidebar onto the canvas\n- Add flow functions (code execution, API calls, etc.)\n- Connect nodes together to define the execution order\n\n![Flow Editor Entry](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/flows/flow-editor-entry.png)\n\n### Connect your nodes\n\nDrag from an output handle of one node to the input of another to connect them. Data flows through the connections.\n\n![Try Connecting](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/flows/try-connecting.png)\n\n</Steps>"
  },
  {
    "title": "Team Templates",
    "description": "Create reusable rule templates for your team. Templates share proven schemas and decision patterns across your organization.",
    "path": "/managing-rules/creating-templates",
    "content": "# Team Templates\n\nTemplates let you capture a well-designed rule and make it available for your whole team to reuse, or for customers to use as a starting point.\n\nWhen someone creates a new rule from a template, they get the schema, sample conditions, settings, and test cases, ready for them to customize.\n\nWhile exported RBM files do save and contain the histories of exported decision assets, users importing them as Team Templates will not receive these histories.\n\n## Creating a Template\n\n## Using a Template\n\nWhen creating a new rule, click the **Templates** tab in the create dialog. Team Templates should appear by default. If you're not seeing them, it's possible the template has been assigned to a specific User Group, and you may not be part of it.\n\n![Find Team Templates](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/templates/find-team-templates.png)\n\n## Managing Templates\n\n- **Administrators** and **Developers** can create and delete templates\n- All team members can view and use templates\n- Templates can't be edited—create a new version with a clear name like `\"Credit Check - v2\"`\n\n## Or, Duplicate\n\nIf templates feel heavyweight for your needs, users can always find an existing rule and click **Duplicate**. This works well for quick iterations or one-off copies."
  },
  {
    "title": "Exporting Rules & Flows",
    "description": "Export rules and flows as .rbm files for backup, version control, or sharing across workspaces.",
    "path": "/managing-rules/exporting-rules",
    "content": "# Exporting Rules & Flows\n\nExport rules and flows as `.rbm` files to back them up, share them across workspaces, or store them in version control.\n\n## Exporting\n\n## Importing\n\nClick **Create → Import** in the dashboard and upload an `.rbm` file.\n\nWe offer two conflict resolution schemes, that help address what happens if you're pulling in data you might already have a local copy of.\n\n![Import View Conflict](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/exporting-rules/import-view-conflict.png)\n\n## What's Included\n\n- **Rules** export with all conditions, results, schema, referenced dynamic values, settings, test cases, and publication histories.\n- **Flows** export the complete flow definition plus all embedded rules.\n\nWe do not obfuscate our schemas in exported files and encourage users to review how their assets are stored. RBM files are stored as large amounts of JSON, but they are structured in a way your team may be able to build custom tools directly against them!"
  },
  {
    "title": "Publishing Rules",
    "description": "Publishing a rule in Rulebricks makes it available for use in your applications. Learn how to publish, version, and compare rules.",
    "path": "/managing-rules/publishing-rules",
    "content": "# Publishing Rules\n\nPublishing makes your rule available via the API, in Forms, and in Rule Flows. Every publish creates a new version—you can target specific versions, compare changes, and roll back if needed.\n\n## Create a new version\n\n</Steps>\n\n## Versioning\n\nEach publish creates a numbered version (v1, v2, etc.). Target specific versions by appending the number to the rule slug:\n\n- `hlDPsJMVGQ` → latest version\n- `hlDPsJMVGQ/2` → version 2 specifically\n\nThis lets you build highly stable and customizable deployment workflows around your rules while developing future versions.\n\n## Comparing Versions\n\nBefore publishing, compare your working changes against any previous version to see exactly what's different.\n\nClick **Compare Versions** in the rule editor header:\n\n![Compare Versions Button](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/comparing-rules/find-compare-button.png)\n\nThe comparison view shows your working changes side-by-side with the selected version. Added rows, removed rows, and modified conditions are highlighted:\n\n![Rule Compare View](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/comparing-rules/rule-compare-view.png)\n\nUse this to review changes before publishing, or to understand what changed between versions when investigating unexpected behavior."
  },
  {
    "title": "Decision Logs",
    "description": "Decision logs record every rule execution with full request/response data. Search with DDQL to find specific decisions.",
    "path": "/managing-rules/rule-logging",
    "content": "# Decision Logs\n\nEvery rule execution is logged with the full request, response, and which conditions matched. Use logs to debug issues, audit decisions, and understand how your rules behave in production.\n\n## Viewing Logs\n\nNavigate to the **Logs** tab in the dashboard.\n\n![Logs Tab](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/logs/view-logs-tab.png)\n\nEach entry shows:\n\n- Request and response payloads\n- Which conditions matched or failed\n- HTTP status, IP address, timestamp, and duration\n\nFilter by rule, status code, or date range to narrow down what you're looking for.\n\n## Searching with DDQL\n\nDecision Data Query Language lets you search by the actual data in your requests and responses.\n\nFor example, if I wanted to pull rule executions for a particular `application_id`, I might do the following:\n\n![Query Logs with DDQL](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/logs/query-logs-ddql.png)\n\n### Examples\n\n[Code: credit_score >= 700 AND approval_decision = \"denied\"\ncustomer_id = \"CUST-12345\"\namount > 10000 AND risk_score < 0.2\ntier:gold OR tier:platinum\n]\n\n### Operators\n\n| Operator          | Description                  | Example            |\n| ----------------- | ---------------------------- | ------------------ |\n| `=`               | Exact match                  | `status=approved`  |\n| `!=`              | Not equals                   | `status!=rejected` |\n| `:`               | Contains (strings) or equals | `name:Smith`       |\n| `<` `<=` `>` `>=` | Comparisons                  | `score>=700`       |\n\nCombine with `AND` and `OR`. Use parentheses for precedence:\n\n[Code: (tier = \"gold\" AND amount > 100) OR tier = \"platinum\"\n]\n\n</Tabs>\n\nField names are case-sensitive and must match your schema. Queries search both request and response payloads automatically.\n\n## Log Details\n\nClick any entry to see the full request/response JSON, detailed condition evaluation, and timing data."
  },
  {
    "title": "Testing Rules",
    "description": "Test your rules before publishing with Try mode for quick checks and Suite mode for regression testing.",
    "path": "/managing-rules/testing-rules",
    "content": "# Testing Rules\n\nTest your rules before they hit production. Rulebricks gives you two modes: **Try** for quick single-request testing, and **Suite** for regression testing across multiple scenarios.\n\n## Try Mode\n\nOpen the **Test** tab in the rule editor and select **Try**.\n\n![Find Test Tab](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/testing-rules/find-test-tab.png)\n\n![Try Tab](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/testing-rules/try-tab.png)\n\nPaste a request object and click the orange button. The decision table lights up:\n\n- **Green cells** — Conditions that matched\n- **Red cells** — Conditions that didn't match\n- **Blue/Yellow cells** — The results returned\n\nThis visual feedback shows exactly which row matched and why.\n\n## Suite Mode\n\nSwitch to **Test Suite** mode to run multiple test cases at once.\n\n![Test Suite](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/testing-rules/test-suite.png)\n\nBuild your suite by saving tests from Try mode. When a test produces the expected result, save it. Mark tests as **Critical** if they should block publishing when they fail.\n\n### Rapid Test Generation\n\nWe find writing tests boring, and we thought you might too– a powerful AI feature here allows you to create many tests very quickly given one or two examples. Just build and name one test case in the Suite, and click \"Generate Tests\" to instantly get coverage over your entire rule.\n\n## Continuous Testing\n\nEnable **Continuous Testing** in rule settings to run your test suite automatically before every publish.\n\nWhen enabled, you'll see a test score next to every published version—the percentage of tests that passed. Critical tests prevent publishing if they fail; non-critical tests report results but don't block."
  },
  {
    "title": "Objects in Rulebricks",
    "description": "Objects are reusable schema definitions that provide field suggestions when building rules and contexts. Define once, use everywhere.",
    "path": "/objects",
    "content": "# Objects in Rulebricks\n\nYou've got a customer object with `tier`, `credit_score`, and `lifetime_value`. You'll use those fields in a dozen rules. Do you really want to type them out each time?\n\nObjects are team-level schema definitions that provide field suggestions when you create rules or contexts. Define your data structure once, and every rule you build can pull from it.\n\n![Objects Team Tab](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/objects/objects-team-tab.png)\n\nRulebricks Admins can find this tab within the **Team** tab on your dashboard.\n\n## Data Clarity\n\n### Field suggestions\n\nWhen building a rule, select an Object and its fields appear in the schema editor. No retyping, no typos.\n\n![Map Fields from Object](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/objects/map-fields-from-object.png)\n\n### Automatic Dynamic Values\n\nIf your Object uses JSON Schema with `enum` fields, Rulebricks extracts those values and creates dropdown options in your rule conditions.\n\n![Enum Benefits](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/objects/mapping-fields-enums-benefits.png)\n\n### Consistency\n\nWhen everyone builds rules from the same Objects, field names stay consistent across your workspace. This way, you'll never run into issues where rule one may have a schema like:\n\n[Code: \n]\n\nAnd rule two, designed elsewhere, uses:\n\n[Code: \n]\n\n## Accepted Formats\n\nObjects can be defined using both JSON Schemas, or just an example JSON object. If you're planning to use our objects feature, it's worth noting using JSON Schemas has substantial benefits across our platform that may not be immediately obvious.\n\nEven if you don't have a unified JSON schema anywhere, we make it really easy to make one using our \"Smart Import\" tool.\n\n**JSON Schema** — Full schema definitions with types, validation rules, and enums\n\n[Code: ,\n    \"credit_score\": \n  }\n}\n]\n\n**JSON Object** — Plain example objects when you just want field suggestions without full validation\n\n[Code: \n]\n\nRulebricks will automatically detect which format you're using.\n\n## Objects vs. Contexts\n\nTwo features that may initially appear somewhat similar on our platform are _Objects_ and _Contexts_.\n\nThe _Objects_ described here are designed for bringing the shape and fields of business objects that may live elsewhere into Rulebricks for consistency.\n\nThe _Contexts_ feature, discussed later in this documentation, while able to create a view of your data relevant for decision making in a similar way, is designed exclusively for decisions where data arrives over time. Contexts are stateful and have lifespans associated with them."
  },
  {
    "title": "Creating Objects",
    "description": "Three ways to create Objects in Rulebricks—manual creation, AI-powered Smart Import, or pre-built templates.",
    "path": "/objects/creating-objects",
    "content": "# Creating Objects\n\n</Tabs>\n\n## Using Objects in Rules\n\nWhen creating a rule, click **From Object** to pull fields from an existing Object:\n\n![Create Rule Using Object](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/objects/create-rule-using-object.png)\n\nSelect the fields you need and they're added to your rule's schema—correctly typed and named.\n\n## Automatic Dynamic Values\n\nWhen you save a JSON Schema with `enum` fields, Rulebricks extracts those values and creates Dynamic Values:\n\n![Objects Create Values](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/objects/objects-create-values.png)\n\nThese appear as dropdown options in your rule conditions, so instead of typing `\"gold\"` you select it from a list. Fewer typos, faster rule building."
  },
  {
    "title": "Architecture & Operations Guide",
    "description": "Explains the Rulebricks Helm chart architecture, component interactions, migration flows, and operational considerations.",
    "path": "/private-deployment/architecture",
    "content": "# Architecture & Operations Guide\n\nThis document explains the Rulebricks Helm chart architecture, component interactions, migration flows, and operational considerations, so you can better configure your deployment.\n\n### Component Overview\n\n[Code: graph TB\n    subgraph Internet\n        Users[Users/API Clients]\n    end\n\n    subgraph Kubernetes[\"Kubernetes Cluster\"]\n        subgraph Ingress[\"Ingress Layer\"]\n            Traefik[Traefik LoadBalancer]\n        end\n\n        subgraph Core[\"Rulebricks Core\"]\n            App[Rulebricks App]\n            HPS[HPS Gateway]\n            Workers[HPS Workers]\n            Redis[Redis Cache]\n        end\n\n        subgraph Data[\"Data Layer\"]\n            Kafka[Kafka]\n            Postgres[(PostgreSQL)]\n            Kong[Kong API Gateway]\n        end\n\n        subgraph Supabase[\"Supabase Stack\"]\n            Auth[GoTrue Auth]\n            Rest[PostgREST]\n            Realtime[Realtime]\n            Storage[Storage API]\n        end\n\n        subgraph Support[\"Supporting Services\"]\n            Vector[Vector]\n            CertManager[cert-manager]\n            KEDA[KEDA]\n            ExternalDNS[external-dns]\n        end\n    end\n\n    subgraph External[\"External Services\"]\n        LetsEncrypt[Let's Encrypt]\n        DNS[DNS Provider]\n        LogSink[Log Sink S3/etc]\n    end\n\n    Users --> Traefik\n    Traefik --> App\n    Traefik --> HPS\n    Traefik --> Kong\n\n    App --> Redis\n    App --> Kafka\n    HPS --> Workers\n    Workers --> Kafka\n    Workers --> Redis\n\n    Kong --> Auth\n    Kong --> Rest\n    Kong --> Realtime\n    Kong --> Storage\n\n    Auth --> Postgres\n    Rest --> Postgres\n\n    Kafka --> Vector\n    Vector --> LogSink\n\n    CertManager --> LetsEncrypt\n    ExternalDNS --> DNS\n    KEDA --> Workers\n]\n\n### Request Flow\n\n[Code: sequenceDiagram\n    participant Client\n    participant Traefik\n    participant HPS\n    participant Kafka\n    participant Worker\n    participant Redis\n\n    Client->>Traefik: POST /api/v1/solve/\n    Traefik->>HPS: Route to HPS Gateway\n    HPS->>Kafka: Publish solve request\n    HPS->>Client: 202 Accepted (async)\n\n    Kafka->>Worker: Consume solve request\n    Worker->>Redis: Fetch rule definition\n    Worker->>Worker: Execute rule\n    Worker->>Kafka: Publish result\n    Worker->>Kafka: Publish decision log\n]\n\n### Component Responsibilities\n\n| Component       | Purpose                             | Scaling                         |\n| :-------------- | :---------------------------------- | :------------------------------ |\n| **Traefik**     | Ingress, TLS termination, routing   | HPA (2-3 replicas default)      |\n| **App**         | Web UI, rule editor, management API | Single replica                  |\n| **HPS Gateway** | API gateway for rule execution      | Static replicas                 |\n| **HPS Workers** | Rule execution engines              | KEDA autoscaling                |\n| **Redis**       | Rule cache, session storage         | Single replica with persistence |\n| **Kafka**       | Message queue, event streaming      | KRaft mode, single node default |\n| **PostgreSQL**  | Persistent data storage             | Single replica with PVC         |\n| **Vector**      | Log aggregation and forwarding      | Static replicas                 |\n\n---\n\n## Database Migrations\n\nThe chart includes two migration job variants that run automatically based on your configuration.\n\n### Migration Decision Tree\n\n[Code: flowchart TD\n    A[Helm Install/Upgrade] --> B\n    B -->|true| C[Self-Hosted Migration Job]\n    B -->|false| D\n    D -->|Yes| E[Managed Supabase Setup Job]\n    D -->|No| F[No migration job runs]\n\n    C --> G[Wait for Postgres ready]\n    G --> H[Extract migrations from app image]\n    H --> I[Apply SQL migrations via psql]\n    I --> J[Track in schema_migrations table]\n\n    E --> K[Install Supabase CLI]\n    K --> L[Authenticate with access token]\n    L --> M[Link to project]\n    M --> N[Push config.toml]\n    N --> O[Run db push]\n    O --> P[Enable SSL enforcement]\n]\n\n### Self-Hosted Migration Job\n\n**Triggered when:** `supabase.enabled: true`\n\n**Process:**\n\n1. **Init Container** extracts Supabase assets from the Rulebricks app image\n2. **Migration Container** uses `postgres:15-alpine` to:\n   - Wait for PostgreSQL to be ready\n   - Create `schema_migrations` tracking table\n   - Apply each `.sql` file in order\n   - Record applied migrations to prevent re-runs\n\n**Key Details:**\n\n[Code: # Job naming pattern\nname: }-db-migrate-}\n\n# Runs on\nannotations:\n  \"helm.sh/hook\": post-install,post-upgrade\n  \"helm.sh/hook-delete-policy\": before-hook-creation\n\n# Auto-cleanup\nspec:\n  ttlSecondsAfterFinished: 600  # 10 minutes\n]\n\n**Migration Tracking:**\n\n[Code: CREATE TABLE IF NOT EXISTS schema_migrations (\n  version VARCHAR(255) PRIMARY KEY,\n  applied_at TIMESTAMP DEFAULT NOW()\n);\n]\n\nEach migration file is tracked by filename. Already-applied migrations are skipped.\n\n### Managed Supabase Setup Job\n\n**Triggered when:** `supabase.enabled: false` AND `global.supabase.accessToken` is provided\n\n**Process:**\n\n1. **Init Container** extracts Supabase project configuration\n2. **Setup Container** uses `node:20-alpine` to:\n   - Install Supabase CLI\n   - Authenticate with your access token\n   - Link to your Supabase project\n   - Download and configure email templates\n   - Push configuration (SMTP, auth settings)\n   - Run `supabase db push` to apply schema\n   - Enable SSL enforcement\n\n**Configuration Flow:**\n\n[Code: flowchart LR\n    A[config.example.toml] --> B[Variable Replacement]\n    B --> C[config.toml]\n\n    D[Email Template URLs] --> E[Download Templates]\n    E --> F[Local Template Files]\n\n    C --> G[supabase config push]\n    F --> G\n    G --> H[Supabase Project Updated]\n]\n\n**Variables Replaced:**\n\n| Placeholder              | Source                              |\n| :----------------------- | :---------------------------------- |\n| `env(FULL_URL)`          | `https://`           |\n| `env(SMTP_HOST)`         | `global.smtp.host`                  |\n| `env(SMTP_PORT)`         | `global.smtp.port`                  |\n| `env(SMTP_USER)`         | `global.smtp.user`                  |\n| `env(SMTP_PASS)`         | `global.smtp.pass`                  |\n| `env(EMAIL_SUBJECTS_*)`  | `global.supabase.emails.subjects.*` |\n| `env(EMAIL_TEMPLATES_*)` | Downloaded from URLs                |\n\n### Debugging Migrations\n\n**Self-hosted:**\n\n[Code: # Check job status\nkubectl get jobs -n rulebricks -l app.kubernetes.io/component=migrations\n\n# View logs\nkubectl logs job/rulebricks-db-migrate-1 -n rulebricks\n\n# Check migration table\nkubectl exec -it deploy/rulebricks-supabase-db -n rulebricks -- \\\n  psql -U postgres -c \"SELECT * FROM schema_migrations ORDER BY applied_at;\"\n]\n\n**Managed Supabase:**\n\n[Code: # Check job status\nkubectl get jobs -n rulebricks -l app.kubernetes.io/component=managed-supabase-setup\n\n# View logs\nkubectl logs job/rulebricks-managed-supabase-setup-1 -n rulebricks\n]\n\n---\n\n## DNS and TLS Setup\n\n### DNS Record Requirements\n\n| Scenario             | Records Needed                  |\n| :------------------- | :------------------------------ |\n| Self-hosted Supabase | ``, `supabase.` |\n| Managed Supabase     | `` only                 |\n\n---\n\n## Scaling Considerations\n\n### Horizontal Scaling\n\n| Component   | Scaling Method | Trigger         |\n| :---------- | :------------- | :-------------- |\n| Traefik     | HPA            | CPU utilization |\n| HPS Workers | KEDA           | Kafka lag, CPU  |\n| Vector      | Manual         | Log volume      |\n\n### KEDA Scaling Configuration\n\n[Code: flowchart LR\n    A[Kafka Consumer Lag] --> B\n    B -->|Yes| C[Scale Up Workers]\n    B -->|No| D\n    D -->|Yes| C\n    D -->|No| E[Maintain Current]\n\n    F[Cooldown Period] --> G\n    G -->|Yes| H[Scale Down]\n    G -->|No| E\n]\n\n---\n\n## Troubleshooting\n\n#### Migration Job Failing\n\n[Code: # Check job status\nkubectl get jobs -n rulebricks\n\n# Get detailed error\nkubectl describe job rulebricks-db-migrate-1 -n rulebricks\n\n# Check pod logs\nkubectl logs job/rulebricks-db-migrate-1 -n rulebricks --all-containers\n]\n\n**Common causes:**\n\n- Database not ready (increase readiness wait)\n- Invalid credentials\n- Network policy blocking access\n\n#### HPS Workers Not Scaling\n\n[Code: # Check KEDA\nkubectl get scaledobject -n rulebricks\nkubectl describe scaledobject rulebricks-hps-workers -n rulebricks\n\n# Check Kafka metrics\nkubectl exec -it rulebricks-kafka-0 -n rulebricks -- \\\n  kafka-consumer-groups.sh --bootstrap-server localhost:9092 \\\n  --describe --group hps-workers\n]\n\n**Common causes:**\n\n- Kafka consumer group not found\n- KEDA unable to reach Kafka\n- Incorrect threshold configuration\n\n### Log Collection\n\n[Code: # All pods in namespace\nkubectl logs -n rulebricks -l app.kubernetes.io/instance=rulebricks --all-containers\n\n# Specific component with follow\nkubectl logs -n rulebricks -l app.kubernetes.io/component=hps-worker -f\n]"
  },
  {
    "title": "Configuration Reference",
    "description": "Comprehensive reference for all configuration values in the Rulebricks Helm chart.",
    "path": "/private-deployment/configuration-reference",
    "content": "# Configuration Reference\n\nThis document provides a comprehensive reference for all configuration values in the Rulebricks Helm chart. Values are organized by component with detailed explanations of their purpose, defaults, and recommendations.\n\n### Core Configuration\n\n| Parameter                   | Type    | Default                    | Required | Description                                                                     |\n| :-------------------------- | :------ | :------------------------- | :------- | :------------------------------------------------------------------------------ |\n| `global.domain`             | string  | `\"\"`                       | **Yes**  | The domain name for your Rulebricks instance. Must be a domain you control.     |\n| `global.email`              | string  | `\"support@rulebricks.com\"` | **Yes**  | Email address for Let's Encrypt certificate registration.                       |\n| `global.licenseKey`         | string  | `\"evaluation\"`             | **Yes**  | Your Rulebricks Enterprise license key.                                         |\n| `global.tlsEnabled`         | boolean | `false`                    | No       | Enable HTTPS. Set to `true` after DNS is configured or when using external-dns. |\n| `global.externalDnsEnabled` | boolean | `false`                    | No       | Enable external-dns annotations on ingresses for automatic DNS management.      |\n\n#### Domain Configuration\n\nYour domain should follow the pattern: `rulebricks.yourdomain.com`\n\nWhen self-hosting Supabase, an additional subdomain is created: `supabase.rulebricks.yourdomain.com`\n\n[Code: global:\n  domain: 'rulebricks.acme.com'\n  email: 'devops@acme.com'\n]\n\n### SMTP Configuration\n\nSMTP is **required** for user authentication flows (invitations, password resets, email verification).\n\n| Parameter              | Type    | Default                     | Description                                        |\n| :--------------------- | :------ | :-------------------------- | :------------------------------------------------- |\n| `global.smtp.host`     | string  | `\"smtp.mailtrap.io\"`        | SMTP server hostname                               |\n| `global.smtp.port`     | integer | `2525`                      | SMTP server port (typically 25, 465, 587, or 2525) |\n| `global.smtp.user`     | string  | `\"demo-user\"`               | SMTP authentication username                       |\n| `global.smtp.pass`     | string  | `\"demo-password\"`           | SMTP authentication password                       |\n| `global.smtp.from`     | string  | `\"no-reply@rulebricks.com\"` | Sender email address                               |\n| `global.smtp.fromName` | string  | `\"Rulebricks\"`              | Sender display name                                |\n\n#### Production SMTP Providers\n\n| Provider | Host                                | Port | Notes                        |\n| :------- | :---------------------------------- | :--- | :--------------------------- |\n| AWS SES  | `email-smtp.<region>.amazonaws.com` | 587  | Requires verified domain     |\n| SendGrid | `smtp.sendgrid.net`                 | 587  | API key as password          |\n| Mailgun  | `smtp.mailgun.org`                  | 587  | Domain verification required |\n| Postmark | `smtp.postmarkapp.com`              | 587  | Server token as password     |\n\n[Code: global:\n  smtp:\n    host: 'email-smtp.us-east-1.amazonaws.com'\n    port: 587\n    user: 'AKIAIOSFODNN7EXAMPLE'\n    pass: 'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY'\n    from: 'no-reply@yourdomain.com'\n    fromName: 'Your Company - Rulebricks'\n]\n\n### Supabase Keys\n\nThese JWT keys are used for authentication between components.\n\n| Parameter                    | Type   | Description                                 |\n| :--------------------------- | :----- | :------------------------------------------ |\n| `global.supabase.anonKey`    | string | Public/anonymous key for client-side auth   |\n| `global.supabase.serviceKey` | string | Service role key for server-side operations |\n| `global.supabase.jwtSecret`  | string | JWT signing secret (self-hosted only)       |\n\n#### Managed Supabase (Cloud)\n\nWhen using Supabase Cloud instead of self-hosting:\n\n| Parameter                     | Type   | Description                                        |\n| :---------------------------- | :----- | :------------------------------------------------- |\n| `global.supabase.url`         | string | Project URL (e.g., `https://abcd1234.supabase.co`) |\n| `global.supabase.projectRef`  | string | Project reference ID (derived from URL if empty)   |\n| `global.supabase.accessToken` | string | Personal access token for Supabase CLI             |\n\n[Code: global:\n  supabase:\n    url: 'https://abcd1234.supabase.co'\n    anonKey: '<from-supabase-dashboard>'\n    serviceKey: '<from-supabase-dashboard>'\n    accessToken: '<personal-access-token>'\n\nsupabase:\n  enabled: false # Disable self-hosted Supabase\n]\n\n### Email Templates\n\nCustomize authentication email subjects and templates:\n\n[Code: global:\n  supabase:\n    emails:\n      subjects:\n        invite: 'Join your team on Rulebricks'\n        confirmation: 'Confirm Your Email'\n        recovery: 'Reset Your Password'\n        emailChange: 'Confirm Email Change'\n      templates:\n        invite: 'https://your-cdn.com/templates/invite.html'\n        confirmation: 'https://your-cdn.com/templates/verify.html'\n        recovery: 'https://your-cdn.com/templates/password_change.html'\n        emailChange: 'https://your-cdn.com/templates/email_change.html'\n]\n\n### AI Features\n\nEnable AI-powered rule generation (optional):\n\n| Parameter                | Type    | Default | Description        |\n| :----------------------- | :------ | :------ | :----------------- |\n| `global.ai.enabled`      | boolean | `false` | Enable AI features |\n| `global.ai.openaiApiKey` | string  | `\"\"`    | OpenAI API key     |\n\n[Code: global:\n  ai:\n    enabled: true\n    openaiApiKey: 'sk-...'\n]\n\n### SSO Configuration\n\nEnable Single Sign-On (SSO) via OpenID Connect (OIDC).\n\n| Parameter                 | Type    | Default | Description                                               |\n| :------------------------ | :------ | :------ | :-------------------------------------------------------- |\n| `global.sso.enabled`      | boolean | `false` | Enable SSO                                                |\n| `global.sso.provider`     | string  | `\"\"`    | Provider name (azure, google, okta, keycloak, ory, other) |\n| `global.sso.url`          | string  | `\"\"`    | Provider URL (required for all except Google)             |\n| `global.sso.clientId`     | string  | `\"\"`    | OAuth client ID                                           |\n| `global.sso.clientSecret` | string  | `\"\"`    | OAuth client secret                                       |\n\n#### Provider Types\n\nYou will need to go to your Supabase dashboard, and configure your provider in the Authentication tab. If you don't see your provider, use _Keycloak_ – our proxy uses it as a bridge.\n\n- **Native Providers** (`azure`, `google`, `okta`, `keycloak`): Supabase handles authentication directly.\n- **Custom Providers** (`ory`, `other`): The app uses a built-in OIDC proxy we manage to translate paths for your IdP.\n\n#### Identity Provider Setup\n\nYou must configure your Identity Provider (IdP) with the following settings:\n\n- **Scopes**: `openid`, `email`, `profile`\n- **Response Type**: `code`\n- **Grant Types**: `authorization_code`, `refresh_token`\n- **Auth Method**: `http body`\n- **Redirect URIs**:\n  1. `https://<your-domain>/api/sso-proxy/callback`\n  2. `<your-supabase-url>/auth/v1/callback`\n\n### External Secrets\n\nFor enterprise deployments using external secret management:\n\n| Parameter                        | Type   | Description                        |\n| :------------------------------- | :----- | :--------------------------------- |\n| `global.secrets.secretRef`       | string | Name of existing Kubernetes secret |\n| `global.secrets.secretRefKeys.*` | object | Key name mappings                  |\n\n[Code: global:\n  secrets:\n    secretRef: 'rulebricks-external-secrets'\n    secretRefKeys:\n      licenseKey: 'RULEBRICKS_LICENSE'\n      smtpUser: 'SMTP_USERNAME'\n      smtpPass: 'SMTP_PASSWORD'\n      supabaseAnonKey: 'SUPABASE_ANON'\n      supabaseServiceKey: 'SUPABASE_SERVICE'\n      supabaseAccessToken: 'SUPABASE_TOKEN'\n      openaiApiKey: 'OPENAI_KEY'\n]\n\n## Rulebricks Application\n\nThe core application and high-performance solver (HPS).\n\n### Application Image\n\n| Parameter                         | Type   | Default                            | Description             |\n| :-------------------------------- | :----- | :--------------------------------- | :---------------------- |\n| `rulebricks.app.image.repository` | string | `\"index.docker.io/rulebricks/app\"` | Docker image repository |\n| `rulebricks.app.image.tag`        | string | `\"1.X.X\"`                          | Image version tag       |\n| `rulebricks.app.image.pullPolicy` | string | `\"IfNotPresent\"`                   | Image pull policy       |\n\n### Logging Configuration\n\n| Parameter                                   | Type    | Default              | Description                              |\n| :------------------------------------------ | :------ | :------------------- | :--------------------------------------- |\n| `rulebricks.app.logging.enabled`            | boolean | `true`               | Enable decision logging                  |\n| `rulebricks.app.logging.kafkaBrokers`       | string  | `\"\"`                 | Kafka brokers (auto-discovered if empty) |\n| `rulebricks.app.logging.kafkaTopic`         | string  | `\"logs\"`             | Kafka topic for logs                     |\n| `rulebricks.app.logging.loggingDestination` | string  | `\"Console (stdout)\"` | Display label in UI                      |\n\n### Ingress\n\n| Parameter                      | Type    | Default     | Description            |\n| :----------------------------- | :------ | :---------- | :--------------------- |\n| `rulebricks.ingress.enabled`   | boolean | `true`      | Enable ingress         |\n| `rulebricks.ingress.className` | string  | `\"traefik\"` | Ingress class name     |\n| `rulebricks.ingress.paths`     | list    | `[]`   | List of paths to route |\n\n### Redis\n\nRedis is used for caching and session management.\n\n| Parameter                                    | Type    | Default   | Recommendation               |\n| :------------------------------------------- | :------ | :-------- | :--------------------------- |\n| `rulebricks.redis.resources.requests.cpu`    | string  | `\"200m\"`  | Increase for high traffic    |\n| `rulebricks.redis.resources.requests.memory` | string  | `\"256Mi\"` | —                            |\n| `rulebricks.redis.resources.limits.cpu`      | string  | `\"500m\"`  | —                            |\n| `rulebricks.redis.resources.limits.memory`   | string  | `\"4Gi\"`   | Increase for large rule sets |\n| `rulebricks.redis.persistence.enabled`       | boolean | `true`    | Keep enabled for production  |\n| `rulebricks.redis.persistence.size`          | string  | `\"4Gi\"`   | —                            |\n| `rulebricks.redis.persistence.storageClass`  | string  | `\"gp3\"`   | Match your storage class     |\n\n### High Performance Server (HPS)\n\nHPS handles rule execution with horizontal scaling.\n\n| Parameter                         | Type    | Default | Description                    |\n| :-------------------------------- | :------ | :------ | :----------------------------- |\n| `rulebricks.hps.enabled`          | boolean | `true`  | Enable HPS                     |\n| `rulebricks.hps.replicas`         | integer | `3`     | Number of HPS gateway replicas |\n| `rulebricks.hps.workers.enabled`  | boolean | `true`  | Enable worker pods             |\n| `rulebricks.hps.workers.replicas` | integer | `4`     | Base worker replica count      |\n\n#### HPS Image\n\n| Parameter                         | Type   | Default                            | Description             |\n| :-------------------------------- | :----- | :--------------------------------- | :---------------------- |\n| `rulebricks.hps.image.repository` | string | `\"index.docker.io/rulebricks/hps\"` | Docker image repository |\n| `rulebricks.hps.image.tag`        | string | `\"1.X.X\"`                          | Image version tag       |\n| `rulebricks.hps.image.pullPolicy` | string | `\"Always\"`                         | Image pull policy       |\n\n#### HPS Resources\n\n| Parameter                                  | Type   | Default   |\n| :----------------------------------------- | :----- | :-------- |\n| `rulebricks.hps.resources.requests.cpu`    | string | `\"1000m\"` |\n| `rulebricks.hps.resources.requests.memory` | string | `\"1Gi\"`   |\n| `rulebricks.hps.resources.limits.cpu`      | string | `\"2000m\"` |\n| `rulebricks.hps.resources.limits.memory`   | string | `\"2Gi\"`   |\n\n#### KEDA Autoscaling for HPS Workers\n\n| Parameter                                     | Type    | Default | Description                   |\n| :-------------------------------------------- | :------ | :------ | :---------------------------- |\n| `rulebricks.hps.workers.keda.enabled`         | boolean | `true`  | Enable KEDA autoscaling       |\n| `rulebricks.hps.workers.keda.minReplicaCount` | integer | `4`     | Minimum workers               |\n| `rulebricks.hps.workers.keda.maxReplicaCount` | integer | `12`    | Maximum workers               |\n| `rulebricks.hps.workers.keda.pollingInterval` | integer | `10`    | Seconds between metric checks |\n| `rulebricks.hps.workers.keda.cooldownPeriod`  | integer | `300`   | Seconds before scale-down     |\n| `rulebricks.hps.workers.keda.lagThreshold`    | integer | `50`    | Kafka lag threshold           |\n| `rulebricks.hps.workers.keda.cpuThreshold`    | integer | `25`    | CPU percentage threshold      |\n\n**Tuning Recommendations:**\n\n[Code: # High-throughput configuration\n# Replicas should match partitions\nrulebricks:\n  hps:\n    replicas: 4\n    workers:\n      replicas: 8\n      keda:\n        minReplicaCount: 12\n        maxReplicaCount: 32\n        lagThreshold: 5\n        cpuThreshold: 20\n]\n\n## Database (Supabase)\n\n### Self-Hosted vs. Managed\n\n| Mode            | `supabase.enabled` | Use Case                               |\n| :-------------- | :----------------- | :------------------------------------- |\n| Self-hosted     | `true`             | Full control, air-gapped environments  |\n| Managed (Cloud) | `false`            | Simplified operations, managed backups |\n\n### Self-Hosted Configuration\n\n| Parameter                            | Type    | Default                          | Description                 |\n| :----------------------------------- | :------ | :------------------------------- | :-------------------------- |\n| `supabase.enabled`                   | boolean | `true`                           | Deploy self-hosted Supabase |\n| `supabase.secret.db.username`        | string  | `\"postgres\"`                     | Database username           |\n| `supabase.secret.db.password`        | string  | `\"postgres-password-change-me\"`  | **Change this!**            |\n| `supabase.secret.db.database`        | string  | `\"postgres\"`                     | Database name               |\n| `supabase.secret.dashboard.username` | string  | `\"supabase\"`                     | Studio dashboard username   |\n| `supabase.secret.dashboard.password` | string  | `\"dashboard-password-change-me\"` | **Change this!**            |\n\n#### Database Resources\n\n| Parameter                                  | Type    | Default  | Production Recommendation    |\n| :----------------------------------------- | :------ | :------- | :--------------------------- |\n| `supabase.db.resources.requests.cpu`       | string  | `\"500m\"` | `\"1000m\"` or higher          |\n| `supabase.db.resources.requests.memory`    | string  | `\"1Gi\"`  | `\"2Gi\"` or higher            |\n| `supabase.db.persistence.enabled`          | boolean | `true`   | Always `true` for production |\n| `supabase.db.persistence.size`             | string  | `\"10Gi\"` | Based on data volume         |\n| `supabase.db.persistence.storageClassName` | string  | `\"gp3\"`  | Use fast storage             |\n\n### Kong Ingress\n\n| Parameter                         | Type    | Default     | Description                 |\n| :-------------------------------- | :------ | :---------- | :-------------------------- |\n| `supabase.kong.ingress.enabled`   | boolean | `true`      | Enable Supabase API ingress |\n| `supabase.kong.ingress.className` | string  | `\"traefik\"` | Must match Traefik class    |\n\n## Message Queue (Kafka)\n\nKafka handles async rule execution and logging.\n\n### Basic Settings\n\n| Parameter                 | Type    | Default | Description                   |\n| :------------------------ | :------ | :------ | :---------------------------- |\n| `kafka.enabled`           | boolean | `true`  | Deploy Kafka                  |\n| `kafka.kraft.enabled`     | boolean | `true`  | Use KRaft mode (no Zookeeper) |\n| `kafka.zookeeper.enabled` | boolean | `false` | Disable Zookeeper             |\n\n### Controller/Broker Configuration\n\n| Parameter                                    | Type    | Default              | Description           |\n| :------------------------------------------- | :------ | :------------------- | :-------------------- |\n| `kafka.controller.replicaCount`              | integer | `1`                  | Number of Kafka nodes |\n| `kafka.controller.resources.requests.cpu`    | string  | `\"500m\"`             | CPU request           |\n| `kafka.controller.resources.requests.memory` | string  | `\"2Gi\"`              | Memory request        |\n| `kafka.controller.resources.limits.cpu`      | string  | `\"2000m\"`            | CPU limit             |\n| `kafka.controller.resources.limits.memory`   | string  | `\"3Gi\"`              | Memory limit          |\n| `kafka.controller.persistence.size`          | string  | `\"10Gi\"`             | Storage size          |\n| `kafka.controller.heapOpts`                  | string  | `\"-Xmx1g -Xms1g...\"` | JVM heap settings     |\n\n### Kafka Tuning\n\nThe default configuration includes extensive JVM and Kafka tuning:\n\n[Code: kafka:\n  overrideConfiguration:\n    auto.create.topics.enable: 'true'\n    log.retention.hours: '24' # Adjust based on log volume\n    default.replication.factor: '1' # Increase for HA\n    offsets.topic.replication.factor: '1'\n    num.partitions: '12' # Increase for parallelism\n  controller:\n    extraEnvVars:\n      - name: KAFKA_JVM_PERFORMANCE_OPTS\n        value: '-XX:MaxDirectMemorySize=256M -Djdk.nio.maxCachedBufferSize=262144'\n      - name: KAFKA_CFG_QUEUED_MAX_REQUESTS\n        value: '10000'\n      - name: KAFKA_CFG_NUM_NETWORK_THREADS\n        value: '8'\n      - name: KAFKA_CFG_NUM_IO_THREADS\n        value: '8'\n      - name: KAFKA_CFG_SOCKET_SEND_BUFFER_BYTES\n        value: '1048576'\n      - name: KAFKA_CFG_SOCKET_RECEIVE_BUFFER_BYTES\n        value: '1048576'\n      - name: KAFKA_CFG_SOCKET_REQUEST_MAX_BYTES\n        value: '209715200'\n      - name: KAFKA_CFG_LOG_RETENTION_BYTES\n        value: '4294967296'\n      - name: KAFKA_CFG_LOG_SEGMENT_BYTES\n        value: '1073741824'\n      - name: KAFKA_CFG_NUM_REPLICA_FETCHERS\n        value: '4'\n      - name: KAFKA_CFG_REPLICA_SOCKET_RECEIVE_BUFFER_BYTES\n        value: '1048576'\n      - name: KAFKA_CFG_LOG_CLEANER_DEDUPE_BUFFER_SIZE\n        value: '268435456'\n      - name: KAFKA_CFG_LOG_CLEANER_IO_BUFFER_SIZE\n        value: '1048576'\n      - name: KAFKA_CFG_MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION\n        value: '10'\n  listeners:\n    client:\n      protocol: PLAINTEXT\n    controller:\n      protocol: PLAINTEXT\n    interbroker:\n      protocol: PLAINTEXT\n]\n\n**High-Availability Configuration:**\n\n[Code: kafka:\n  controller:\n    replicaCount: 3\n  overrideConfiguration:\n    default.replication.factor: '3'\n    min.insync.replicas: '2'\n]\n\n## Ingress (Traefik)\n\nTraefik handles all incoming traffic and TLS termination.\n\n| Parameter                         | Type    | Default     | Description        |\n| :-------------------------------- | :------ | :---------- | :----------------- |\n| `traefik.enabled`                 | boolean | `true`      | Deploy Traefik     |\n| `traefik.ingressClass.name`       | string  | `\"traefik\"` | Ingress class name |\n| `traefik.autoscaling.enabled`     | boolean | `true`      | Enable HPA         |\n| `traefik.autoscaling.minReplicas` | integer | `1`         | Minimum replicas   |\n| `traefik.autoscaling.maxReplicas` | integer | `2`         | Maximum replicas   |\n\n### Resources\n\n| Parameter                           | Type   | Default   | High-Traffic |\n| :---------------------------------- | :----- | :-------- | :----------- |\n| `traefik.resources.requests.cpu`    | string | `\"100m\"`  | `\"500m\"`     |\n| `traefik.resources.requests.memory` | string | `\"256Mi\"` | `\"512Mi\"`    |\n| `traefik.resources.limits.cpu`      | string | `\"1000m\"` | `\"2000m\"`    |\n| `traefik.resources.limits.memory`   | string | `\"2Gi\"`   | `\"4Gi\"`      |\n\n### Ports\n\n| Parameter                             | Default | Description         |\n| :------------------------------------ | :------ | :------------------ |\n| `traefik.ports.web.port`              | `8000`  | Internal HTTP port  |\n| `traefik.ports.web.exposedPort`       | `80`    | External HTTP port  |\n| `traefik.ports.websecure.port`        | `8443`  | Internal HTTPS port |\n| `traefik.ports.websecure.exposedPort` | `443`   | External HTTPS port |\n\n### Persistence\n\n| Parameter                     | Type    | Default | Description        |\n| :---------------------------- | :------ | :------ | :----------------- |\n| `traefik.persistence.enabled` | boolean | `false` | Enable persistence |\n\n## Autoscaling (KEDA)\n\nKEDA provides event-driven autoscaling for HPS workers.\n\n| Parameter           | Type    | Default | Description                  |\n| :------------------ | :------ | :------ | :--------------------------- |\n| `keda.enabled`      | boolean | `true`  | Deploy KEDA                  |\n| `keda.crds.install` | boolean | `false` | CRDs managed by parent chart |\n\n## Certificates (cert-manager)\n\ncert-manager provisions TLS certificates from Let's Encrypt.\n\n| Parameter                  | Type    | Default | Description                  |\n| :------------------------- | :------ | :------ | :--------------------------- |\n| `cert-manager.enabled`     | boolean | `true`  | Deploy cert-manager          |\n| `cert-manager.installCRDs` | boolean | `false` | CRDs managed by parent chart |\n\nThe chart creates:\n\n- A `ClusterIssuer` for Let's Encrypt production\n- `Certificate` resources for your domain(s)\n\n## Logging (Vector)\n\nVector aggregates logs from Kafka and forwards them to configured sinks.\n\n| Parameter         | Type    | Default                  | Description        |\n| :---------------- | :------ | :----------------------- | :----------------- |\n| `vector.enabled`  | boolean | `true`                   | Deploy Vector      |\n| `vector.role`     | string  | `\"Stateless-Aggregator\"` | Vector role        |\n| `vector.replicas` | integer | `2`                      | Number of replicas |\n\n### Resources\n\n| Parameter                          | Type   | Default   |\n| :--------------------------------- | :----- | :-------- |\n| `vector.resources.requests.cpu`    | string | `\"50m\"`   |\n| `vector.resources.requests.memory` | string | `\"128Mi\"` |\n| `vector.resources.limits.cpu`      | string | `\"200m\"`  |\n| `vector.resources.limits.memory`   | string | `\"256Mi\"` |\n\n### Service\n\n| Parameter                | Type    | Default   | Description           |\n| :----------------------- | :------ | :-------- | :-------------------- |\n| `vector.service.enabled` | boolean | `true`    | Enable Vector service |\n| `vector.service.ports`   | list    | `[]` | Service ports         |\n\n### Environment Variables\n\n| Parameter    | Type | Default   | Description                                           |\n| :----------- | :--- | :-------- | :---------------------------------------------------- |\n| `vector.env` | list | `[]` | Environment variables (e.g., KAFKA_BOOTSTRAP_SERVERS) |\n\n### Custom Sinks\n\nConfigure log destinations in `vector.customConfig.sinks`:\n\n[Code: vector:\n  customConfig:\n    sources:\n      kafka:\n        type: kafka\n        bootstrap_servers: '$'\n        topics:\n          - logs\n        group_id: vector-consumers\n        auto_offset_reset: latest\n    sinks:\n      # Console output (default)\n      console:\n        type: console\n        inputs: [kafka]\n        encoding:\n          codec: json\n\n      # S3 sink example\n      s3:\n        type: aws_s3\n        inputs: [kafka]\n        bucket: 'your-logs-bucket'\n        region: 'us-east-1'\n        key_prefix: 'rulebricks/logs/%Y/%m/%d/'\n        compression: gzip\n        encoding:\n          codec: json\n]\n\n## DNS (external-dns)\n\nexternal-dns automatically creates DNS records for your ingresses.\n\n| Parameter                    | Type    | Default         | Description                  |\n| :--------------------------- | :------ | :-------------- | :--------------------------- |\n| `external-dns.enabled`       | boolean | `false`         | Deploy external-dns          |\n| `external-dns.provider`      | string  | `\"route53\"`     | DNS provider                 |\n| `external-dns.sources`       | list    | `[\"ingress\"]`   | Resource types to watch      |\n| `external-dns.domainFilters` | list    | `[]`            | Restrict to specific domains |\n| `external-dns.policy`        | string  | `\"upsert-only\"` | Record management policy     |\n\n### Provider Configuration\n\n#### AWS Route53\n\n[Code: external-dns:\n  enabled: true\n  provider: route53\n  # Uses IRSA - ensure service account has Route53 permissions\n]\n\n#### Cloudflare\n\n[Code: external-dns:\n  enabled: true\n  provider: cloudflare\n  extraEnvVars:\n    - name: CF_API_TOKEN\n      valueFrom:\n        secretKeyRef:\n          name: cloudflare-api-token\n          key: api-token\n]\n\n#### Google Cloud DNS\n\n[Code: external-dns:\n  enabled: true\n  provider: google\n  google:\n    project: 'your-gcp-project'\n]\n\n#### Azure DNS\n\n[Code: external-dns:\n  enabled: true\n  provider: azure\n  azure:\n    resourceGroup: 'your-resource-group'\n    subscriptionId: 'your-subscription-id'\n]\n\n## Monitoring (Prometheus)\n\nOptional Prometheus stack for metrics collection.\n\n| Parameter                                    | Type    | Default | Description         |\n| :------------------------------------------- | :------ | :------ | :------------------ |\n| `monitoring.enabled`                         | boolean | `false` | Enable monitoring   |\n| `kube-prometheus-stack.alertmanager.enabled` | boolean | `false` | Deploy Alertmanager |\n| `kube-prometheus-stack.grafana.enabled`      | boolean | `false` | Deploy Grafana      |\n\n### Prometheus Storage\n\n[Code: kube-prometheus-stack:\n  prometheus:\n    prometheusSpec:\n      retention: 30d\n      storageSpec:\n        volumeClaimTemplate:\n          spec:\n            storageClassName: gp3\n            resources:\n              requests:\n                storage: 50Gi\n]\n\n## Storage\n\n### StorageClass\n\nThe chart can create a gp3 StorageClass for AWS EBS:\n\n| Parameter                           | Type    | Default                  | Description         |\n| :---------------------------------- | :------ | :----------------------- | :------------------ |\n| `storageClass.create`               | boolean | `true`                   | Create StorageClass |\n| `storageClass.name`                 | string  | `\"gp3\"`                  | StorageClass name   |\n| `storageClass.provisioner`          | string  | `\"ebs.csi.aws.com\"`      | CSI provisioner     |\n| `storageClass.type`                 | string  | `\"gp3\"`                  | EBS volume type     |\n| `storageClass.fsType`               | string  | `\"ext4\"`                 | File system type    |\n| `storageClass.reclaimPolicy`        | string  | `\"Delete\"`               | Reclaim policy      |\n| `storageClass.volumeBindingMode`    | string  | `\"WaitForFirstConsumer\"` | Binding mode        |\n| `storageClass.allowVolumeExpansion` | boolean | `true`                   | Allow expansion     |\n\nFor non-AWS clusters, set `storageClass.create: false` and ensure a compatible StorageClass exists."
  },
  {
    "title": "values.yaml",
    "description": "This guide covers common deployment patterns and the minimum configuration values you need to provide for various Rulebricks deployment scenarios.",
    "path": "/private-deployment/deployment",
    "content": "## Deployment Modes\n\nThis guide describes the minimum configuration values you need to provide to deploy Rulebricks.\n\n### Quick Start (Development/Testing)\n\nMinimal configuration for evaluation purposes. Self-hosts Supabase.\n\n[Code: # values.yaml\nglobal:\n  domain: '<domain-you-control.com>\n  email: '<valid-email>'\n  licenseKey: '<valid-license-key>'\n  smtp:\n    <valid-information>\n\n# Everything else uses defaults\n]\n\n[Code: helm install rulebricks oci://ghcr.io/rulebricks/charts/stack \\\n  --namespace rulebricks \\\n  --create-namespace \\\n  -f dev-values.yaml\n]\n\n### Production with Supabase Cloud\n\nAutomatic DNS, external database.\n\n[Code: # production-values.yaml\nglobal:\n  domain: '<domain-you-control.com>\n  email: '<valid-email>'\n  licenseKey: '<valid-license-key>'\n  tlsEnabled: true\n  externalDnsEnabled: true\n\n  smtp:\n    <valid-information>\n\n  supabase:\n    url: 'https://abcd1234.supabase.co'\n    projectRef: 'abcd1234'\n    anonKey: 'from-supabase-dashboard'\n    serviceKey: 'from-supabase-dashboard'\n    # Account > Settings > Access Tokens\n    accessToken: '$'\n\nsupabase:\n  enabled: false # Don't deploy self-hosted\n\n# Ensure this is configured properly\nexternal-dns:\n  enabled: true\n  provider: route53\n]\n\n## Cloud-Specific Values\n\n### AWS EKS\n\n[Code: # AWS-specific settings\nstorageClass:\n  create: true\n  provisioner: ebs.csi.aws.com\n  type: gp3\n\nexternal-dns:\n  enabled: true\n  provider: route53\n  # Uses IRSA - create IAM role and service account\n# Recommended: Use IRSA for all AWS integrations\n# eksctl create iamserviceaccount ...\n]\n\n**Prerequisites:**\n\n- EBS CSI driver installed\n- IRSA configured for external-dns and Vector (if using S3)\n- ALB/NLB annotations if not using Traefik\n\n### Google GKE\n\n[Code: storageClass:\n  create: true\n  provisioner: pd.csi.storage.gke.io\n  type: pd-ssd\n\nexternal-dns:\n  enabled: true\n  provider: google\n  google:\n    project: 'your-gcp-project'\n# GKE uses Workload Identity\n# Annotate service accounts accordingly\n]\n\n### Azure AKS\n\n[Code: storageClass:\n  create: true\n  provisioner: disk.csi.azure.com\n  type: Premium_LRS\n\nexternal-dns:\n  enabled: true\n  provider: azure\n  azure:\n    resourceGroup: 'your-resource-group'\n    subscriptionId: 'your-subscription-id'\n]\n\n## Uninstallation\n\n[Code: # Remove release (keeps PVCs)\nhelm uninstall rulebricks -n rulebricks\n\n# Full cleanup including data\nhelm uninstall rulebricks -n rulebricks\nkubectl delete pvc --all -n rulebricks\nkubectl delete namespace rulebricks\n]"
  },
  {
    "title": "1. Create your values file (see Configuration below)",
    "description": "Deploy Rulebricks to your Kubernetes cluster using our official Helm charts.",
    "path": "/private-deployment/quick-start",
    "content": "![Rulebricks Cloud Banner](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/private-deployment/rb-cloud-banner.png)\n\nOur unified Helm chart deploys Rulebricks and all its dependencies to your Kubernetes cluster in a single command. You'll need:\n\n- **Kubernetes 1.19+** (EKS, GKE, AKS, or self-managed)\n- **Helm 3.2.0+**\n- **kubectl** configured for your cluster\n- A **domain name** you control\n\n### Quick Start\n\n[Code: # 1. Create your values file (see Configuration below)\n# 2. Install the chart\nhelm install rulebricks oci://ghcr.io/rulebricks/charts/stack \\\n  --namespace rulebricks \\\n  --create-namespace \\\n  -f your-values.yaml\n\n# 3. Follow the on-screen instructions for DNS setup\n# 4. Enable TLS once DNS is configured\nhelm upgrade rulebricks oci://ghcr.io/rulebricks/charts/stack \\\n  --namespace rulebricks \\\n  --reuse-values \\\n  --set global.tlsEnabled=true\n]\n\n### Single-Phase Installation (with external-dns)\n\nIf you're on AWS, GCP, or Azure and want fully automated DNS:\n\n[Code: helm install rulebricks oci://ghcr.io/rulebricks/charts/stack \\\n  --namespace rulebricks \\\n  --create-namespace \\\n  -f your-values.yaml \\\n  --set external-dns.enabled=true \\\n  --set global.externalDnsEnabled=true \\\n  --set global.tlsEnabled=true\n]\n\nSee [Deployment Modes](/private-deployment/deployment) for minimal configurations required for different deployment scenarios, and visit [Configuration Reference](/private-deployment/configuration-reference) for a complete breakdown of all available options in `values.yaml`.\n\n---\n\n## What am I deploying?\n\nYou're deploying a complete Rulebricks stack to your existing Kubernetes cluster. The chart installs multiple integrated services, pre-configured for production workloads.\n\n[Code: flowchart TD\n    LB(\"Load Balancer<br/>Cloud Provider LB\") --> Traefik(\"Traefik Ingress<br/>TLS Termination & Routing\")\n\n    Traefik --> RB(\"Rulebricks App<br/>API & Management\")\n    Traefik -.-> SB(\"Supabase Dashboard<br/>Optional Admin UI\")\n    Traefik -.-> GF(\"Grafana Dashboard<br/>Optional Monitoring\")\n\n    RB --> Redis[(\"Redis<br/>Cache Layer\")]\n    RB --> PG[(\"PostgreSQL<br/>Primary Database\")]\n    Redis -.->|\"Cache miss<br/>fallback\"| PG\n    SB -.-> PG\n\n    %% Rule execution flow\n    RB -->|\"Rule Execution<br/>Requests\"| Kafka(\"Kafka Cluster<br/>Event Streaming & Job Queue\")\n\n    %% Worker scaling and execution\n    KEDA(\"KEDA<br/>Auto Scaler\") -.->|\"Scales based on<br/>Kafka queue depth\"| WorkerPool\n\n    subgraph WorkerPool [\" \"]\n        direction LR\n        W1(\"Worker 1<br/>Rule Executor\")\n        W2(\"Worker 2<br/>Rule Executor\")\n        W3(\"Worker N<br/>Rule Executor\")\n    end\n\n    Kafka -->|\"Consumes execution<br/>requests\"| WorkerPool\n\n    %% Logging flows\n    RB -->|\"Rule execution<br/>logs & metrics\"| Vector(\"Vector<br/>Log Processing & Forwarding\")\n    Kafka -->|\"Event logs<br/>(with lag)\"| Vector\n\n    %% Simplified sinks\n    Vector --> Sinks(\"External Log Sinks<br/>S3, Elasticsearch, Datadog, etc.\")\n\n    %% Styling\n    classDef primary fill:#e3f2fd,stroke:#1976d2,stroke-width:3px,color:#000\n    classDef secondary fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000\n    classDef storage fill:#e8f5e8,stroke:#388e3c,stroke-width:2px,color:#000\n    classDef processing fill:#fff8e1,stroke:#f57c00,stroke-width:2px,color:#000\n    classDef scaling fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:#000\n    classDef optional stroke-dasharray: 5 5,color:#fff\n\n    class LB,Traefik primary\n    class RB secondary\n    class PG,Redis,Kafka,Sinks storage\n    class WorkerPool,W1,W2,W3,Vector processing\n    class KEDA scaling\n    class SB,GF optional\n]\n\n### Components Deployed\n\n| Component        | Purpose                                      | Enabled by Default |\n| :--------------- | :------------------------------------------- | :----------------: |\n| **Rulebricks**   | Core application and high-performance solver |         ✓          |\n| **Supabase**     | PostgreSQL database and authentication       |         ✓          |\n| **Kafka**        | Message queue for async rule execution       |         ✓          |\n| **Traefik**      | Ingress controller with automatic TLS        |         ✓          |\n| **cert-manager** | Let's Encrypt certificate provisioning       |         ✓          |\n| **KEDA**         | Event-driven autoscaling for workers         |         ✓          |\n| **Vector**       | Log aggregation and forwarding               |         ✓          |\n| **external-dns** | Automatic DNS record management              |         ✗          |\n| **Prometheus**   | Metrics collection and alerting              |         ✗          |\n\n### Database Options\n\n**Self-hosted (default):** PostgreSQL runs in your cluster with persistent storage. You have full control and data never leaves your infrastructure.\n\n**Managed Supabase:** Use Supabase Cloud instead. Set `supabase.enabled: false` and provide your project credentials. The chart automatically configures your managed project.\n\n---\n\n## Troubleshooting\n\n[Code: # Check pod status\nkubectl get pods -n rulebricks\n\n# View events for issues\nkubectl get events -n rulebricks --sort-by='.lastTimestamp'\n\n# Check specific component logs\nkubectl logs -n rulebricks -l app.kubernetes.io/name=rulebricks --tail=100\n\n# Check migration job status\nkubectl get jobs -n rulebricks\nkubectl logs job/rulebricks-db-migrate-1 -n rulebricks\n]\n\n### Common Issues\n\n**Pods stuck in Pending:**\n\n- Check node resources: `kubectl describe nodes`\n- Verify StorageClass exists: `kubectl get storageclass`\n\n**Certificate not issuing:**\n\n- Verify DNS resolves to your LoadBalancer\n- Check cert-manager logs: `kubectl logs -n cert-manager -l app=cert-manager`\n- View certificate status: `kubectl describe certificate -n rulebricks`\n\n**Database connection errors:**\n\n- Wait for PostgreSQL to be ready (can take 2-3 minutes)\n- Check database pod: `kubectl logs -n rulebricks -l app.kubernetes.io/name=supabase-db`\n\n### Clean Reinstall\n\n[Code: # Uninstall and clean up\nhelm uninstall rulebricks -n rulebricks\nkubectl delete pvc --all -n rulebricks\n\n# Reinstall\nhelm install rulebricks oci://ghcr.io/rulebricks/charts/stack \\\n  --namespace rulebricks \\\n  -f your-values.yaml\n]\n\n---\n\n## Caveats & Limits\n\n### Cluster Requirements\n\nThe Helm chart deploys to your **existing** Kubernetes cluster. You're responsible for:\n\n- Cluster provisioning and scaling\n- Node pool configuration\n- Storage provisioner (e.g., AWS EBS CSI driver)\n- Network policies and security\n\nSee [example-min-cluster.yaml](https://github.com/rulebricks/helm/blob/main/example-min-cluster.yaml) for minimum EKS cluster specifications.\n\n### Air-Gapped Deployments\n\nRulebricks can run nearly air-gapped with these exceptions:\n\n| Feature          | External Dependency       | Can Disable?                       |\n| :--------------- | :------------------------ | :--------------------------------- |\n| Managed Supabase | Supabase Cloud API        | Yes—use self-hosted                |\n| AI Features      | OpenAI API                | Yes—set `global.ai.enabled: false` |\n| Log Forwarding   | External sinks (S3, etc.) | Yes—use console sink only          |\n| TLS Certificates | Let's Encrypt             | Yes—bring your own certs           |\n| Fonts            | Google Fonts              | Requires customization             |\n| Analytics        | Sentry                    | Requires customization             |\n\n### Installing Updates\n\nRule engines usually take critical roles, so we don't release updates continuously. We make upgrades easy with zero downtime, but you control when they happen:\n\nFirst, visit our [Changelog](/changelog), and find the `rulebricks/app` tag containing the fixes/features you need in your upgrade.\n\nThen, edit `rulebricks.app.image.tag` in your `values.yaml` file accordingly.\n\nFinally, run:\n\n[Code: # Upgrade to latest version\nhelm upgrade rulebricks oci://ghcr.io/rulebricks/charts/stack \\\n  --namespace rulebricks \\\n  -f your-values.yaml\n]"
  },
  {
    "title": "Releases in Rulebricks",
    "description": "Structured version-controlled deployments for your Rulebricks rules and flows. Learn how releases separate development from production deployment.",
    "path": "/releases",
    "content": "# Releases in Rulebricks\n\nBuilding business logic is only half the story. The rules and flows you create in Rulebricks represent critical decision-making processes—pricing calculations, eligibility checks, fraud detection, compliance validation—that drive real outcomes in your applications. But between the moment you finish building a rule and the moment it starts serving production traffic, there exists a gap that many teams overlook until it becomes a problem.\n\nReleases in Rulebricks enable structured, version-controlled deployments for your rules and flows.\n\nRather than having changes take effect the moment you click \"publish,\" Releases creates a deliberate separation between ongoing development work and production deployments.\n\n## The Releases Tab\n\nWhen you navigate to the Releases tab in your Rulebricks workspace, you encounter a unified view of your deployment landscape. The interface organizes your assets—both rules and flows—into two distinct categories that reflect their current deployment status.\n\n![The Releases tab provides a central view of pending and active releases across your environments](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/releases/releases-tab-entry.png)\n\nAt the top of the screen, you can toggle between viewing rules and flows, and filter by environment using the dropdown selector. This environment-centric view is intentional: rather than asking \"what state is this rule in?\" you ask \"what is deployed to staging?\" or \"what is live in production?\" This subtle shift in perspective mirrors how operations teams actually think about deployments.\n\nThe interface divides releases into two sections. The Pending section shows releases that have been requested but not yet approved—these represent changes that are in flight, awaiting review before they go live. Below that, the Releases section displays assets that have successfully been released to the selected environment, showing you exactly what version is currently active and when it was deployed."
  },
  {
    "title": "Creating and Managing Releases",
    "description": "Learn how to create, approve, and promote releases in Rulebricks. Manage the complete release lifecycle from staging to production.",
    "path": "/releases/creating-and-managing-releases",
    "content": "# Creating and Managing Releases\n\nWith environments configured, you can begin the actual work of releasing your business logic. A release in Rulebricks represents a specific version of a rule or flow that has been tagged for deployment to a particular environment. Creating a release does not immediately deploy anything—instead, it opens a request that must be approved before the release becomes active. This two-step process separates the intent to deploy from the actual deployment, creating space for review and validation.\n\n## Starting a New Release\n\n## Navigating Releases by Environment\n\nThe Releases tab organizes everything by environment because that is how most teams think about deployments. When you select an environment from the dropdown, the view updates to show only releases relevant to that specific deployment target.\n\n![Filtering releases by environment helps you focus on what matters for each deployment target](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/releases/select-release-environment.png)\n\nThe pending section shows releases that have been created but not yet approved. Each pending release displays key information: the asset name, the version number, when the release was opened, how many approvals are still needed, and how many comments have been added. This at-a-glance view helps you quickly identify which releases need attention and their current status in the approval workflow.\n\nBelow the pending releases, the released section shows assets that have been successfully deployed to this environment. Each entry indicates the version that is currently active and confirms that the release is live. This serves as a source of truth for what is actually running in each environment.\n\n## The Approval Workflow\n\nWhen you open a pending release, you enter the detailed view where the actual approval workflow takes place. This screen presents all the information approvers need to make an informed decision, along with tools for collaboration and action.\n\n![The release detail view shows approval status, the release asset, and a collaborative activity feed](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/releases/comment-markdown.png)\n\nThe header area displays the current approval status—\"Pending Approval\" for releases still awaiting sign-off, or \"Released\" for approved deployments. Action buttons allow approvers to approve the release, update the version target if needed, or cancel the release entirely if circumstances have changed.\n\nThe approval status panel shows who has approved the release and who is still pending. The scheme indicator reminds everyone whether a single approval is sufficient or if all designated approvers must sign off. As approvals come in, the panel updates in real time, providing clear visibility into how close the release is to going live.\n\nThe release asset section shows exactly what is being released—the rule or flow card displays the same information you would see in the Rules or Flows tab, making it easy to review what this release contains without navigating away. You can click through to view the full rule details if needed.\n\nThe activity feed on the right captures the complete history of the release: when it was created, who commented, what notes were added, and when approvals were given. Comments support rich formatting and mentions, allowing you to tag specific team members for input or flag concerns that need addressing before approval.\n\n## Promoting Releases\n\nOnce a release has been approved in one environment, you may want to advance it to the next stage of your deployment pipeline. Rather than creating a new release from scratch, you can promote the existing release to a higher-level environment. This action preserves the connection between the releases, making it clear that what is running in production came from what was tested in staging.\n\nThe promoted release still requires approval according to the target environment's configuration, ensuring that each stage maintains its own governance."
  },
  {
    "title": "Notifications and Collaboration",
    "description": "Configure release notifications in Rulebricks via email, Slack, Discord, or webhooks. Keep your team informed about pending approvals and deployments.",
    "path": "/releases/notifications-and-collaboration",
    "content": "# Notifications and Collaboration\n\nA release workflow is only as effective as the team's awareness of it. The best-designed approval process fails if approvers do not know releases are waiting for their attention, or if stakeholders learn about deployments only after something goes wrong. Rulebricks addresses this through configurable notifications that keep your team informed at the moments that matter, without overwhelming them with noise.\n\n## Configuring Notifications for Each Environment\n\nNotification settings are configured per environment, recognizing that different deployment stages warrant different levels of attention. A staging environment might need minimal notifications since changes there are routine, while production releases might warrant immediate alerts across multiple channels.\n\nTo configure notifications, open the Release Environments modal and locate the notifications column. Each environment shows a bell icon that indicates whether notifications are enabled. Clicking this icon opens the notification configuration for that specific environment.\n\n![Each environment has its own notification settings, accessible from the environments list](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/releases/setup-release-notifications-1.png)\n\nThe notifications button appears alongside other environment properties, making it easy to audit which environments have alerting configured and which do not. This visibility helps ensure that your production environment does not accidentally go unmonitored while less critical environments have elaborate notification setups.\n\n## Choosing What to Notify On\n\nThe notification settings screen presents two dimensions of configuration: which events trigger notifications, and which channels receive them. The events tab lets you toggle notifications for each type of release activity, giving you fine-grained control over what your team hears about.\n\n![The events tab allows you to enable or disable notifications for specific release activities](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/releases/release-events.png)\n\nThe available events cover the complete release lifecycle:\n\n| Event                      | Description                                                                                                                   |\n| -------------------------- | ----------------------------------------------------------------------------------------------------------------------------- |\n| **Release Created**        | Fires when someone opens a new release request, alerting approvers that their attention is needed                             |\n| **Release Commented**      | Notifies when discussion happens on a release, keeping everyone aware of the conversation                                     |\n| **Release Updated**        | Triggers when someone changes the version target of an existing release                                                       |\n| **Release Cancelled**      | Notifies when a release is cancelled                                                                                          |\n| **Release Approved**       | Notifies when an approver gives their approval                                                                                |\n| **Release Fully Approved** | Fires when a release meets all approval requirements and goes live—the moment when API traffic begins serving the new version |\n\nThe **direct mentions** setting deserves special attention. When enabled, team members who are mentioned in release comments receive email notifications about that specific mention. This creates a lightweight way to pull someone into a discussion without adding them as a formal approver or sending notifications about every release event.\n\n## Notification Channels\n\nThe channels tab determines how notifications reach your team. Rulebricks supports multiple delivery mechanisms, and you can enable any combination that fits your workflow.\n\n**Email notifications** go directly to specified addresses. You can add individual recipients or quickly add all environment approvers with a single click. Email works well for ensuring notifications reach people even when they are not monitoring real-time communication tools.\n\n**Slack and Discord integrations** allow notifications to flow into your team's existing communication channels. By providing a webhook URL for your Slack or Discord workspace, release events can post messages directly to a dedicated channel. This keeps release activity visible alongside other team discussions and makes it easy to react quickly without context-switching to the Rulebricks interface.\n\n**Custom webhooks** provide maximum flexibility for teams with existing notification infrastructure or specialized requirements. Any URL that can receive a POST request with release event data can be configured as a notification destination, enabling integration with paging systems, custom dashboards, or internal tools."
  },
  {
    "title": "Release URLs and API Access",
    "description": "Understand the difference between Preview URLs and Release URLs in Rulebricks API. Learn integration patterns for production and staging environments.",
    "path": "/releases/release-urls-and-api-access",
    "content": "# Release URLs and API Access\n\nThe practical integration of releases into your applications comes down to URLs. When you call a rule or flow via the Rulebricks API, the URL you use determines which version of the logic gets executed. Understanding the distinction between preview URLs and release URLs is essential for building robust applications that take full advantage of the release system.\n\n## Two Ways to Access Your Rules\n\nEvery rule and flow in Rulebricks can be accessed through the API using two different URL patterns. The first pattern uses a version number at the end of the URL, directly targeting a specific published version. The second pattern uses an environment slug, which dynamically resolves to whatever version is currently released in that environment.\n\nWhen you view a pending release, both URL patterns are displayed together, making the distinction clear.\n\n![A pending release shows both the Preview URL (version-specific) and Release URL (environment-specific)](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/releases/release-url-zoom-in.png)\n\nThe **Preview URL** follows the pattern `/api/v1/solve//`. This URL always returns results from the exact version you specify, regardless of what has been released. It provides a stable, predictable endpoint that never changes behavior unless you explicitly change the version number in the URL. Use this URL for testing specific versions or when you need guaranteed consistency.\n\nThe **Release URL** follows the pattern `/api/v1/solve//`. This URL resolves to whatever version is currently active in the specified environment. When you approve a new release, the Release URL automatically starts serving the newly released version without any changes to your application code. This dynamic resolution is what makes releases powerful—your production systems can point to the release URL, and deployments happen by approving releases rather than updating configurations.\n\n## Before and After Approval\n\nThe relationship between these URLs and the approval workflow is where releases provide their real value. Before a release is approved, the Release URL still points to the previous released version—or returns an error if nothing has ever been released to that environment. The pending release exists in a preparatory state, visible in the Rulebricks interface but not yet affecting API traffic.\n\nOnce the release is approved, the situation changes. The Release URL now resolves to the newly approved version, and the status indicator turns green.\n\n![After approval, the Release URL actively serves the released version](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/releases/released-url-zoom-in.png)\n\nThe green confirmation message—\"This endpoint is active and can be used in production\"—signals that this version is now live. Any API call to the Release URL will execute this version of the rule. The transition from pending to released happens atomically when the final required approval is given, ensuring there is no ambiguous intermediate state.\n\n## Practical Integration Patterns\n\nThough quite simple, understanding these URL patterns genuinely enables several familiar integration strategies:\n\n**Production systems with controlled updates:** Configure your application to use the Release URL. Your code always calls the same endpoint, and updates happen through the approval workflow rather than code deployments. This separation means you can update business logic without touching your application infrastructure.\n\n**Staging and testing environments:** Use the Preview URL to pin to a specific version while you validate behavior. This ensures your tests run against known logic even if someone approves a new release while your test suite is executing.\n\n**Multi-environment applications:** Some teams use different Release URLs for different parts of their application. A customer-facing pricing service might call the production Release URL, while an internal analytics pipeline calls the staging Release URL. Both are calling the same rule, but they receive different versions based on what has been released to each environment.\n\n**Emergency rollback:** The version-specific Preview URL also serves as a safety mechanism. If something goes wrong with a newly released version, you can temporarily point critical systems to the Preview URL of the previous version while you investigate. This provides an immediate escape hatch that does not require rushing through a new release approval."
  },
  {
    "title": "Setting Up Environments",
    "description": "Configure release environments in Rulebricks to define deployment targets, approval workflows, and promotion hierarchies for your rules and flows.",
    "path": "/releases/setting-up-environments",
    "content": "# Setting Up Environments\n\nBefore you can begin releasing rules and flows, you need to define the environments through which your changes will travel. An environment in Rulebricks represents a deployment target—a conceptual space like \"staging\" or \"production\" where a particular version of your business logic will run. The configuration of these environments determines not just where releases can go, but how they get there and who has the authority to approve them.\n\nThe design of your environment structure should reflect your organization's actual deployment practices. A small team might operate with a simple two-environment setup: a staging environment for testing and a production environment for live traffic. Larger organizations often require more nuanced hierarchies, perhaps with multiple staging environments for different testing purposes, or regional production environments that receive releases at different times.\n\n## Creating Your First Environment\n\nTo configure environments, click the \"Release Environments\" button in the Releases tab. This opens a modal where you can view existing environments and create new ones. The environment list displays key information at a glance: the environment name, its level in the promotion hierarchy, the number of designated approvers, the approval scheme, and whether notifications are configured.\n\n![The environments modal displays all configured environments with their levels, approvers, and approval schemes](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/releases/new-environment-modal.png)\n\nWhen creating or editing an environment, you define several critical properties. The environment name serves as its identifier throughout the system—choose something meaningful like \"Staging\" or \"Production EU\" rather than cryptic abbreviations. The description field allows you to document the environment's purpose and its place in your release workflow, which proves invaluable when onboarding new team members or auditing your processes months later.\n\n## Understanding Environment Levels\n\nThe level setting deserves particular attention because it governs the promotion path for your releases. Environments with lower level numbers are considered earlier in the release pipeline, and releases can only be promoted from a lower level to the next higher level. This constraint is intentional: it prevents releases from skipping stages in your workflow, ensuring that every change passes through the appropriate validation steps before reaching production.\n\n![Environment configuration showing level settings and approver selection](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/releases/environment-levels-important.png)\n\nConsider a typical three-environment setup. Your staging environment might be level 1, a pre-production environment level 2, and production level 3. A release created in staging cannot jump directly to production—it must first be promoted to pre-production, approved there, and only then can it advance to production. This sequential progression creates natural checkpoints where your team can validate changes before they move closer to live traffic.\n\nYou can also have multiple environments at the same level. This is useful when you have parallel deployment targets, such as regional production environments or multiple staging environments for different feature teams. Releases from a lower-level environment can be promoted to any environment at the next level, giving you flexibility while maintaining the overall progression structure.\n\n## Configuring Approvers and Approval Schemes\n\nEach environment requires at least one approver—a team member authorized to approve releases into that environment. The approvers you designate should align with who has responsibility for changes reaching that stage of deployment. Your staging environment might allow any developer to approve releases, while production might require sign-off from a senior engineer or technical lead.\n\nThe approval scheme determines how many approvers must give their consent before a release goes live. With the \"Any approver\" scheme, a single approval from any designated approver is sufficient. The \"All approvers\" scheme requires every designated approver to provide explicit approval. Choose based on the risk profile of each environment: staging might use \"any approver\" for agility, while production might require consensus from all approvers for safety."
  },
  {
    "title": "Service Level Agreement",
    "description": "Rulebricks offers a common SLA with varying minimum response and resolution times for two levels of issues– low, and high severity. Learn more about this agreement here.",
    "path": "/security/service-level-agreement",
    "content": "## 🤝  SLA\n\nRulebricks offers a common SLA with varying minimum response and resolution times for two levels of issues: low, and high severity.\n\nWe define \"high severity\" issues as bugs/errors that prevent the development and correct execution of rule or flow assets on our platform, directly impeding your team from gaining value from our software.\n\n#### **Low Severity**\n\n- 48 hour maximum response time\n- 10 day resolution time\n\n#### **High Severity**\n\n- 24 hour maximum response time\n- 3 day resolution time\n\nIf Rulebricks breaks the SLA in two consecutive months or over three months in any 12-month period, then Customer may, as its only remedy, terminate this Order Form upon notice and receive a prorated refund of prepaid fees for the remainder of the Subscription Period.\n\n## Pricing\n\nIn addition to the public cloud plans we offer on our pricing page [here](https://rulebricks.com/pricing), we also offer an enterprise-level plan for customers with extensive needs for Rulebricks.\n\n#### Unlimited execution-volume Enterprise\n\nThere is an additional plan available for Rulebricks Enterprise customers that wish to privately deploy our rule engine and have maximum flexibility while doing so. This plan includes a dedicated account manager, custom SLA, and a 24/7 support line for $1000 **per deployment, per month**, and no limits of any kind on rule executions. Please note that each **deployment** adds capacity for 20 new users and flows, either to an existing instance of Rulebricks you are hosting, or a new one. If you are interested in this plan, please schedule a demo with us.\n\n---\n\nWe have a CommonPaper (https://commonpaper.com/) Cloud Services Agreement template for Rulebricks containing what you see on this page you may request access to for closer review should you wish to move forward."
  },
  {
    "title": "Rulebricks Subprocessors",
    "description": "Rulebricks subprocessors are third-party services that Rulebricks uses to provide its core functionality. Learn more about them here.",
    "path": "/security/subprocessor-list",
    "content": "# Rulebricks Subprocessors\n\n| Subprocessor | Technology             | Description                                                                                                                                                                                                                 | Website                          |\n| ------------ | ---------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------- |\n| Vercel (AWS) | Hosting & Edge Caching | Provides cloud hosting and edge caching services. Vercel is used for hosting the Next.js application, which includes React and Node.js environments. They also manage the Edge Cache to enhance content delivery speeds.    | [Vercel](https://vercel.com)     |\n| Supabase     | Cloud Database         | Acts as a backend service. Supabase offers a PostgreSQL database service, authentication, real-time subscriptions, and storage capabilities. It is used to manage and store all the application data in the cloud securely. | [Supabase](https://supabase.com) |\n| Upstash      | Redis Cache            | Provides managed Redis services. Upstash is used for caching frequently accessed data to reduce latency and improve the performance of database operations.                                                                 | [Upstash](https://upstash.com)   |\n\n## Details\n\n- **Next.js**: A React framework that enables server-side rendering and static site generation, which is hosted on Vercel. _Region – Vercel – IAD1 (Washington, D.C.)_\n- **Node 22**: Handles all server-side logic.\n- **Vercel Edge Cache**: Utilizes Vercel's global network to cache and serve static and dynamic content at the edge, closest to the users, for faster performance.\n- **Supabase (Cloud)**: A cloud-hosted backend-as-a-service that provides not only database solutions but also handles authentication and real-time data functionality. _Region – Supabase – US East (N. Virginia)_\n- **Redis (Upstash)**: Rulebricks uses Upstash to manage user rate limits, and temporarily store compressed asset data for increased API performance."
  },
  {
    "title": "System Architecture",
    "description": "Rulebricks",
    "path": "/security/system-architecture",
    "content": "## Technology Overview\n\nRulebricks is built using Next JS, Postgres, and Redis, **all of which can be run on your own infrastructure via Kubernetes** if you choose to deploy Rulebricks privately.\n\nOur cloud infrastructure is respectively hosted on Vercel, Supabase, and Upstash. You can find more information about our subprocessors [here](/security/subprocessor-list), including the technology they provide, and the regions we operate over them in.\n\nAll cloud data is backed up every few hours and retained for 30 days.\n\nFor our AI features, we use OpenAI. We do not store any data with OpenAI, and only send data to them when you explicitly take an AI action in the Rulebricks interface.\n\n### Private Hosting\n\nAll private deployments are HTTPS and require certification, _provided DNS records are updated immediately after deployment._\n\nCurrently we support terraform based deployment AWS and GCP, with Azure support coming soon.\n\nAll private deployments use Helm charts to spin up and run occasional upgrades against the requisite services. We publish upgrades to our application quite often (2-3 times a day), and you can choose to upgrade your private deployment at your convenience, or opt into notifications about major upgrades we recommend you apply.\n\nMost third party services are disabled or re-configured in private deployments, particularly certain logging, user analytics, and AI features."
  },
  {
    "title": "Terms Of Service",
    "description": "Rulebricks",
    "path": "/security/terms-of-service",
    "content": "## Legal Information\n\nYou can find our Terms of Service on our website [here](https://www.rulebricks.com/legal/terms-of-service), along with our Privacy Policy [here](https://www.rulebricks.com/legal/privacy-policy).\n\nSigning up for Rulebricks means you agree to these terms, so do read them before you get started."
  },
  {
    "title": "Video Introduction",
    "description": "A brief video overview of Rulebricks to get you started building and using rules right away.",
    "path": "/video-introduction",
    "content": "### A Brief Overview\n\nThere're a lot of pages here. Don't want to read through all of them? Here's a short video to give you a bird's eye view of our platform to get you started working with Rulebricks right away.\n\n  <iframe\n    src=\"https://www.loom.com/embed/f9f3371774894fc9a5393a932d804e7a?sid=dea2534d-5423-4f01-919c-1ae415f991aa\"\n    frameBorder=\"0\"\n    allowFullScreen\n    className=\"overview-video\"\n    style=}\n  ></iframe>"
  },
  {
    "title": "Rule Warnings",
    "description": "Rulebricks automatically analyzes your decision tables and warns you about potential issues before they cause problems in production.",
    "path": "/warnings",
    "content": "# Rule Warnings\n\nRulebricks analyzes your decision tables and warns you about structural issues—rows that can never be reached, conditions that shadow later rows, gaps where inputs might fall through.\n\nWarning detection is fairly powerful and can identify situations where conditions are structured in ways that overlap in strange and ambiguous ways, encouraging rule developers to write clearer rules.\n\n![Warning Detection](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/warnings/warning-detection.png)\n\nWarnings appear in the rule editor footer. Click to see details and jump to the affected rows.\n\n## Severity Levels\n\n**Error (Red)** — Definite problems that will cause incorrect behavior. Unreachable rows, catch-alls blocking everything below them. Fix these before publishing.\n\n**Warning (Yellow)** — Likely issues that deserve attention. Partial overlaps, coverage gaps, unhandled boundary values. Review to ensure the behavior is intentional.\n\n**Info (Blue)** — Informational notices. Missing catch-all row, incomplete coverage suggestions. Consider whether these apply to your use case.\n\n## Common Issues\n\n**Catch-All Blocking:** A row with \"any\" for all conditions matches everything, blocking all rows below it. Move catch-alls to the bottom.\n\n**Unreachable Rows:** Every input that would match a row is already caught by an earlier row. Reorder so more specific conditions come first.\n\n**Coverage Gaps:** A range of values won't match any row. Add handling for the missing range, or verify your catch-all covers it.\n\nSee **[Warning Types](/warnings/warning-types)** for detailed explanations and fixes for each warning."
  },
  {
    "title": "Warning Types",
    "description": "Detailed explanations of each warning type in Rulebricks, including what causes them and how to fix them.",
    "path": "/warnings/warning-types",
    "content": "# Warning Types\n\n## Errors\n\n### Catch-All Blocking\n\n**Message:** \"Row X is a catch-all. Rows Y, Z will never be reached.\"\n\nA row with \"any\" for all conditions matches everything, blocking all rows below it.\n\n[Code: Row 1: If tier = \"gold\" → Discount 20%\nRow 2: If any → Discount 0%  ← Catch-all\nRow 3: If tier = \"platinum\" → Discount 30%  ← Never reached!\n]\n\n**Fix:** Move the catch-all to the bottom.\n\n[Code: Row 1: If tier = \"gold\" → Discount 20%\nRow 2: If tier = \"platinum\" → Discount 30%\nRow 3: If any → Discount 0%  ← Now at the bottom\n]\n\n### Unreachable Row\n\n**Message:** \"Row X is unreachable because it is fully covered by Row Y.\"\n\nEvery input that would match Row X is already caught by an earlier row.\n\n[Code: Row 1: If score >= 700 → Approved\nRow 2: If score >= 750 → Premium  ← Unreachable!\n]\n\nAny score >= 750 also satisfies >= 700, so Row 1 catches it first.\n\n**Fix:** Reorder so the more specific condition comes first:\n\n[Code: Row 1: If score >= 750 → Premium\nRow 2: If score >= 700 → Approved\n]\n\n## Warnings\n\n### Partial Overlap\n\n**Message:** \"Row X partially overlaps with Row Y.\"\n\nSome inputs match both rows, but not all. The earlier row wins for the overlap.\n\n[Code: Row 1: If tier = \"gold\" AND score > 600 → Plan A\nRow 2: If score > 700 → Plan B\n]\n\nA gold-tier customer with score 750 matches both, but gets Plan A.\n\n**Fix:** If unintentional, make conditions mutually exclusive. If intentional, document why and ignore the warning.\n\n### Coverage Gap\n\n**Message:** \"Column 'X' has a coverage gap: values in [a, b] have no explicit handling.\"\n\nThere's a range of values that won't match any row.\n\n[Code: Row 1: If age < 18 → Minor rate\nRow 2: If age > 65 → Senior rate\n← Gap: Ages 18-65 have no explicit handling\n]\n\n**Fix:** Add a row for the missing range, or verify your catch-all handles it correctly.\n\n### Boundary Gap\n\n**Message:** \"Exact value X = 100 has no explicit handling.\"\n\nAdjacent conditions leave a specific value unhandled.\n\n[Code: Row 1: If score < 100 → Fail\nRow 2: If score > 100 → Pass\n← Gap: Exactly 100 falls through!\n]\n\n**Fix:** Use inclusive operators:\n\n[Code: Row 1: If score < 100 → Fail\nRow 2: If score >= 100 → Pass\n]\n\n## Info\n\n### Incomplete Coverage\n\n**Message:** \"No catch-all row exists. Some inputs may not match any row.\"\n\nWithout a catch-all, unmatched inputs return an error.\n\n**Fix:** Add a final row with \"any\" for all conditions if you want a default result. Leave it out if you want unhandled cases to error.\n\n---"
  },
  {
    "title": "Assigning Roles",
    "description": "Control workspace access with system roles and custom roles with fine-grained permissions.",
    "path": "/workspace-management/assigning-roles",
    "content": "# Assigning Roles\n\nRoles control what users can access and modify. Assign them from the **Team** tab by clicking the pencil icon next to any user's current role.\n\n![Assigning Roles](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/roles/assigning-roles.png)\n\n## System Roles\n\n**Developer** — Full access to rules, flows, API keys, logs, Dynamic Values, and settings. Cannot edit team membership or billing.\n\n**Editor** — Can view and edit existing rules. Cannot create/delete rules, access API keys, logs, flows, or settings.\n\n**Administrator** — Complete control including team management and billing. Reserved for the workspace owner.\n\n## Custom Roles\n\nFor granular control, create custom roles with exactly the permissions you need."
  },
  {
    "title": "User Groups",
    "description": "Partition your workspace into isolated User Groups for different teams, clients, or projects.",
    "path": "/workspace-management/creating-tenants",
    "content": "# User Groups\n\nUser Groups partition your workspace into isolated sections. Users only see rules and flows in their assigned groups—useful for multi-team organizations, client isolation, or separating environments.\n\n![Team Tenants Tab](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/creating-tenants/team-tenants-tab.png)\n\nAdministrators & Developers, by default, see all groups and data within. Everyone else sees only their assigned groups, and data explicitly assigned to that group."
  },
  {
    "title": "Managing Subscriptions",
    "description": "Manage your Rulebricks subscription, payment information, and billing from the customer portal.",
    "path": "/workspace-management/customer-portal",
    "content": "# Managing Subscriptions\n\nIf you don't have an active subscription, you'll be redirected to the pricing page instead."
  },
  {
    "title": "Inviting Collaborators",
    "description": "Invite team members to your Rulebricks workspace and manage their access levels.",
    "path": "/workspace-management/inviting-collaborators",
    "content": "# Inviting Collaborators\n\nNavigate to the **Team** tab to see your current team members and invite new ones.\n\n![View Team](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/inviting-collaborators/view-team.png)\n\nCollaborators cannot edit team membership, view billing, or remove the workspace owner—those are admin-only."
  },
  {
    "title": "Updating Your Account",
    "description": "Update your email, password, and team name from the Account tab.",
    "path": "/workspace-management/updating-your-account",
    "content": "# Updating Your Account"
  }
]