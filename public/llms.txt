# Rulebricks Documentation

> Decision automation platform for visual rule modeling and business logic.

## User Guide
/

Rulebricks is a decision automation platform that helps you model important decisions in your business visually as "rules", and then integrate them into an automated workflow. Learn how to get started with Rulebricks here.

<div className="landing-page">

<div className="landing-hero">

# User Guide

<div className="hero-description text-xl font-light max-w-3xl sm:mb-0 mb-6">
  Learn how our visual decision modeling approach can help your business make
  complex, embedded logic surprisingly accessible.
</div>

</div>

<AISearchBar />

<div className="feature-cards-grid shadow-sm">
  <FeatureCard
    icon={<IconCube size={64} strokeWidth={0.5} />}
    title="What is a rule?"
    description="The building blocks of decision automation."
    href="/getting-started/what-is-a-rule"
  />
  <FeatureCard
    icon={<IconHammer size={64} strokeWidth={0.5} />}
    title="Start building"
    description="Create your first rule in under 5 minutes."
    href="/getting-started/start-building"
  />
  <FeatureCard
    icon={<IconCode size={64} strokeWidth={0.5} />}
    title="API/SDK Reference"
    description="Complete API docs and SDK examples."
    href="/api-reference"
  />
  <FeatureCard
    icon={<IconPlug size={64} strokeWidth={0.5} />}
    title="Integration guide"
    description="How to use the rules you've built."
    href="/getting-started/integration"
  />
  <FeatureCard
    icon={<IconRoute2 size={64} strokeWidth={0.5} />}
    title="Rulebricks Flows"
    description="Chain rules together for complex workflows."
    href="/integrating-rules/rule-flows"
  />
  <FeatureCard
    icon={<IconServer size={64} strokeWidth={0.5} />}
    title="Private deployments"
    description="Self-host with full control."
    href="/private-deployment/quick-start"
  />
</div>

</div>

## Condition Priorities
/advanced-features/condition-priorities

Condition priorities allow you to specify arbitrary subgroup "flights" of conditions that should be evaluated before others. Learn how to set them up here.

# Condition Priorities

By default in Rulebricks, conditions are evaluated in the order they are defined in the decision table, from top to bottom, and the first condition row where every comparison is satisfied is the one that is used to calculate the result of the rule.

But in some more complex scenarios, you may want a single decision table, but certain subgroups of conditions to take precedence over others. This is where condition priorities come in.

Priorities allow you to specify arbitrary subgroup "flights" of conditions that should be evaluated before others. This is useful when you have a set of conditions that should be evaluated first, and only if none of those conditions are met, should the other conditions be evaluated, and so on.

## Setting priorities

To set condition priorities, open the Row Settings menu for the condition row you want to set a priority for, and set a priority number. Higher numbers are evaluated first, and lower numbers are evaluated later. If two rows have the same priority, they are evaluated in the order they appear in the decision table, but in isolation, as if all rows with lower priority numbers do not exist, and so on.

![Settings Menu](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/advanced-features/row-priority.png)

Row priorities cannot be configured if a row is already a member of a group. If you want to set a priority for a row that is already a member of a group, you must first ungroup the row, set the priority, and then regroup the row. Alternatively, you can set the priority for the group itself, which will apply to all rows in the group.

After you've set priorities for your rows, you can see the priority number in the row itself, in the indicators on the left.

![Priority Indicator](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/advanced-features/status-symbols.png)

You might note a new symbol in the row indicator in the above image– a little clock icon. This indicates if a particular condition is in or out of schedule, which we'll cover in the next section.

## Groups & Hit Policies
/advanced-features/groups-and-hit-policies

Groups in Rulebricks allow you to organize conditions in a decision table in a way that makes sense for your use case. Learn how to create groups and configure hit policies here.

# Groups & Hit Policies

In Rulebricks, conditions in a decision table can be grouped in various ways. Often, this grouping functionality provides an elegant solution to situations where your decision tables would otherwise become large and unwieldy.

Let's take a look at how groups work in Rulebricks, and how you can use them to organize your decision tables.

---

<Steps>

### Creating a group

To create a group, select the conditions you want to group together, and select the "Group" icon from the toolbar. If you are confused which icon is the "Group" icon, hover over the icons to see their tooltips.

![Group Icon](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/advanced-features/group-rows.png)

### Explore the group's settings

Once you've created a group, you can open the group settings menu by clicking either the group indicator, or any row's settings icon within the group.

![Group Settings](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/advanced-features/settings-openers.png)

You should see a menu that allows you to configure the group's hit policy, and other settings.

![Group Settings Menu](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/advanced-features/group-settings-menu.png)

### Configure the group's hit policy

The hit policy determines how the output of the decision table is calculated. They are outlined in the menu you just opened, and we'll cover them in more detail below.

![Hit Policy](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/advanced-features/hit-policies.png)

1. #### Fill Values

For each satisfied condition in the group, the *Fill Values* hit policy will identify any new non-null response dimensions and add them to the output object.

For example, if you have a group with two conditions, and the first condition returns a percentage discount of 10% but a flat price of `null`, and the second condition returns a flat price of $5 but a percentage discount of `null`, this policy will return an object with both the percentage discount and the flat price. This is useful when you want to create a decision table that incrementally updates response data dimensions (i.e. first you have a set of rows that decides what the "percentage_discount" should be, then you have a set of rows that decides what the "flat_price_discount" should be, and you want to return both).

2. #### Add Values

*Add Values* in Rulebricks groups is similar to *Fill Values*, but rather than simply filling in non-null response dimensions, it will actually try to add non-null values together. This is useful when you want to return a single value that is the sum or score of all the values from multiple response rows satisfied in the decision table.

3. #### Compute Values

*Compute Values* is the most advanced hit policy in Rulebricks and allows you to define a custom accumulation pattern for each column. This policy is useful if you want to add up the results of multiple satisfied rows for some columns, but not for others. It's also useful if you'd like more control over how you combine responses from multiple satisfied rows, rather than just adding up everything– this policy also allows you to write your own accumulation function, should you need it.

A good example of this policy in action can be found on [this use-case page](https://rulebricks.com/examples/rules/investment-portfolio-builder).

</Steps>

---

You can visually identify groups in your decision table by the group indicator, which is a small colored circle that appears to the left of the group's conditions. Different groups are assigned random unique colors.

![Group Indicator](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/advanced-features/group-dots.png)

## Scheduled Conditions
/advanced-features/scheduled-conditions

Scheduled conditions in Rulebricks allow you to change how you make a particular decision based on the current time of week & time of day. Learn how to set up scheduled conditions here.

# Scheduled Conditions

Decision tables are a powerful way to make decisions based on data, but what if you need to change how you make a particular decision based on the current time of week & time of day? Scheduled conditions are your answer, and are remarkably easy to set up.

## Configuring a schedule

First, open a condition row's settings menu by clicking the gear icon in the left margin of the row. You should see a menu that allows you to configure the row's schedule.

![Settings Menu](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/advanced-features/row-settings.png)

Check any days of the week you want the condition to be active, and set a start and end time in UTC for the condition.

![Schedule Settings](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/advanced-features/enabling-row-schedule.png)

If you'd like to disable the schedule for a row, simply uncheck all days of the week.

## Viewing if a condition is in schedule

After you've set a schedule for a condition, you can see if it's currently in schedule simply by looking at the row indicator in the left margin of the row. If the row is in schedule, you'll see a green clock icon, and if it's out of schedule, you'll see a red one. Again, **schedule times are in UTC**, so be sure to adjust accordingly for your local time zone, or you may end up confused about why a scheduled condition isn't working as expected.

![Schedule Indicator](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/advanced-features/status-symbols.png)

In this example, the first condition is out of schedule, and would currently be disregarded if I were to run that Rule, and the last condition is in schedule.

## Dynamic Values
/advanced-features/values-and-functions

Store reusable values and write custom JavaScript functions to use across your rules.

# Dynamic Values

Your tax rate appears in twelve rules. When it changes from 8% to 8.5%, do you want to update twelve rules—or one value?

Dynamic Values solve this problem for you by storing numbers, strings, and other data types centrally. Reference them in any rule, and update them in one place.

Changes to values propagate instantly, and using values doesn't detract from how performant your rules are because values are deeply integrated into our caching infrastructure.

## Ad-hoc values

<Steps>

### Create a value

Go to **Team → Values** and click **Create New Value**.

![Values Tab](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/values-and-functions/values-tab.png)

### Fill in the value's details

![Create Value Modal](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/values-and-functions/create-value-modal.png)

### Use it in a rule

In the rule editor, click a condition or result cell. Toggle to **variable mode** and select your value from the dropdown.

Note that you'll only see your value if it's the right type of data for the operator the cell is using. For example, if your operator is "Greater than", then you'll only see your Values of type number.

![Values in Dropdowns](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/values-and-functions/values-dropdowns-rule.png)

</Steps>

## Bulk importing

You'll often want to bring in a large number of values at once to start using vocabulary from your business right away. Rulebricks offers you three ways to do this quickly.

First, our values UI allows you to simply import large, potentially nested JSON dictionaries that simply contain key value pairs.

Use the "From JSON" tab to continue with this option.

![Bulk Import Values](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/values-and-functions/bulk-import-values.png)

Second, an API endpoint is also available to create and update dynamic values. Start by looking at our [Dynamic Values API](https://rulebricks.com/docs/api-reference#tag/values).

Finally, if you have JSON Schema on hand, or even a DDL or other similar schema artifact, you can upload your schema as an Object (or use smart import if you're bringing a DDL/non-standard format).
Rulebricks will automatically scan your schema for enums/ranges, and create values based on them in your workspace.

## Functions

Functions let you write JavaScript that computes results dynamically, calculating results based on input and other output values.

Functions can be authored here as arrow expressions. Some libraries are available to assist with complex operations.

```javascript
((quantity, price) => (quantity > 100 ? price * 0.9 : price))
```

<Steps>

### Create a function

Go to **Dashboard → Values** and click **Create New Value** – functions are just a kind of Dynamic Value.

Select the function type, and write in a JavaScript arrow expression.

### Use it in a rule

Add a **Function** type column to your rule's **response**, or update an existing column's type accordingly. Type `$` to see available functions, including the one you've just made.

![Using Functions](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/values-and-functions/using-functions.png)

</Steps>

## Analysis Tools
/analysis-tools

Rulebricks provides analysis tools to help you understand how your rules perform in production and how changes might affect outcomes.

# Analysis Tools

Rulebricks provides two powerful analysis tools in the rule editor to help you understand how your rules perform in production and how changes might affect outcomes.

## Available Tools

### Impact Analysis

Test how changes to your rule conditions would affect outputs **before deploying**. Impact analysis replays historical requests through modified conditions to show you exactly what would change.

![Impact Analysis](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/rule-analysis-tools/impact-analysis.png)

**Use it when:**

- You're considering changing a condition value
- You want to compare the current rule version against a previous one
- You need to understand the downstream effects of a rule change

[Learn more about Impact Analysis →](/analysis-tools/impact-analysis)

### Reachability Analysis

See which rows in your decision table are actually being matched by production traffic. Reachability analysis shows you hit frequencies and helps identify dead code or optimization opportunities.

![Reachability Analysis](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/rule-analysis-tools/reachability-analysis.png)

**Use it when:**

- You suspect some rows are never being matched
- You want to optimize rule evaluation order
- You need to understand which conditions are causing the most rejections

[Learn more about Reachability Analysis →](/analysis-tools/reachability-analysis)

## Accessing the Tools

Both tools are available in the **footer bar** of the rule editor and are available on any paid plan. Click **Impact** or **Reachability** to open the respective analysis panel.

<Callout type="info">
  Results are based on your rule's execution logs, so you'll need some
  production traffic before the analysis becomes meaningful.
</Callout>

For static analysis of rule structure (without production data), see [Rule Warnings](/warnings)—which examines your rule for potential issues like unreachable rows and coverage gaps.

## Impact Analysis
/analysis-tools/impact-analysis

See exactly how rule changes would affect your outputs before deploying. Impact Analysis replays historical requests through modified conditions.

# Impact Analysis

You're about to change your credit score threshold from 700 to 650. How many more applications will get approved? Will your denial reasons shift?

Impact Analysis gives you crystal clear answers to these questions before you deploy anything.

![Impact Analysis](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/rule-analysis-tools/impact-analysis.png)

The tool replays a configurable sample of real production requests through your modified rule logic and shows you exactly what would change—approval rates, output distributions, everything.

## Analysis Methods

Two analysis methods are made available, depending on how your organization is using rules in production, and the extent of changes you're trying to simulate.

<Tabs items={['Specific Conditions', 'Compare Versions']}>
<Tabs.Tab>

Test one or more specific condition changes (against the working rule) before publishing them:

1. Click on any condition cell in your rule table
2. Enter the new value you want to test
3. Click **Run Analysis**

The results show how your outputs would shift. If you're lowering a threshold, you'll see exactly how many more requests would match. If you're tightening a condition, you'll see what would get filtered out.

<Callout type="info">
  You can also click on multiple condition cells to understand interactions from
  multiple changes to different conditions at once.
</Callout>

</Tabs.Tab>
<Tabs.Tab>

Compare the current (working) rule against a previously published version:

1. Switch to **Version** mode in the panel
2. Select a previous version from the dropdown
3. Click **Run Analysis**

This is useful when something seems off after a deploy— you can see precisely what changed between versions and how it affected your output distribution.

<Callout type="warning">
  While it will still run, we do not recommend this approach if your schema
  changes often.
</Callout>

</Tabs.Tab>
</Tabs>

## Reading the Results

Results show distribution charts for each output field. The visualization adapts to the data type:

<Tabs items={['Numeric', 'Categorical', 'Date']}>
<Tabs.Tab>

![Numeric Results](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/rule-analysis-tools/impact-results-numeric.png)

Histogram distributions with before/after comparison. Shows how value distributions shift.

</Tabs.Tab>
<Tabs.Tab>

![Categorical Results](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/rule-analysis-tools/impact-results-categorical.png)

Bar charts showing how often each value would be returned. Boolean outputs show percentage shifts between true/false.

</Tabs.Tab>
<Tabs.Tab>

![Date Results](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/rule-analysis-tools/impact-results-date.png)

Timeline distributions for date outputs. Useful for rules that set deadlines or expiration dates.

</Tabs.Tab>
</Tabs>

Watch for **null shifts**—when values suddenly become null, it often means requests stopped matching any row. Impact Analysis will surface this in an alert if it detects it.

<Callout>
  While computation is done on our servers and included with your Rulebricks
  plan, we recommend being very deliberate about the sample size you use–
  particularly between the 100k - 1M range; these can be large reports.
</Callout>

## Example: Threshold Optimization

Say you want to approve more loan applications by lowering the credit score requirement from 700 to 650.

1. Click the credit score condition cell
2. Change it to 650
3. Run analysis against the last 500 requests

The results might show:

- Approval rate jumps from 62% to 78%
- Average approved amount drops slightly (riskier applicants qualify for less)
- Denial reason distribution shifts from "low credit" to "high debt ratio"

Now you know exactly what you're signing up for before you ship the change.

## Reachability Analysis
/analysis-tools/reachability-analysis

See which rows in your decision table are actually being matched by production traffic. Find dead code and optimization opportunities.

# Reachability Analysis

Your rule has 47 rows. Which ones actually matter?

Reachability Analysis shows you exactly which rows are being hit by real traffic—and which ones might be dead weight. It analyzes your execution logs to surface usage patterns you wouldn't otherwise see.

![Reachability Analysis](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/rule-analysis-tools/reachability-analysis.png)

## What It Shows

<Tabs items={['Row Hits', 'Condition Denials', 'Condition Passes']}>
<Tabs.Tab>

Which rows are doing the heavy lifting:

- Rows sorted by hit frequency, most matched at top
- Percentages showing traffic distribution
- Rows that were **never hit** flagged as potential dead code

</Tabs.Tab>
<Tabs.Tab>

Which conditions are blocking matches. This helps you understand why certain rows aren't being reached—maybe a condition is too restrictive, or an earlier row is catching everything.

</Tabs.Tab>
<Tabs.Tab>

Which conditions pass most frequently, revealing your typical traffic patterns and the "happy path" through your rule.

![Condition Acceptance View](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/rule-analysis-tools/reachability-condition-acceptance-view.png)

</Tabs.Tab>
</Tabs>

The panel header shows summary stats: how many requests matched at least one row, how many matched nothing, and how many rows have zero hits.

<Callout type="warning">
  High "no match" counts mean inputs are falling through without being handled.
  You probably need a catch-all row or broader conditions.
</Callout>

## Finding Dead Rows

A row with 0% hits over 30 days is probably:

- **Unreachable** — an earlier catch-all row blocks it
- **Obsolete** — handles an edge case that never actually occurs
- **Safe to remove** — cleaning up your rule table

Before deleting, make sure to thoroughly investigate _why_ it's not being hit. Some rows handle rare but critical cases— you don't want to remove your fraud detection row just because it only fires twice a month.

## Performance Optimization

If one row handles 80% of your traffic but sits at the bottom of your table, moving it up can meaningfully improve evaluation speed at scale. Rulebricks evaluates top-to-bottom, so putting your high-traffic rows near the top reduces unnecessary condition checks.

Use [Impact Analysis](/analysis-tools/impact-analysis) afterward to verify that reordering didn't change your rule's behavior.

## Large Reports

Computation is handled on our servers– but we encourage users to be prudent about the sample sizes they use as particularly large requests may take several minutes to complete and potentially timeout.

We perform cardinality analysis on your rule internally to optimize reachability reports for massive amounts of data/rows.

## Creating a Form
/building-forms/creating-a-form

Creating a form in Rulebricks is a great way to embed information specific to your business and help users calculate something based on their inputs. Learn how to create a form here.

# Creating a Form

As it turns out, rules in Rulebricks also can be used to create forms & quizzes for your business and/or clients remarkably easily.

This is a particularly good way to **embed information specific to your business** and **help users calculate something** based on their inputs, like a particular pricing quote or eligibility status.

Any form built in Rulebricks can easily be embedded on your website, with your company colors/branding, so it will look right at home when you send it along.

## Video Overview

Below is a brief video overview of what forms in Rulebricks look like.

<div
  style={{
    position: 'relative',
    paddingBottom: '62.5%',
    marginTop: '2rem',
    height: 0,
  }}
>
  <iframe
    src="https://www.loom.com/embed/043c046f88b14f8f935053e6da797339?sid=27fbf55f-f427-484c-a928-2e7d1e9a6dfa"
    frameBorder="0"
    allowFullScreen
    className="overview-video"
    style={{
      position: 'absolute',
      top: 0,
      left: 0,
      width: '100%',
      height: '100%',
      borderRadius: '4px',
    }}
  ></iframe>
</div>

## Form Guide

Let's walk through creating a form in Rulebricks.

<Steps>

### Create & publish a rule

Create and publish a rule. If you're not sure how to do this, check out our [Getting Started](/getting-started/what-is-a-rule) guide for a brief refresher.

As you're creating your rule, you'll want to make sure you're including in the **Request Object** all the form data you want to collect from your users. This is the data that will be sent to your rule when the form is submitted.

When your rule is ready, click the "Form" button in the top right corner of the rule editor.

![Form Button](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/building-forms/form-button.png)

### Open the form editor

This will open the form editor. Here you can customize the form to your liking, including editing inputs, changing the form title, description, branding, and more.

![Form Editor](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/building-forms/form-editor.png)

### Try out your form

By default your form is already connected to your rule, so when a user submits the form, the data will be sent to your rule and the result will be displayed to the user.

You can try out your rule either in the form editor itself, or by visiting the URL available in the "Sharing" section of the sidebar to see how it might look when embedded on your website or shared with others.

![Form Sharing](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/building-forms/try-form.png)

</Steps>

---

Your form is already live and ready to be shared with your users, but you'll probably want to edit the form to make the inputs easier for folks to understand first. In the next section, we'll walk through how to do just that.

## Editing Form Fields
/building-forms/editing-fields

Editing form fields in Rulebricks is a powerful way to customize the form fields and results fields in your rules. Learn how to do it here.

# Editing Form Fields

If you're following along, you might've noticed by now that each attribute of your request object is automatically turned into a form field when you click the "Form" button in the Rulebricks editor, and each attribute in your response object is automatically turned into a result field, i.e. a field that will be displayed to the user after they submit the form.

This is a powerful feature that allows you to quickly create forms that collect the data you need, and display the results you want, without having to write any code.

But how do you customize these form fields? What if you want to change the type of a field, or add a description, or make a field required?

Sometimes, this behavior can be really important, for example if you want to collect text from a user, but you want to make sure they enter one of a few specific options, like "A" or "B". In this case, you might want to change the field type from "Short Text" to "Multiple Choice", and add the options "A" and "B".

## Edit Fields

Let's walk through how to do this.

<Steps>

### Open the form editor

First, open the rule you want to edit in the Rulebricks editor, and click the "Form" button in the top right corner of the rule editor to open the form editor.

![Form Editor](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/building-forms/form-editor.png)

### View the form fields

The form editor has three tabs: "Form", "Edit Fields", and "Edit Results". Click on the "Edit Fields" tab to view and edit the form fields.

You should be able to see a dropdown for each field named "Input Variant", describing the particular type of field it is.

![Edit Fields](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/building-forms/change-field-type.png)

<Callout type="info" emoji="">
  Note that by default, Rulebricks will automatically choose the field type
  based on the data type of the attribute in your request object. For example,
  if the attribute is a number, Rulebricks will choose the "Number" field type.
  Not all field types are available for all data types, and there are some cases
  where you may not be able to change the field type.
</Callout>

### Edit the field

To change the field type, click on the dropdown and select the field type you want. You can also add a description, make the field required, or add options for certain field types.

In this brief example, we're changing the field type from "Short Text" to "Multiple Choice", and adding a few options.

![Change Field Type](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/building-forms/add-choices.png)

### Return to your form

Now, click the "Form" tab to return to the form editor, and you should see your changes reflected in the form. In this particular case, what used to be an open-ended text field is now a multiple choice field with specific options I compare against in my rule.

![Returned to Form](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/building-forms/returned-to-form.png)

</Steps>

## Edit Results

You can also edit the results fields in the same way, but instead of changing how inputs appear to the user, you're changing how results appear to the user after they submit the form.

These are useful for displaying the results of your rule in a way that makes visual sense to the user, and are purely for display purposes.

<Steps>

### View the form results

To edit the results fields, click on the "Edit Results" tab in the form editor, and check out the "Display Variant" dropdown for each field.

![Outcome Results](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/building-forms/change-result-type.png)

### Edit the display variant

Let's say in this particular case, simply showing the user "Income Verification: true" isn't very helpful, even though it's the result of my rule.

Instead, we can change the display variant to "Outcomes", which will show the user a more human-readable version of the result, like "Income Verified", depending on whether this particular result in the response data is true or false.

![Outcome Results](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/building-forms/use-outcomes.png)

### Return to your form

Now, when I head back to my form and try it out, I can see the results of my rule displayed in a way that makes sense to me and my users.

![Outcome Results](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/building-forms/outcome-results.png)

</Steps>

## Sharing Forms
/building-forms/sharing-forms

Sharing forms in Rulebricks is easy, and there are a few ways you can do it. Learn how to share your forms here.

# Sharing Forms

Congrats– you've created a form! Now it's time to share it with the world. There're a few ways you can do this, and a few things you need to keep in mind, so we'll walk through them here.

## Your form is live

When you create a form in Rulebricks, it's automatically public. This means that anyone with the link can access and submit the form. This is great for sharing your form with others, but it also means you need to be careful about who you share the link with.

Each time someone submits your form, the data is sent to your rule, and the result is displayed to the user. This uses up one of your monthly rule executions/runs, so be mindful of this as you share your form. Of course, you can always upgrade your plan if you need more rule executions/runs.

## Sharing your form

To share your form, you can simply copy the URL from the "Sharing" section of the sidebar in the form editor. This URL is unique to your form, and can be shared with anyone you'd like to fill out the form.

![Form Sharing](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/building-forms/try-form.png)

## Three options

There are three ways you can share/use your Rulebricks forms. Each of the menus below is available in the sidebar of the form editor, so simply scroll down to find them.

<Tabs
  items={[
    'Sharing the URL',
    'Embedding on your website',
    'Using an integration',
  ]}
>
  <Tabs.Tab>
    You can share your form by copying the URL from the "Sharing" section of the sidebar in the form editor. This URL is unique to your form, and can be shared with anyone you'd like to fill out the form.

![Form Sharing](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/building-forms/sharing-forms-url.png)

  </Tabs.Tab>
  <Tabs.Tab>
  You embed your form on your website by copying the embed code from the "Embed" section of the sidebar. This will allow you to display your form directly on your website, so users can fill it out without leaving your site.

![Form Embed](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/building-forms/sharing-forms-embed.png)

  </Tabs.Tab>
  <Tabs.Tab>
    You can use an integration to connect your form to other tools you use in your business. For example, you can use Zapier to connect your form to your CRM, or to send an email notification when someone fills out your form.

    This approach focuses less on the way you share the form, and more on what you do with the data once it's submitted.

    To use this, simply provide a Webhook URL to the tool you want to integrate with, and we'll send the form data, along with the rule result, to that URL whenever a form is submitted.

![Form Integration](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/building-forms/sharing-forms-integration.png)

  </Tabs.Tab>
</Tabs>

## Contexts
/contexts

Contexts hold your decision together while data arrives from different sources at different times. Progressive rule execution for async business processes.

# Contexts

A loan application arrives on Monday. The credit check comes back Wednesday. Employment verification finishes Friday. By the time you have everything you need to make a decision, where did Monday's data go?

**Contexts hold your decision together while the pieces arrive.**

![Contexts Tab](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/contexts/context-tab.png)

Instead of building infrastructure to track what data you have, what's missing, and when to run your rules, Contexts handle it for you. Define the facts you need, submit them as they arrive from different sources, and your rules execute automatically when everything's ready.

## A Useful Reframing

You should use rules directly when your business already has all the data you need upfront, and you've just been missing the rule piece until now. You should use Contexts when you don't have all the data right away, but you do know the rules that will apply to that data.

Contexts allow you to think about rules and decisions from the perspective of _updates to business entities_, which becomes somewhat apparent when you look at how to use the contexts API:

```javascript
// Credit score arrives from bureau webhook
POST /api/v1/contexts/loan-application/APP-12345
{ "credit_score": 720 }

// Response tells you what's still missing
{
  "status": "pending",
  "have": ["applicant_id", "credit_score"],
  "need": ["annual_income", "employment_verified"]
}

// When the last piece arrives, rules auto-execute
{
  "status": "complete",
  "state": {
    "approval_decision": "approved",  // Written by your rule
    "max_loan_amount": 250000
  }
}
```

As opposed to:

```javascript
// Assumes we have all the data upfront
POST /api/v1/solve/approval-rule
{ "credit_score": 720, "annual_income": 120000, "employment_verified": true }

// Manual write-back/result storage
// ...
```

<Callout>
  **Contexts vs Objects:** Objects define data structures for your rules.
  Contexts track decision-relevant facts as they arrive over time. If you have
  all your data upfront, use Objects. If data arrives progressively from
  different sources, use Contexts.
</Callout>

## When to Use Contexts

- Data arrives from multiple sources at unpredictable times (webhooks, user actions, third-party APIs)
- You want rules to execute automatically when their inputs are ready
- Your decision process spans hours, days, or weeks
- You need to track what's been collected vs what's still missing

## Linking Rules & Flows to Contexts
/contexts/binding-rules

Connect rules to Contexts so they read from context facts and write their outputs back automatically.

# Linking Rules & Flows to Contexts

Once your Context(s) are ready, you're ready to create rules & flows that are "bound" to them, priming them to automatically run when your live contexts start receiving data.

Once bound, the rule reads its inputs from context facts and writes its outputs back—no API calls required on your end. All flows that start from that rule are also considered bound and will fire automatically upon associated context updates.

Flow write-back into contexts is accomplished slightly more explicitly via an "Context Operations" step you can find easily from the flow editor.

## Create a Bound Rule

<Steps>

### Open the Rule

Click the "Create rule" button in the dashboard and open the **From Context** tab, which only appears when you have Contexts available.

Provide a name and description for your rule, then click **Continue**.

### Select Context Facts

You will be presented with an interface to select facts from your associated Context as inputs _and outputs_ to this particular rule. If your rule requires data or outputs data you cannot find, update the associated Context by adding the missing fact(s) and return here.

Fields you select as inputs cannot also be selected as outputs. Certain fields may not be eligible for selection as inputs.

![Map Fields](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/contexts/map-fields.png)

As indicated, the rule's request schema fields will map to context facts with matching names, and the rule's response fields will write to context facts with matching names.

### Create Rule

Click the **Create from Context** button at the bottom of your modal, customize your rule, and publish it when you're ready.

</Steps>

<Callout>
  To bind flows, simply create a new flow that uses a bound rule as its
  origin/first rule.
</Callout>

<Callout>
  You can bind multiple decision assets to the same context. They'll execute in
  dependency order—a rule that reads `risk_tier` waits for the rule that writes
  it.
</Callout>

## Cascading Rules

When Rule A writes a fact that Rule B needs, B executes automatically after A:

```
Facts arrive: credit_score, annual_income
       ↓
[Credit Check Rule] executes → writes: risk_tier
       ↓
[Pricing Rule] now has all inputs → executes → writes: rate, max_amount
```

This happens within a single API response. The `cascaded` array shows what ran:

```json
{
  "cascaded": [
    { "rule": "credit-check", "result": { "risk_tier": "low" } },
    { "rule": "pricing", "result": { "rate": 4.5, "max_amount": 500000 } }
  ]
}
```

## Viewing Bound Rules

From the Context dashboard, the **Assets** tab shows all currently bound rules & flows, their execution modes, and which facts they read/write.

## Getting Started with Contexts
/contexts/getting-started

Create your first Context in Rulebricks and see progressive rule execution in action.

# Getting Started with Contexts

Let's build a Customer Context that tracks customer data across multiple sources and automatically runs your bound rules when the required information is available.

<Steps>

### Create a Context

Go to **Dashboard → Contexts** and click **Create Context**.

![Context Tab](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/contexts/context-tab.png)

Name it "Customer" and set `customer_id` as the identity fact—this is what uniquely identifies each customer flowing through the system.

### Define Your Facts

In the Context Editor, add the facts your decisions need:

![Define Facts](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/contexts/define-facts.png)

| Fact          | Type    | Required |
| ------------- | ------- | -------- |
| `customer_id` | string  | Yes      |
| `name`        | string  | No       |
| `email`       | string  | No       |
| `tier`        | string  | Yes      |
| `income`      | number  | Yes      |
| `address`     | object  | No       |
| `nicknames`   | list    | No       |
| `subscribed`  | boolean | No       |

Mark facts as **required** if rules can't execute without them. Facts like `tier` and `income` might be required for your decisions, while profile data like `nicknames` is optional.

### Add a Derived Fact (Optional)

Derived facts calculate automatically from other facts or related entities. Add a `total_spent` fact that aggregates transaction amounts:

![Derived Facts](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/contexts/derived-facts.png)

```javascript
sum($relations.Transaction, 'amount')
```

This updates whenever a related Transaction is added or modified. You can also create derived facts like `transaction_count` to track how many transactions a customer has.

### Link Your Rule

Create a rule, set its input schema to **From Context**, and select the Customer context. Any rules you create in this way will read from context facts and write their decision results back automatically.

[Learn more about linking decision assets →](/contexts/binding-rules)

### Test It

Use the **Console** tab to explore live customer instances:

![Context Console](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/contexts/context-console.png)

Enter a customer ID like `c_001` to fetch the instance and see all base facts (name, tier, income, etc.) and derived facts (transaction_count, total_spent). When required facts are present, bound rules/flows execute automatically– if you've already set those up, you should be able to see their outputs write-back to your live context accordingly.

</Steps>

## Using the API

Submit facts to a context instance via POST:

```bash
curl -X POST "https://rulebricks.com/api/v1/contexts/customer/c_001" \
  -H "x-api-key: YOUR_API_KEY" \
  -d '{ "tier": "gold", "income": 200000 }'
```

The response shows current state:

```json
{
  "status": "pending",
  "have": ["customer_id", "tier", "income"],
  "need": []
}
```

When all required facts are present and a bound rule exists, the response includes rule execution:

```json
{
  "status": "complete",
  "cascaded": [
    {
      "rule": "customer-decision",
      "result": { "tier_benefits": ["free_shipping", "priority_support"] }
    }
  ]
}
```

## Key Concepts

- **[Facts and Schema](/contexts/key-concepts/facts-and-schema)** — Derived facts, history tracking, and schema design
- **[Execution Mode](/contexts/key-concepts/progressive-execution)** — How auto-execution and cascades work
- **[Binding Rules](/contexts/binding-rules)** — Connect rules to read from and write to contexts

## Gradient
/contexts/gradient

Gradient automatically discovers decision patterns from your Context data and generates rules for you.

# Gradient

_What if your rules could write themselves?_

Gradient is a new feature coming to Rulebricks that watches the data flowing through your Contexts and automatically surfaces the decision patterns hiding in it. That credit approval workflow your team runs manually? Gradient sees that 94% of applicants with scores above 720 and debt ratios below 30% get approved—and generates the rule for you.

### From Data to Decisions

Your Contexts already capture the facts that matter: what arrived, when, what was decided. Gradient analyzes this history to find what drives outcomes.

**It discovers patterns like:**

- Orders from gold-tier customers over $500 are always expedited
- Applications missing employment verification stall 3x longer than others
- Price adjustments above 15% require manager approval regardless of other factors

These become draft rules you can review, refine, and publish. The implicit knowledge in your business becomes explicit, auditable logic.

### Finding procedural bottlenecks

Beyond rule generation, Gradient identifies where decisions get stuck. Which facts are most often missing when applications stall? Where would a new integration have the highest ROI?

This turns operational friction into actionable insights—you see exactly which data gaps cost you the most.

<Callout>
  **Early Access:** Gradient is in active development. If you're interested in
  automated rule discovery, [reach out](mailto:support@rulebricks.com) to learn
  more or join the early access program.
</Callout>

## Facts and Schema
/contexts/key-concepts/facts-and-schema

Understanding base facts, derived facts, and the identity fact in Rulebricks Contexts.

# Facts and Schema

A Context's schema defines what data it collects. There are three kinds of facts: base facts (the raw data you submit), derived facts (computed automatically), and one special identity fact (what uniquely identifies each instance).

## Base Facts

Base facts are the data points you collect—things like `credit_score`, `annual_income`, or `employment_verified`. They come from API calls, webhooks, user input, or anywhere else in your system.

Each fact has a type (string, number, boolean, date, list, or object) and can be marked as:

- **Required** — Must be present before rules can execute
- **Output only** — Can only be written by rules, not submitted externally
- **Track history** — Stores previous values for temporal queries

## The Identity Fact

One fact must be the **identity fact**—the unique identifier for each context instance. For a loan application context, this might be `application_id`. For transaction processing, `transaction_id`.

The identity appears in your API URLs:

```
POST /api/v1/contexts/loan-application/APP-12345
                                       ↑ identity value
```

<Callout>
  Identity facts must be strings or numbers, must be required, and can't be
  output-only. Once set, they shouldn't change.
</Callout>

## Derived Facts

Derived facts compute automatically from other facts using expressions:

```javascript
// Debt-to-income ratio
monthly_debt / (annual_income / 12)

// Risk category based on score
ifelse(
  credit_score >= 750,
  'low',
  ifelse(credit_score >= 650, 'medium', 'high')
)

// Aggregate from related contexts
sum($relations.transaction, 'total')

// Available functions are listed directly in app UI
```

They update whenever their dependencies change—no manual recalculation needed.

## Relationships

Contexts can relate to each other. A customer context can have many transaction contexts. An transaction context can belong to a customer. These relationships let you build decisions that span multiple entities.

### The Pattern

**Customer** (one) → **Transactions** (many)

A customer context tracks lifetime data: total spend, transaction count, loyalty tier. Each transaction context tracks a single transaction. When an transaction completes, you might want to update the customer's lifetime stats.

![Context Relations](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/contexts/context-relations.png)

### Defining Relationships

In the Context Editor, add a relationship field:

**On the Customer context:**

```
transactions: has_many(Transaction, 'customer_id')
```

**On the Transaction context:**

```
customer_id: string (foreign key)
```

Now transactions link to their customer, and customers can reference their transactions.

### Using Relationships

Derived facts are required for you to expose and use data from related Contexts.

For example, on a Customer context, I might use:

```javascript
// Total spend across all transactions
total_spend: sum($relations.transaction, 'total')

// Number of completed transactions
transaction_count: count($relations.transaction, 'status == "complete"')

// Most recent transaction date
last_transaction_date: max($relations.transaction, 'created_at')
```

These recalculate automatically when any related transaction changes.

### Cascading Across Relationships

When an transaction is marked complete, it can trigger rules on the customer context:

1. Transaction context receives `status: "complete"`
2. Customer's `transaction_count` derived fact recalculates
3. If `transaction_count` crosses a threshold, a loyalty tier rule executes
4. Customer's `loyalty_tier` fact updates

This cascade happens automatically based on the relationships and rule bindings you've defined.

<Callout>
  Relationship queries (`$relations.transaction`) only include live, non-expired
  context instances– expired transactions won't appear in aggregations. If this
  is an issue, consider maintaining a running statistic in your systems and
  sending it into the Context via a base fact– we still consider this a data
  concern rather than a Rulebricks problem.
</Callout>

### Navigating the Other Direction

From an transaction, access the parent customer:

```javascript
// Get customer's tier for transaction-level pricing
customer_tier: $relations.customer.loyalty_tier
```

This creates a dependency—the transaction context waits for the customer's `loyalty_tier` before derived facts using it can calculate.

## Solvability

A context instance is "solvable" when all required facts are present. The API always tells you where you stand:

```json
{
  "status": "pending",
  "have": ["application_id", "credit_score"],
  "need": ["annual_income", "employment_verified"]
}
```

When `need` is empty, `status` becomes `complete` and bound rules can execute.

## Live Contexts
/contexts/key-concepts/live-contexts

Understanding context instances, their lifecycle, and the have/need pattern for tracking data collection progress.

# Live Contexts

When you submit data to a Context, you create a **live context**—an instance that accumulates facts over time until rules can execute.

- **Context** = the schema definition (what facts you need for loan approval)
- **Live context** = a specific instance (loan application APP-12345's data)

## Lifecycle

A live context is created when you first submit data for a new identity:

```bash
POST /api/v1/contexts/loan-application/APP-12345
{ "annual_income": 85000 }
```

It persists as you submit more facts over time. Each submission merges into the existing state—new fields are added, existing fields are updated, missing fields are left alone.

When all required facts are present, the status changes from `pending` to `complete`, and bound rules can execute.

Eventually, live contexts expire based on their TTL (time-to-live) setting. Expired contexts are no longer accessible—POST requests to that identity create a fresh instance.

## The Have/Need Pattern

Every API response tells you exactly where you stand:

```json
{
  "status": "pending",
  "have": ["application_id", "credit_score", "annual_income"],
  "need": ["employment_verified"],
  "expires_at": "2024-01-22T10:30:00Z"
}
```

- `have` — facts with values
- `need` — required facts still missing
- `status` — `pending` until `need` is empty, then `complete`

This makes it easy to show progress in your UI, decide what to fetch next, or debug why a rule isn't executing.

## TTL and Expiration

Set TTL when creating your context (1 hour to 30 days). The clock starts when the instance is created, not when it's last updated.

<Callout>
  When a context expires, you can configure a webhook to fire—useful for
  cleaning up related resources or notifying users that their process timed out.
</Callout>

## Fetching State

Get the current state of any live context:

```bash
GET /api/v1/contexts/loan-application/APP-12345
```

The response includes all facts (base and derived), the have/need arrays, timestamps, and expiration time.

## Progressive Execution
/contexts/key-concepts/progressive-execution

Rules automatically execute when their inputs are ready. Understand auto-execution and cascading rule chains in Contexts.

# Progressive Execution

The magic of Contexts is that **decisions run automatically when their inputs are ready.**

You don't schedule rule execution or poll for completeness. Simply submit facts as they arrive, and the rules that can run will run.

## How It Works

When you bind a rule to a context, Rulebricks knows what inputs that rule needs. When you submit a fact:

1. All derived facts that depend on it recalculate
2. The system checks if any bound rules now have all their required inputs
3. Rules that are ready execute automatically
4. Their outputs write back to the context as new facts

This happens in a single API response—you submit `employment_verified: true`, and you get back the approval decision your rule computed.

## Cascading Execution

Rules can write facts that other rules depend on. This creates automatic chains:

```
Submit: credit_score = 720
        ↓
  [Risk Assessment Rule] executes
        ↓
Writes: risk_tier = "low"
        ↓
  [Pricing Rule] executes (was waiting for risk_tier)
        ↓
Writes: rate = 4.5, max_amount = 500000
```

The response tells you what ran:

```json
{
  "status": "complete",
  "cascaded": [
    { "rule": "risk-assessment", "result": { "risk_tier": "low" } },
    { "rule": "pricing", "result": { "rate": 4.5, "max_amount": 500000 } }
  ]
}
```

## Execution Modes

There are very specific situations where automatic decision evaluation on Contexts may be undesirable. While we make Automatic Execution a default, you can also turn it off, preferring to register pending rules/flows manually.

| Mode        | When it runs                              |
| ----------- | ----------------------------------------- |
| **Enabled** | Automatically when all inputs are present |
| **Manual**  | Only when you explicitly call `/solve`    |

<Callout>
  Manual mode is useful when you want to control timing precisely—for example,
  waiting for human approval before running a disbursement rule.
</Callout>

## Deterministic Order

When multiple rules can execute, they run in dependency order—a rule that writes `risk_tier` always runs before a rule that reads it. If rules have no dependencies, execution order is stable but arbitrary.

If a rule fails, the cascade stops and the error is returned. Other facts already written in that request remain—partial progress is preserved.

## Webhooks
/contexts/webhooks

Get notified when contexts are solved or expire via webhook callbacks.

# Webhooks

Contexts can call your endpoints when something happens—a rule executes, a context expires, or an error occurs.

## Events

| Event             | When it fires                      |
| ----------------- | ---------------------------------- |
| `context.solved`  | A bound rule executed successfully |
| `context.expired` | The context's TTL elapsed          |
| `context.error`   | A rule execution failed            |

## Configuration

In the Context Editor, add a webhook URL and select which events to send.

Rulebricks signs each request with your webhook secret (available in settings). Verify the `X-Rulebricks-Signature` header to ensure requests are authentic.

## Payload Structure

**context.solved:**

```json
{
  "event": "context.solved",
  "context": "loan-application",
  "identity": "APP-12345",
  "rule": "credit-check",
  "result": {
    "risk_tier": "low",
    "approved": true
  },
  "timestamp": "2024-01-15T10:30:00Z"
}
```

**context.expired:**

```json
{
  "event": "context.expired",
  "context": "loan-application",
  "identity": "APP-12345",
  "final_state": {
    "have": ["application_id", "credit_score"],
    "need": ["employment_verified"]
  },
  "timestamp": "2024-01-22T10:30:00Z"
}
```

<Callout>
  The `final_state` on expiration shows what was still missing—useful for
  understanding why a decision couldn't be made.
</Callout>

## Why Rulebricks Embedded?
/embedding-rulebricks/about-embedded

Rulebricks Embedded is for engineering teams who need to deliver **enterprise-grade rule configuration** to their users _now_, without diverting their roadmap for six months to build a rule engine fro

# Why Rulebricks Embedded?

Rulebricks Embedded is for engineering teams who need to deliver **enterprise-grade rule configuration** to their users _now_, without diverting their roadmap for six months to build a rule engine from scratch.

---

When your product needs advanced user-configurable logic—like dynamic pricing, eligibility criteria, or routing rules— many engineering teams face a difficult choice:

1.  **Build it yourself**: You spend a month building a decision table UI/backend. You soon discover that features like undo/redo stacks, copy/paste support, change tracking, caching, and performant execution against large datasets are massive engineering sinks.
2.  **Use a traditional BRMS**: You get a powerful engine, but you compromise your client experience. Your users are redirected to a third-party dashboard that doesn't look or feel like your product, despite your white-labeling.

Rulebricks Embedded eliminates this compromise. Paired with our SDK, it offers you a unique native-component that allows you to **buy an engine, but build the experience.**

## Built with React, Compatible with Everything

While we ship primarily as a React component, Rulebricks Embedded is designed to work within any modern frontend stack. The component is self-contained and can be mounted into:

- **Angular & Vue**: Using standard wrapper patterns or mounting helpers.
- **Next.js / Remix**: Full support for Server Components and SSR.
- **.NET / Blazor**: Embeddable within Razor pages or Blazor components via JS interop.
- **Internal Tools**: Easily mountable in Retool (custom component) or plain HTML/JS dashboards.

## API Reference & Customization
/embedding-rulebricks/api-reference-and-customization

This reference covers the `` component props, the server-side helper, customization options, and troubleshooting.

# API Reference & Customization

This reference covers the `<Rule>` component props, the server-side helper, customization options, and troubleshooting.

## Component API

### `<Rule />`

The main React component for the embedded editor.

```jsx

```

| Prop              | Type      | Default      | Description                                      |
| :---------------- | :-------- | :----------- | :----------------------------------------------- |
| `embedToken`      | `string`  | **Required** | The JWT generated by your backend.               |
| `height`          | `number`  | `600`        | Height of the editor in pixels.                  |
| `apiBaseUrl`      | `string`  | (Origin)     | Base URL for API calls (use for self-hosted).    |
| `showControls`    | `boolean` | `true`       | Show/hide the top toolbar (Undo, Redo, Publish). |
| `showFooter`      | `boolean` | `true`       | Show/hide the status bar (row count, search).    |
| `showRowSettings` | `boolean` | `false`      | Show gear icon for row-level settings.           |
| `requestLabel`    | `string`  | "Request"    | Custom label for the input columns section.      |
| `responseLabel`   | `string`  | "Response"   | Custom label for the output columns section.     |
| `onPublish`       | `func`    | -            | Callback fired after publishing `(e) => {}`.     |
| `onError`         | `func`    | -            | Callback fired on errors `(e) => {}`.            |

### `createEmbedToken(options)`

Server-side helper to generate tokens.

```javascript

const { token } = await createEmbedToken({
  apiKey: 'rb_live_...', // Required
  ruleId: 'rule_123', // Required
  expiresIn: 3600, // Optional (default: 1h)
  baseUrl: '...', // Optional (for self-hosted)
})
```

## Programmatic Control (Refs)

You can interact with the component instance using a React Ref. This is useful for building external "Test" buttons or custom export flows.

```jsx
const ruleRef = useRef(null)
// ...
;<Rule ref={ruleRef} embedToken={token} />
```

### Methods

- **`testRule(payload)`**: Runs a test against the current rule state. Highlights matching rows in the UI.
  ```javascript
  const result = await ruleRef.current.testRule({ age: 25, type: 'standard' })
  console.log(result.response) // The rule output
  console.log(result.successIdxs) // Indices of matching rows
  ```
- **`clearTestResults()`**: Clears the visual highlighting from a previous test.
- **`getRule()`**: Returns the current JSON structure of the rule.
- **`isTestLoading()`**: Returns `true` if a test is currently executing.

## Branding & Customization

The embed **automatically inherits** branding from your Rulebricks organization settings (Colors, Fonts, Border Radius). No client-side config is needed for this.

### Manual Overrides (CSS)

If you need to override styles manually or create a dark mode workaround, target the `data-embed-container` attribute to ensure scoped styling.

```css
/* Override primary color */
[data-embed-container='true'] {
  --rb-color-primary: #ff5733;
  --rb-color-accent: #33ff57;
  --rb-font-family: 'Inter', sans-serif;
  --rb-border-radius: 8px;
}

/* Dark mode override example */
[data-embed-container='true'] .bg-white {
  background-color: #1e1e1e !important;
  color: #ffffff !important;
}
```

## Troubleshooting

| Error                         | Possible Cause                           | Solution                                        |
| :---------------------------- | :--------------------------------------- | :---------------------------------------------- |
| **"No embed token provided"** | `embedToken` prop is null/undefined.     | Ensure your fetch completes before rendering.   |
| **HTTP 401 / Invalid Token**  | Token expired or API Key revoked.        | Generate a fresh token; check API key validity. |
| **HTTP 403 / Access Denied**  | User/Key lacks permission for this rule. | Check Rulebricks permissions for that API key.  |
| **Styles missing/broken**     | CSS file not imported.                   | Add `import "@rulebricks/embedded/styles.css"`. |
| **Hydration Error (Next.js)** | SSR mismatch.                            | Use `next/dynamic` with `{ ssr: false }`.       |

### Debugging

Pass an `onError` handler to the component to catch and log issues:

```jsx
<Rule onError={(e) => console.error("Rulebricks Error:", e)} ... />
```

## Core Concepts & Security
/embedding-rulebricks/core-concepts-and-security

Understanding the architecture, permission model, and security best practices is crucial for a production deployment of Rulebricks Embedded.

# Core Concepts & Security

Understanding the architecture, permission model, and security best practices is crucial for a production deployment of Rulebricks Embedded.

## Architecture & Token Flow

Rulebricks Embedded uses a **token-based architecture** to ensure your API keys never reach the client.

1.  **Client**: Your app requests access to a rule (e.g., when a user opens the editor).
2.  **Server**: Your backend authenticates the user and uses your **Rulebricks API Key** to generate a short-lived, scoped `embedToken`.
3.  **Rulebricks API**: Validates your key and the user's access, then returns a signed JWT.
4.  **Client**: The `<Rule>` component initializes with this token. All subsequent reads/writes use this token.

```mermaid
sequenceDiagram
    participant User as Client App
    participant Server as Your Backend
    participant RB as Rulebricks API

    User->>Server: Request Embed Token
    Server->>RB: POST /embed/token (with API Key)
    RB-->>Server: Return JWT Token
    Server-->>User: Return JWT Token
    User->>RB: <Rule embedToken={jwt} /> (Direct API calls)
```

## API Keys & Permissions

Permissions in the embed are **inherited** from the API key used to generate the token.

### Hierarchy

- **Organization Admin Key**: Full access to all rules.
- **User Key**: Access only to rules owned by or shared with that specific user.

### Roles & Capabilities

The embed automatically adapts its UI based on the permissions granted:

| Permission      | Effect in Embed                                                                                   |
| :-------------- | :------------------------------------------------------------------------------------------------ |
| **Read-Only**   | User can view rules but cannot edit cells or add rows. Controls are hidden.                       |
| **Editor**      | User can modify values and structure but cannot publish to production.                            |
| **Publisher**   | User can edit and has access to the "Publish" button.                                             |
| **Schema View** | Controls whether users see technical field names (`customer_id`) or descriptions (`Customer ID`). |

**Example**: To give a customer read-only access to their specific rule:

1.  Use an API key associated with a read-only role (or the specific customer's key).
2.  Generate a token for that rule ID.
3.  The embed will render in "Read-Only" mode automatically.

## Security Best Practices

### 1. Never Expose API Keys

**Never** use your Rulebricks API key in client-side code. Always generate tokens on your server.

❌ **Bad:**

```javascript
// Client-side
fetch('https://rulebricks.com/api/embed/token', {
  headers: { 'x-api-key': 'rb_live_...' }, // EXPOSED!
})
```

✅ **Good:**

```javascript
// Server-side
createEmbedToken({ apiKey: process.env.RULEBRICKS_API_KEY, ... })
```

### 2. Token Expiration

Set an appropriate expiration time (`expiresIn`). The default is 1 hour (3600s).

- **Short (15m)**: High security, requires refresh logic.
- **Long (8h)**: Better UX for internal tools.

### 3. Content Security Policy (CSP)

If your app uses CSP, allow connections to Rulebricks:

```html
<meta
  http-equiv="Content-Security-Policy"
  content="connect-src 'self' https://rulebricks.com;"
/>
```

## Installation & Setup
/embedding-rulebricks/installation-and-setup

Install the package using your preferred package manager:

# Installation & Setup

Install the package using your preferred package manager:

```bash
npm install @rulebricks/embedded
# or
yarn add @rulebricks/embedded
# or
pnpm add @rulebricks/embedded
```

> **Note**: Requires React 18+.

## Quick Start

Getting up and running involves two steps: generating a secure token on your backend, and rendering the component on your frontend.

### 1. Server-Side: Generate an Embed Token

You must generate an access token on your server to keep your API key secure.

```javascript
// Node.js / Next.js API Route

export async function POST(request) {
  // 1. Authenticate your user
  const user = await getCurrentUser()

  // 2. Generate the token
  const { token } = await createEmbedToken({
    apiKey: process.env.RULEBRICKS_API_KEY, // Your secret key
    // Get this ID from the admin API, dashboard URL, or published URL slug
    ruleId: 'abc123', // The rule to load
    baseUrl: 'https://rulebricks.com', // Optional: for self-hosted
    expiresIn: 3600, // Token validity in seconds
  })

  return Response.json({ token })
}
```

### 2. Client-Side: Render the Component

Fetch the token and pass it to the `<Rule>` component. Don't forget the CSS import!

```jsx

import '@rulebricks/embedded/styles.css' // Required!

export default function RuleEditor({ ruleId }) {
  const [token, setToken] = useState(null)

  useEffect(() => {
    fetch('/api/generate-token', { method: 'POST' })
      .then((res) => res.json())
      .then((data) => setToken(data.token))
  }, [])

  if (!token) return <div>Loading...</div>

  return (
    <Rule
      embedToken={token}
      height={600}
      onPublish={(e) => console.log('Just Published:', e.rule)}
      onError={(e) => console.error('Error:', e)}
    />
  )
}
```

## Using your Rules
/getting-started/integration

Integrating Rulebricks into your workflows is easy, and there are a few ways you can do it. Learn how to integrate Rulebricks here.

# Using your Rules

Once you’ve finished configuring and testing your rule, it's time to publish your rule, and integrate it into your work.

You'll need to decide, given the technologies your business already uses, what the best way to connect it to your existing systems looks like.

We offer many ways to use your rules across different levels of technical expertise– you do not need to learn or employ all of them, merely pick out the one that works best in your situation.

## For Business Users

A great place to start as a less technically-involved Rulebricks user is to think about when you want your rule to actually run/be triggered. This will give you a bunch of relevant information to what's best for you at once– what data will be available, who is actually providing that data/where it's coming from, etcetera.

### Via Forms

If you want to use your rule to calculate something every once in a while, or help your users do so, forms are perfect for you. You don't actually have to build a form once you have your rule created– we generate the form for you using the logic in your rule! These forms can be embedded on your site and present your company's branding.

[Learn more about using forms →](/building-forms/creating-a-form)

### Via Zapier

This probably mainly works if you have heard of or are already familiar with Zapier, but we have a pretty powerful "Make Decision" action on Zapier that allows you to use Rules in lieu of Paths/Filters to perform complex comparisons/outcome determinations.

![Untitled](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/Go%20live%20and%20integrate%20your%20rule/Untitled.png)

The action will guide you fully through the process of connecting your Rulebricks account to Zapier, connecting a rule to your Zap, and finally mapping data in your automation to send to the rule. If you ever run into issues with the action that do not seem clear, try deleting and re-creating the entire step, and if you’re still stuck, send us a quick email.

[Find us on Zapier →](https://zapier.com/apps/rulebricks/integrations)

### Developer Handoff

Given that you've created and published a rule– Rulebricks is incredibly quick for developers to integrate into existing applications, often taking less than half an hour to implement. What's more, they only need to set up each rule for you once– subsequent edits to the rule and changes to the decision table within will take effect seamlessly.

## For Developers

### Via API/SDK

A few API endpoints are made available for developers to effectively integrate a Rulebricks decision from anywhere. We also offer fully-featured SDK's in most programming languages that are dead-easy to install and use.

The particular endpoints that execute decision making assets are below, and all require the `x-api-key` header (with the API key found on your dashboard).

`/solve/[slug]` – **POST** your JSON request data to this endpoint to run your rule

`/flows/[id]` – **POST** your JSON request data to a Rule Flow you've created using this rule to run it as part of a larger sequence

Read more about these endpoints in our [API Reference](/api-reference), and use the tab there in the top right to switch to our SDK documentation in the language of your choice.

### Via Flows

Flows will still require use of our API/SDK noted above, but contain within them powerful abilities to chain rules, or connect them with databases or internal services.

One particularly powerful component of Flows is that flows allow you to leverage powerful caching mechanisms on any data fetching you're doing within– meaning you can create high-performance, low-latency Flows that still perform otherwise time consuming tasks like fetching data from an API or querying an SQL database.

Flows also allow you to explode lists and run rules against each object within.

[Learn more about Flow capabilities →](/integrating-rules/rule-flows)

## Requests & Responses
/getting-started/requests-and-responses

Requests and responses are the inputs and outputs to any rule in Rulebricks. Learn how to configure them here.

# Requests & Responses

## Inputs and outputs

Request & Response objects are, respectively, the inputs and outputs to any rule in Rulebricks. Specifically, they are any object in JSON notation, as previewed at the end of the last section.

Let’s look at those one more time:

### Request Object

```json
{
  "industry": "Financial technology",
  "company_size": 4400,
  "location": {
    "city": "San Francisco",
    "state": "California",
    "country": "United States"
  },
  "date_form_completed": "2022-11-23"
}
```

### Result Object

```json
{
  "score": 90
}
```

## Inputs → "Request Columns"

**To begin configuring any rule in Rulebricks, you require a Request Object**.

Rulebricks uses the attributes available in the JSON object provided to initialize the columns of an empty decision table. Most applications will document examples of objects their platform outputs from various API endpoints and integrations on their website, but you're also free to create your own example objects/formats based on your needs for a particular decision point.

Each property in the JSON object corresponds with a column in your decision table, either as a "Request" column, within which you can define conditions against data, or a "Response" column within which you can define outcome data.

A fresh decision table initialized in Rulebricks using the request object a bit above might look like:

### **Request Columns**

| Industry `industry` | Company Size `company_size` | Location City `location.city` | Location State `location.state` | Location Country `location.country` | Date Form Completed `date_form_completed` |
| ------------------- | --------------------------- | ----------------------------- | ------------------------------- | ----------------------------------- | ----------------------------------------- |
|                     |                             |                               |                                 |                                     |                                           |

Something that isn’t shown here is that the table also identifies what kind of data is in each column, determining whether it contains text, numbers, booleans, dates, or lists.

From here, you’re able to hide columns you’d like to ignore, rename columns to make information more meaningful, and set default values for information that is missing from future request objects.

## Outputs → "Response Columns"

**To receive any information from a rule, you require a Response Object.**

Much like the request object, Rulebricks will initialize columns to match any attributes you provide in this object. Unlike the request object, the response object doesn’t come from anywhere– you probably have to create it based on what you're trying to use rules to determine, and you’re free to add or remove any fields as they come to mind.

#### Functions

Response columns can uniquely also be "Function" type, which is a powerful type that essentially lets you create Excel-style formulas that can calculate using any of the input data or other output data. For example, if we override the price response column type in our running example to be a Function type column, we can simply type in something like `50 + company_size / 1.2` into cells in the price response columns.

## Build your first rule
/getting-started/start-building

Build your first rule in Rulebricks. Learn how to create a rule, add conditions, and test your rule here.

# Build your first rule

Let's get started building a rule. First, go to the [dashboard](https://rulebricks.com/dashboard). If this is your first time creating a rule, it will look something like this:

![Dashboard Entry](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/start-building/app-entry.png)

## Creating Your First Rule

<Steps>

### Create a new rule

Click the **Create Rule** button in the top right. You'll be presented with a dialog to configure your new rule.

![Create Rule Modal](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/start-building/create-new-rule-modal.png)

### Select "From Scratch"

Choose **From Scratch** to build a rule from the ground up (just for this tutorial– we actually recommend using our wizard or a template if you'd like to skip to seeing what things look like in Rulebricks right away).

![From Scratch](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/start-building/from-scratch.png)

### Open the editor

Your rule will be created, and you'll be dropped into the **rule editor**. This is where you'll define your decision logic.

![Table Editor Entry](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/start-building/table-editor-entry.png)

</Steps>

## Understanding the Rule Table

The **rule table** is the main area where you define your decision logic. It's split into two sections:

- **Request (Conditions)**: The left side contains the conditions that determine which row matches
- **Response (Results)**: The right side contains the values returned when a row matches

At the top of each column is the **column header** showing the column name and data type icon.

### Data Types

Rulebricks supports several types of data commonly used in decision-making:

<Tabs items={['Text', 'Boolean', 'Number', 'Date', 'List', 'Function']}>
<Tabs.Tab>

<IconAlphabetLatin
  size={64}
  className="bg-green-200 text-green-500 rounded-md border border-green-500 p-2"
/>

Text is a string of characters.

```jsx
'Hello, world!'
'approved'
```

Example operations: Equals, contains, starts with, is valid email.

</Tabs.Tab>
<Tabs.Tab>

<IconCheckbox
  size={64}
  className="bg-purple-200 text-purple-500 rounded-md border border-purple-500 p-2"
/>

A boolean is a logical value: true or false.

```jsx
true
false
```

Example operations: Is true, is false.

</Tabs.Tab>
<Tabs.Tab>

<Icon123
  size={64}
  className="bg-red-100 text-red-800 rounded-md border border-red-300 p-2"
/>

A number is a numerical value—integer or floating-point.

```jsx
3.14
42 - 100
```

Example operations: Greater than, less than, equal to, within range.

</Tabs.Tab>
<Tabs.Tab>

<IconCalendar
  size={64}
  className="bg-orange-200 text-orange-500 rounded-md border border-orange-500 p-2"
/>

A date is a calendar date and time in ISO 8601 format.

```jsx
'2024-01-15T10:30:00Z'
```

Example operations: Before, after, within last N days.

</Tabs.Tab>

<Tabs.Tab>

<IconBrackets
  size={64}
  className="bg-sky-100 text-sky-800 rounded-md border border-sky-300 p-2"
/>

A list is a collection of items. Each item in the list can be of a different type.

```jsx
[1, 2, 3]
['apple', 'banana', 'cherry']
```

Example operations: Checking if a list contains a value, checking if a list is empty, checking length.

</Tabs.Tab>
<Tabs.Tab>

<IconMathFunction
  size={64}
  className="bg-neutral-200 text-neutral-500 rounded-md border border-neutral-500 p-2"
/>

A function is a mathematical expression that computes a value.

<Callout>
  Functions can only be used in the response section to compute values based on
  request data.
</Callout>

```jsx
price * 1.08 // Add 8% tax
```

</Tabs.Tab>
</Tabs>

Want to see a full list of the operators supported for each type on Rulebricks? Check out our [Operator Index](https://rulebricks.com/operators).

## Setting Up Your Schema

The schema defines what data your rule accepts (request) and returns (response).

<Steps>

### Open the Schema Editor

Click on the **Schema** button to open the schema editor. This is where you define your input and output fields.

<Tabs items={['Simple', 'JSON Mode']}>
<Tabs.Tab>

Simple mode gives you a clear view of your inputs. Click the colored type icons on each item to change its type.

![Schema Editor](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/start-building/schema-editor.png)

</Tabs.Tab>
<Tabs.Tab>
You can also use **JSON mode** to paste a sample request object directly:

![Schema Editor JSON Mode](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/start-building/schema-editor-json-mode.png)
</Tabs.Tab>
</Tabs>

### Configure the Request Schema

Let's create a simple pricing rule. Set up your request schema with:

```json
{
  "price": 40,
  "date_purchased": "2024-01-15T10:30:00Z",
  "gift": false
}
```

Click **Set Schema** to apply the changes.

![Set Schema](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/start-building/set-schema.png)

### View Column Details

You can click on any column header to see and edit its details, including type and display name.

![Column Details](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/start-building/column-details.png)

### Save the Schema

Click **Save** to apply your schema changes.

![Save Schema](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/start-building/save-schema.png)

### Set Up the Response Schema

Configure what your rule returns. For our example:

```json
{
  "result": true
}
```

![Set Response Schema](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/start-building/set-save-response-schema.png)

</Steps>

## Adding Conditions and Results

Now let's add the actual decision logic to your rule.

<Steps>

### Add a condition

Click on a condition cell in the **price** column and add a condition. Let's check if the price is greater than 10.

![Create Price Condition](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/start-building/create-price-condition.png)

### Set the result

Click on the result cell in the **result** column and set the value to **true**.

![Create Result](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/start-building/create-result.png)

</Steps>

## Testing Your Rule

<Steps>

### Open the Test tab

Click on the **Test** tab in the sidebar to test your rule locally.

![Test Rule](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/start-building/test-rule.png)

### Test with matching data

Enter a test request:

```json
{
  "price": 20
}
```

Click **Test**. You should see the row highlight in green (conditions matched) and blue (result returned), with a 200 OK response.

### Test with non-matching data

Try a price that doesn't match:

```json
{
  "price": 5
}
```

![Nothing Hit](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/start-building/nothing-hit.png)

Since the price is not greater than 10, no row matches, and you'll get a 400 error.

</Steps>

## Adding a Catch-All Row

To handle cases where no specific condition matches, add a catch-all row.

<Steps>

### Add a new row

Click **Add Row** in the toolbar to add a blank row.

![Add Catch All](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/start-building/add-catch-all.png)

### Leave conditions as "Any"

The new row will have **Any** for all conditions, meaning it matches any input that doesn't match earlier rows.

### Set the catch-all result

Set the result to **false** for the catch-all row.

### Test again

Test with the price of 5 again:

![Catch All Hit](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/start-building/catch-all-hit.png)

Now the catch-all row matches, returning `result: false` with a 200 OK response.

</Steps>

## Final Rule State

Your completed rule should look like this:

![Final Rule State](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/start-building/final-rule-state.png)

**Row 1**: If price > 10 → result: true
**Row 2**: Catch-all → result: false

## How Row Matching Works

Rulebricks evaluates rows **top to bottom**:

1. For each row, all conditions in the request section are checked
2. If **all** conditions in a row pass, that row "matches"
3. The **first matching row** determines the response
4. If **no rows match**, an error is returned (unless you have a catch-all)

<Callout>
  Cells highlighted in **green** indicate conditions that passed. Cells
  highlighted in **red** indicate conditions that failed. Cells highlighted in
  **blue** show the result that was returned.
</Callout>

---

That's it! You've built and tested your first rule. Continue to the next section to learn how to [publish your rule](/managing-rules/publishing-rules) and call it from your application.

## What is a rule?
/getting-started/what-is-a-rule

Understanding what a rule is in Rulebricks is the first step to building powerful automations. Learn more about rules here.

# What is a rule?

## A quick example

The fastest way to understand how rules work is by example.

Let’s say we’re working at a software company and have a few automations on Zapier that help us engage prospects that sign up on our website, follow up with them as potential customers, and add them to our CRM, and we’re looking to start scoring these prospects so we have a better understanding of which are more likely to convert and actually provide us with their business.

Our ideal customer could be anyone, but for the purposes of this example let’s say we’re looking specifically for startups in financial technology– these are the people most likely to buy our software. From some form responses and lead enrichment technologies, we have a bunch of data on each prospect, and we mainly need to look for industry and company size matches.

There might be some exceptions here, however– if someone from a particularly big company reaches out, we’ll probably at least want to talk with them to understand their needs, so we can score them highly. And our market might be local to the US, so we might like that as well.

From what we’ve written down so far, a decision table to score leads for our business might look like the following:

### **Conditions → Results**

| Industry   | Company Size | HQ Location | Last Contact  |     | Score |
| ---------- | ------------ | ----------- | ------------- | --- | ----- |
| Fintech    | < 500        | in US       | Any           | →   | 100   |
| Fintech    | > 2,000      | in US       | < 30 days ago | →   | 90    |
| Fintech    | Any          | not in US   | < 30 days ago | →   | 80    |
| Finance    | Any          | in US       | < 30 days ago | →   | 70    |
| Insurance  | Any          | in US       | < 30 days ago | →   | 50    |
| Government | Any          | in US       | < 30 days ago | →   | 50    |
| Any        | Any          | in US       | Any           | →   | 10    |
| Any        | Any          | Any         | Any           | →   | 0     |

Unpacking this is quite straightforward.

Using our data on a prospect, we can identify if they meet all the comparisons in a row, looking at each row one at a time, from top to bottom. If we have a large US fintech that’s recently reached out, we’d find they meet all the conditions in the second row and stop there.

We then look at the results table for that particular row– any values in the second row of the results table are now our output and returned as results of this decision. The decision table above only has one column, so only the number 90 for the score is returned, but we could easily modify it to return other information along with this as well.

All the “Any” values at the bottom of the table are our catch-all, as we’ll want to return something if none of the rows match our data. In Rulebricks, you’re able to simply provide default values that help eliminate some of the need to explicitly define these rows everywhere.

#### Terminology

- **Comparisons**: The individual logical checks we’re making in our decision table. Each comparison is a single check that must be true for a row (condition) to be considered a match.
- **Conditions**: Each condition is a row in the table, i.e. a group of comparisons that must all be true for a row to be considered a match.
- **Request Data (Object)**: The incoming data for each decision we are using our rule to make using the left side of the table, i.e. the data that is being compared to the conditions.
- **Results/Response Data (Object)**: The outgoing data on the right side of the table, i.e. the data that is returned from our rule when a condition row is considered a match.

Some terminology is used interchangeably, but these are the most common terms you’ll see when working on Rulebricks.

## What this actually looks like

Decision tables are fairly simple conceptually, and can be straightforward enough to set up on Rulebricks, but how do they interact with real world data? The decision above requires a **Request Object** to configure, and return a **Result Object**, further discussed in the next section, and previewed below.

#### Request Object

```json
{
  "industry": "Financial technology",
  "company_size": 4400,
  "location": {
    "city": "San Francisco",
    "state": "California",
    "country": "United States"
  },
  "date_form_completed": "2022-11-23"
}
```

#### Result Object

```json
{
  "score": 90
}
```

<Callout type="info">
If you look closely, you’ll notice some details that make this decision possible that aren’t obvious– the data is not *exactly* what we represented it in the decision table, and the date is just text, so it’s not immediately clear how to set up a comparison for that.

Here we can start seeing a few of the logistics around defining rules that Rulebricks can make particularly easy.

</Callout>

## Flow Functions
/integrating-rules/flow-capabilities

Flows are a powerful way to chain together multiple rules, alongside calls to external services, and structure complex decision-making workflows. Explore their latest capabilities here.

# Flow Functions

While your configurable rules are undoubtedly the most valuable pieces Flows expose, we offer several built-in functions to help your team collect data from external sources and run logic conditionally.

We call these "flow functions"– special operations you can use in your flows to perform various actions beyond rule execution. Below are all the available flow function node types– but do try our application or reach out to get information on our latest capabilities.

## Continue If

<FlowNodeCard
  colorScheme="orange"
  icon={<IconRouteAltRight className="w-3 h-3 rotate-90" />}
  name="Continue If"
  description="Evaluate if an input property is true/truthy and only proceed with specific data if so."
/>

![Continue If](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/integrating-rules/continue-if.png)

Proceed based on one of four selectable conditions:

- If a specific property is **"truthy"** (not empty, non-zero, non-null)
- If a specific property is exactly **`true`**
- If a specific property is exactly **`false`**
- If a specific property is **"falsy"** (empty list, zero, null, or false)

If the condition is met, the flow continues along the exiting edges. Use two "Continue If" nodes to model if/else logic.

<Callout>
  All data you want to proceed with after a Continue If node must be wired in as
  inputs.
</Callout>

## Result Object

<FlowNodeCard
  colorScheme="amber"
  icon={<IconBraces className="w-3 h-3" />}
  name="Result Object"
  description="Nest data in a result object within a specific key to better organize the final output of your flow."
/>

![Result Object](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/integrating-rules/result.png)

The final output of your flow. It collects results from all preceding nodes and returns them as the flow's response.

- You can use multiple Result Object nodes with unique keys
- **Required**: Every flow must end with at least one Result Object node

## Lookup Table

<FlowNodeCard
  colorScheme="green"
  icon={<IconBrandCitymapper className="w-3 h-3" />}
  name="Lookup Table"
  description="Map an input 'key' to any output 'value' based on a table of key & value pairs."
/>

![Lookup Table](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/integrating-rules/lookup-table.png)

Look up a value in a table and return a corresponding value if an exact match is found. Works well with Continue If nodes by returning true/false based on lookup results.

## Run Code

<FlowNodeCard
  colorScheme="sky"
  icon={<IconCode className="w-3 h-3" />}
  name="Run Code"
  description="Execute custom JavaScript to perform operations like computing data, making API calls, or integrating with external services."
/>

![Run Code](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/integrating-rules/code.png)

Run custom JavaScript code using data from your flow. Useful for:

- Making calls to external services
- Performing complex calculations
- Custom string formatting or data transformation

Available libraries: `fetch`, `moment`, `lodash`, and more.

Access connected values via the `inputs` dictionary and return values via the `outputs` dictionary.

```javascript
// Example: Calculate discount
const total = inputs.subtotal
const discount = total > 100 ? total * 0.1 : 0
outputs['discount'] = discount
outputs['final_total'] = total - discount
```

## SOAP Request

<FlowNodeCard
  colorScheme="cyan"
  icon={<IconCloud className="w-3 h-3" />}
  name="SOAP Request"
  description="Connect to SOAP/XML web services using WSDL to call operations on enterprise systems."
/>

Connect to SOAP/XML web services to integrate with legacy enterprise systems. Upload a WSDL file to auto-discover available operations.

Features:

- WSDL-based service discovery
- Support for complex XML request/response structures
- Built-in authentication options

## Database Query

<FlowNodeCard
  colorScheme="blue"
  icon={<IconDatabase className="w-3 h-3" />}
  name="Database Query"
  description="Query a PostgreSQL database to fetch data from an external resource and use it in this flow."
/>

![Database Query](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/integrating-rules/db.png)

Query a PostgreSQL, MSSQL, or MySQL database, and return results. Variables from your flow can be used in the query.

Features:

- Use `rows` with a For Each node or send directly to Result Object
- Built-in 1-minute caching for performance

## API Request

<FlowNodeCard
  colorScheme="indigo"
  icon={<IconApiApp className="w-3 h-3" />}
  name="API Request"
  description="Make an HTTP request to any API to fetch & send data from/to external resources."
/>

![API Request](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/integrating-rules/api.png)

Make HTTP requests to external APIs. Variables from your flow can be used in the URL, headers, and body.

Features:

- GET, POST, PUT, DELETE methods
- Custom headers and authentication
- Built-in 1-minute caching, customizable cache key

## For Each

<FlowNodeCard
  colorScheme="red"
  icon={<IconBracketsContain className="w-3 h-3" />}
  name="For Each"
  description="Perform following operations on each available item in a non-empty list of values/objects, and return a list of results."
/>

![For Each](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/integrating-rules/for-each.png)

Iterate over a list of items and apply a rule to each one. Perfect for:

- Transforming collections of objects
- Processing lists of orders, users, or products
- Batch operations

<Callout type="warning">
  For Each nodes must culminate in a Result Object node. Values inside the loop
  cannot connect to parts of the flow outside that loop (indicated by different
  edge colors).
</Callout>

## AI Inference

<FlowNodeCard
  colorScheme="fuchsia"
  icon={<IconSparkles className="w-3 h-3" />}
  name="AI Inference"
  description="Intelligently parse out structured properties from text using AI models to evaluate rules against."
/>

![AI Inference](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/integrating-rules/ai-inference.png)

Extract structured data from text using OpenAI. Useful for:

- Parsing emails and reports
- Extracting specific information from documents
- NLP preprocessing before rule execution

To use:

1. Connect a text input
2. Define target labels to extract
3. Click "Run Inference"

## Vault

<FlowNodeCard
  colorScheme="slate"
  icon={<IconLock className="w-3 h-3" />}
  name="Vault"
  description="Connect to secure key vaults to retrieve secrets at runtime without exposing credentials."
/>

![Vault](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/integrating-rules/vault.png)

Securely retrieve sensitive information from cloud secrets managers (AWS, GCP, Azure).

Security features:

- Secrets never appear in clear text in the flow
- Cannot be logged or returned in output
- Only accessible within Run Code nodes

## Context Operation

<FlowNodeCard
  colorScheme="violet"
  icon={<IconFocusCentered className="w-3 h-3" />}
  name="Context Operation"
  description="Read, update, or delete context data. Use for stateful context data operations within flows."
/>

Interact with [Rulebricks Contexts](/contexts) directly from your flow. Perfect for:

- Reading entity data to use in rule evaluation
- Updating context properties based on flow outcomes
- Deleting or archiving context records

<Callout type="info">
  Context Operations require a configured Context in your workspace. See the
  [Contexts documentation](/contexts) for setup instructions.
</Callout>

## Send Notification

<FlowNodeCard
  colorScheme="neutral"
  icon={<IconBell className="w-3 h-3" />}
  name="Send Notification"
  description="Send multi-channel alerts via Email, Slack, Discord, or PagerDuty based on flow data."
/>

Trigger notifications to your team or external systems based on flow outcomes. Supports multiple channels:

- **Email**: Send templated emails with flow data
- **Slack**: Post messages to channels or DMs
- **Discord**: Send webhook messages to Discord servers
- **PagerDuty**: Create incidents for on-call alerting

<Callout>
  Configure notification channels in your workspace settings before using this
  node.
</Callout>

## Flows in Rulebricks
/integrating-rules/rule-flows

Flows in Rulebricks are a powerful way to chain together multiple rules, alongside calls to external services, and structure complex decision-making workflows. Learn how to create a Rule Flow here.

# Flows in Rulebricks

![Flow Header](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/flows/flow-header.png)

Flows are a powerful way to chain together multiple rules, alongside calls to external services, and structure complex decision-making workflows.

These are particularly useful when you have a series of decisions that need to be made in a specific order, or when you'd like to separate logic into multiple rules for easier maintenance of your decision-making logic.

<Callout type="info">
  Flows are built with external data and massive scale in mind, and can help you
  easily cache data consumed from external sources within to support uniquely
  low latencies and high throughput.
</Callout>

## Flow Reactivity

Unique to Rulebricks, the Rulebricks Flow editor is **reactive**— as you make changes to rule input fields, the editor automatically visualizes your data flow in real-time. This makes it incredibly easy to see how your flow behaves _as you build it_ without repeated end-to-end build/test cycles.

<div className="rounded-lg my-8 shadow-lg">
  <video
    width="1920"
    height="1080"
    autoPlay
    muted
    loop
    preload="auto"
    className="rounded-lg"
  >
    <source src="https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/integrating-rules/flow-reactivity.m4v" />
    Your browser does not support the video tag
  </video>
</div>

Reactivity applies to all sequences of nodes until certain execution or query nodes are reached. These nodes pause execution until you manually click the run button, preventing accidental spam to external services.

While this feature exists to help you model your flow while understanding what is happening to the actual data as it moves through, it is not a perfect guarantee of how your Flow will behave _end-to-end_– for that, simply use the "Try" or "Test" tabs, available in the sidebar.

## Creating a Rule Flow

<Steps>

### Navigate to the Flows tab

Open the Rulebricks dashboard and click the **Flows** tab.

### Create a new flow

Click the **Create Flow** button to create a new Rule Flow.

![Create Flow Modal](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/flows/create-flow-modal-origin.png)

<Callout type="warning">
  You must have at least one published rule in your workspace to use as a
  starting point for your flow.
</Callout>

### Build your flow

You'll be taken to the Flow editor where you can:

- Drag and drop published rules from the sidebar onto the canvas
- Add flow functions (code execution, API calls, etc.)
- Connect nodes together to define the execution order

![Flow Editor Entry](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/flows/flow-editor-entry.png)

### Connect your nodes

Drag from an output handle of one node to the input of another to connect them. Data flows through the connections.

![Try Connecting](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/flows/try-connecting.png)

</Steps>

## Team Templates
/managing-rules/creating-templates

Create reusable rule templates for your team. Templates share proven schemas and decision patterns across your organization.

# Team Templates

Templates let you capture a well-designed rule and make it available for your whole team to reuse, or for customers to use as a starting point.

When someone creates a new rule from a template, they get the schema, sample conditions, settings, and test cases, ready for them to customize.

While exported RBM files do save and contain the histories of exported decision assets, users importing them as Team Templates will not receive these histories.

## Creating a Template

<Steps>

### Build the rule you want to share

Create a rule with the schema, conditions, and settings you want others to start from. Include test cases if you want them copied to new rules.

### Save as template

Navigate to **Team → Templates** and click **Create Template**, or use the **Create Template** button in the rule editor.

![Team Templates Tab](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/templates/team-templates-tab-2.png)

You can also upload `.rbm` files directly to your templates.

![Upload RBM File](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/templates/upload-rbm-file-2.png)

</Steps>

## Using a Template

When creating a new rule, click the **Templates** tab in the create dialog. Team Templates should appear by default. If you're not seeing them, it's possible the template has been assigned to a specific User Group, and you may not be part of it.

![Find Team Templates](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/templates/find-team-templates.png)

## Managing Templates

- **Administrators** and **Developers** can create and delete templates
- All team members can view and use templates
- Templates can't be edited—create a new version with a clear name like `"Credit Check - v2"`

<Callout>
  Templates can have tenancy– if a template is assigned to a particular user
  group, only users belonging to that group will see it. Developers (usually
  unassigned to any user group) will only see templates that do not have any
  user group.
</Callout>

## Or, Duplicate

If templates feel heavyweight for your needs, users can always find an existing rule and click **Duplicate**. This works well for quick iterations or one-off copies.

## Exporting Rules & Flows
/managing-rules/exporting-rules

Export rules and flows as .rbm files for backup, version control, or sharing across workspaces.

# Exporting Rules & Flows

Export rules and flows as `.rbm` files to back them up, share them across workspaces, or store them in version control.

## Exporting

<Steps>

### Open the rule or flow

Navigate to the asset you want to export.

### Click Export

![Export Rule Button](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/exporting-rules/export-rule-button.png)

### Name your export

![Name Export](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/exporting-rules/name-export.png)

### Review dependencies

Exports intelligently bundle all assets related to the item you're exporting. Exporting Flows also exports the rules within. Exporting rules also exports any values those rules reference.

This ensures you won't have to think about dependencies while moving around assets- all relevant data is self-contained within a single file.

![Exports Bundled Values](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/exporting-rules/export-bundled-values.png)

### Download

Click **Export** to download the `.rbm` file.

</Steps>

## Importing

Click **Create → Import** in the dashboard and upload an `.rbm` file.

We offer two conflict resolution schemes, that help address what happens if you're pulling in data you might already have a local copy of.

![Import View Conflict](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/exporting-rules/import-view-conflict.png)

## What's Included

- **Rules** export with all conditions, results, schema, referenced dynamic values, settings, test cases, and publication histories.
- **Flows** export the complete flow definition plus all embedded rules.

We do not obfuscate our schemas in exported files and encourage users to review how their assets are stored. RBM files are stored as large amounts of JSON, but they are structured in a way your team may be able to build custom tools directly against them!

## Publishing Rules
/managing-rules/publishing-rules

Publishing a rule in Rulebricks makes it available for use in your applications. Learn how to publish, version, and compare rules.

# Publishing Rules

Publishing makes your rule available via the API, in Forms, and in Rule Flows. Every publish creates a new version—you can target specific versions, compare changes, and roll back if needed.

## Create a new version

<Steps>

### Open the publish menu

Click the **Publish** button in the top right corner of the rule editor.

![Publish Button](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/managing-rules/publishing-rules-1.png)

### Publish your rule

You'll see a history of prior versions. Click **Publish** to create a new version.

![Publish Menu](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/managing-rules/publishing-rules-2.png)

<Callout type="info">
  You can click on the colored tags in this menu ("Conditions", "Request
  Schema", etc.) to see a summary of what changed between versions.
</Callout>

</Steps>

## Versioning

Each publish creates a numbered version (v1, v2, etc.). Target specific versions by appending the number to the rule slug:

- `hlDPsJMVGQ` → latest version
- `hlDPsJMVGQ/2` → version 2 specifically

This lets you build highly stable and customizable deployment workflows around your rules while developing future versions.

<Callout>
  The clock icon next to each version lets you **roll back**. This is
  destructive—versions between your current state and the rollback target are
  permanently lost as API targets.
</Callout>

## Comparing Versions

Before publishing, compare your working changes against any previous version to see exactly what's different.

Click **Compare Versions** in the rule editor header:

![Compare Versions Button](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/comparing-rules/find-compare-button.png)

The comparison view shows your working changes side-by-side with the selected version. Added rows, removed rows, and modified conditions are highlighted:

![Rule Compare View](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/comparing-rules/rule-compare-view.png)

Use this to review changes before publishing, or to understand what changed between versions when investigating unexpected behavior.

<Callout type="info">
  New versions take effect roughly 1 minute after publishing while caches
  update.
</Callout>

## Decision Logs
/managing-rules/rule-logging

Decision logs record every rule execution with full request/response data. Search with DDQL to find specific decisions.

# Decision Logs

Every rule execution is logged with the full request, response, and which conditions matched. Use logs to debug issues, audit decisions, and understand how your rules behave in production.

<Callout type="info">
  Logs are retained for up to 90 days on most plans and appear in the dashboard
  within seconds of execution.
</Callout>

## Viewing Logs

Navigate to the **Logs** tab in the dashboard.

![Logs Tab](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/logs/view-logs-tab.png)

Each entry shows:

- Request and response payloads
- Which conditions matched or failed
- HTTP status, IP address, timestamp, and duration

Filter by rule, status code, or date range to narrow down what you're looking for.

## Searching with DDQL

Decision Data Query Language lets you search by the actual data in your requests and responses.

For example, if I wanted to pull rule executions for a particular `application_id`, I might do the following:

![Query Logs with DDQL](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/logs/query-logs-ddql.png)

### Examples

```
credit_score >= 700 AND approval_decision = "denied"
customer_id = "CUST-12345"
amount > 10000 AND risk_score < 0.2
tier:gold OR tier:platinum
```

### Operators

| Operator          | Description                  | Example            |
| ----------------- | ---------------------------- | ------------------ |
| `=`               | Exact match                  | `status=approved`  |
| `!=`              | Not equals                   | `status!=rejected` |
| `:`               | Contains (strings) or equals | `name:Smith`       |
| `<` `<=` `>` `>=` | Comparisons                  | `score>=700`       |

Combine with `AND` and `OR`. Use parentheses for precedence:

```
(tier = "gold" AND amount > 100) OR tier = "platinum"
```

<Tabs items={['Strings', 'Numbers', 'Booleans', 'Bare Terms']}>
<Tabs.Tab>

Quotes optional unless value contains spaces:

```
status = approved
city = "New York"
```

</Tabs.Tab>
<Tabs.Tab>

Integers and decimals:

```
score >= 85.5
quantity = 0
```

</Tabs.Tab>
<Tabs.Tab>

```
verified = true
flagged = false
```

</Tabs.Tab>
<Tabs.Tab>

Type a word to search anywhere in request or response:

```
timeout
error
```

</Tabs.Tab>
</Tabs>

Field names are case-sensitive and must match your schema. Queries search both request and response payloads automatically.

## Log Details

Click any entry to see the full request/response JSON, detailed condition evaluation, and timing data.

## Testing Rules
/managing-rules/testing-rules

Test your rules before publishing with Try mode for quick checks and Suite mode for regression testing.

# Testing Rules

Test your rules before they hit production. Rulebricks gives you two modes: **Try** for quick single-request testing, and **Suite** for regression testing across multiple scenarios.

## Try Mode

Open the **Test** tab in the rule editor and select **Try**.

![Find Test Tab](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/testing-rules/find-test-tab.png)

![Try Tab](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/testing-rules/try-tab.png)

Paste a request object and click the orange button. The decision table lights up:

- **Green cells** — Conditions that matched
- **Red cells** — Conditions that didn't match
- **Blue/Yellow cells** — The results returned

This visual feedback shows exactly which row matched and why.

<Callout>
  If you get an error, your rule doesn't handle that input. Check for missing
  conditions or add a catch-all row at the bottom.
</Callout>

## Suite Mode

Switch to **Test Suite** mode to run multiple test cases at once.

![Test Suite](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/testing-rules/test-suite.png)

Build your suite by saving tests from Try mode. When a test produces the expected result, save it. Mark tests as **Critical** if they should block publishing when they fail.

### Rapid Test Generation

We find writing tests boring, and we thought you might too– a powerful AI feature here allows you to create many tests very quickly given one or two examples. Just build and name one test case in the Suite, and click "Generate Tests" to instantly get coverage over your entire rule.

<Callout type="info">
  For large test suites, we offer a simple API to bulk upload test cases
  programmatically.
</Callout>

## Continuous Testing

Enable **Continuous Testing** in rule settings to run your test suite automatically before every publish.

When enabled, you'll see a test score next to every published version—the percentage of tests that passed. Critical tests prevent publishing if they fail; non-critical tests report results but don't block.

## Objects in Rulebricks
/objects

Objects are reusable schema definitions that provide field suggestions when building rules and contexts. Define once, use everywhere.

# Objects in Rulebricks

You've got a customer object with `tier`, `credit_score`, and `lifetime_value`. You'll use those fields in a dozen rules. Do you really want to type them out each time?

Objects are team-level schema definitions that provide field suggestions when you create rules or contexts. Define your data structure once, and every rule you build can pull from it.

![Objects Team Tab](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/objects/objects-team-tab.png)

Rulebricks Admins can find this tab within the **Team** tab on your dashboard.

## Data Clarity

### Field suggestions

When building a rule, select an Object and its fields appear in the schema editor. No retyping, no typos.

![Map Fields from Object](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/objects/map-fields-from-object.png)

### Automatic Dynamic Values

If your Object uses JSON Schema with `enum` fields, Rulebricks extracts those values and creates dropdown options in your rule conditions.

![Enum Benefits](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/objects/mapping-fields-enums-benefits.png)

### Consistency

When everyone builds rules from the same Objects, field names stay consistent across your workspace. This way, you'll never run into issues where rule one may have a schema like:

```json
{
  "customer_id": "cust_12345",
  "order_total": 299.99,
  "is_priority": true
}
```

And rule two, designed elsewhere, uses:

```json
{
  "customerId": "cust_12345",
  "total": 299.99,
  "priority": true
}
```

## Accepted Formats

Objects can be defined using both JSON Schemas, or just an example JSON object. If you're planning to use our objects feature, it's worth noting using JSON Schemas has substantial benefits across our platform that may not be immediately obvious.

Even if you don't have a unified JSON schema anywhere, we make it really easy to make one using our "Smart Import" tool.

**JSON Schema** — Full schema definitions with types, validation rules, and enums

```json
{
  "type": "object",
  "properties": {
    "customer_tier": {
      "type": "string",
      "enum": ["bronze", "silver", "gold", "platinum"]
    },
    "credit_score": {
      "type": "number",
      "minimum": 300,
      "maximum": 850
    }
  }
}
```

**JSON Object** — Plain example objects when you just want field suggestions without full validation

```json
{
  "customer_id": "cust_12345",
  "order_total": 299.99,
  "is_priority": true
}
```

Rulebricks will automatically detect which format you're using.

## Objects vs. Contexts

Two features that may initially appear somewhat similar on our platform are _Objects_ and _Contexts_.

The _Objects_ described here are designed for bringing the shape and fields of business objects that may live elsewhere into Rulebricks for consistency.

The _Contexts_ feature, discussed later in this documentation, while able to create a view of your data relevant for decision making in a similar way, is designed exclusively for decisions where data arrives over time. Contexts are stateful and have lifespans associated with them.

## Creating Objects
/objects/creating-objects

Three ways to create Objects in Rulebricks—manual creation, AI-powered Smart Import, or pre-built templates.

# Creating Objects

<Tabs items={['Manual', 'Smart Import', 'Templates']}>
<Tabs.Tab>

Go to **Team → Objects** and click **Add Object**.

![Objects Team Tab](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/objects/objects-team-tab.png)

Enter a name and paste or write your JSON. Rulebricks detects whether it's a JSON Schema or plain JSON Object automatically.

Good for quick definitions when you know exactly what structure you need.

</Tabs.Tab>
<Tabs.Tab>

Let AI generate a schema from your existing documentation.

Click **Smart Import** and provide:

- **Name and description** of what you're modeling
- **Attachments** — PDFs, spreadsheets, SQL DDL files, images, or URLs
- **Notes** — Additional context or constraints

Click **Generate** and Rulebricks creates a complete JSON Schema.

**Supported files:** PDF, Excel, CSV, Word, JSON, SQL/DDL, images (with OCR), and web URLs.

Good for converting existing specs, database schemas, or documentation without manual translation.

</Tabs.Tab>
<Tabs.Tab>

Pre-built schemas for common use cases.

![Object Templates](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/objects/object-templates.png)

Click **Use Template**, browse categories or search, preview the schema, and click **Add to Workspace**. Templates are pretty good for getting started quickly with industry-standard data structures.

</Tabs.Tab>
</Tabs>

## Using Objects in Rules

When creating a rule, click **From Object** to pull fields from an existing Object:

![Create Rule Using Object](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/objects/create-rule-using-object.png)

Select the fields you need and they're added to your rule's schema—correctly typed and named.

## Automatic Dynamic Values

When you save a JSON Schema with `enum` fields, Rulebricks extracts those values and creates Dynamic Values:

![Objects Create Values](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/objects/objects-create-values.png)

These appear as dropdown options in your rule conditions, so instead of typing `"gold"` you select it from a list. Fewer typos, faster rule building.

<Callout>
  Objects can be used to inform rules and contexts. Update the Object and you
  have a single source of truth for that data structure.
</Callout>

## Architecture & Operations Guide
/private-deployment/architecture

Explains the Rulebricks Helm chart architecture, component interactions, migration flows, and operational considerations.

# Architecture & Operations Guide

This document explains the Rulebricks Helm chart architecture, component interactions, migration flows, and operational considerations, so you can better configure your deployment.

### Component Overview

```mermaid
graph TB
    subgraph Internet
        Users[Users/API Clients]
    end

    subgraph Kubernetes["Kubernetes Cluster"]
        subgraph Ingress["Ingress Layer"]
            Traefik[Traefik LoadBalancer]
        end

        subgraph Core["Rulebricks Core"]
            App[Rulebricks App]
            HPS[HPS Gateway]
            Workers[HPS Workers]
            Redis[Redis Cache]
        end

        subgraph Data["Data Layer"]
            Kafka[Kafka]
            Postgres[(PostgreSQL)]
            Kong[Kong API Gateway]
        end

        subgraph Supabase["Supabase Stack"]
            Auth[GoTrue Auth]
            Rest[PostgREST]
            Realtime[Realtime]
            Storage[Storage API]
        end

        subgraph Support["Supporting Services"]
            Vector[Vector]
            CertManager[cert-manager]
            KEDA[KEDA]
            ExternalDNS[external-dns]
        end
    end

    subgraph External["External Services"]
        LetsEncrypt[Let's Encrypt]
        DNS[DNS Provider]
        LogSink[Log Sink S3/etc]
    end

    Users --> Traefik
    Traefik --> App
    Traefik --> HPS
    Traefik --> Kong

    App --> Redis
    App --> Kafka
    HPS --> Workers
    Workers --> Kafka
    Workers --> Redis

    Kong --> Auth
    Kong --> Rest
    Kong --> Realtime
    Kong --> Storage

    Auth --> Postgres
    Rest --> Postgres

    Kafka --> Vector
    Vector --> LogSink

    CertManager --> LetsEncrypt
    ExternalDNS --> DNS
    KEDA --> Workers
```

### Request Flow

```mermaid
sequenceDiagram
    participant Client
    participant Traefik
    participant HPS
    participant Kafka
    participant Worker
    participant Redis

    Client->>Traefik: POST /api/v1/solve/{rule}
    Traefik->>HPS: Route to HPS Gateway
    HPS->>Kafka: Publish solve request
    HPS->>Client: 202 Accepted (async)

    Kafka->>Worker: Consume solve request
    Worker->>Redis: Fetch rule definition
    Worker->>Worker: Execute rule
    Worker->>Kafka: Publish result
    Worker->>Kafka: Publish decision log
```

### Component Responsibilities

| Component       | Purpose                             | Scaling                         |
| :-------------- | :---------------------------------- | :------------------------------ |
| **Traefik**     | Ingress, TLS termination, routing   | HPA (2-3 replicas default)      |
| **App**         | Web UI, rule editor, management API | Single replica                  |
| **HPS Gateway** | API gateway for rule execution      | Static replicas                 |
| **HPS Workers** | Rule execution engines              | KEDA autoscaling                |
| **Redis**       | Rule cache, session storage         | Single replica with persistence |
| **Kafka**       | Message queue, event streaming      | KRaft mode, single node default |
| **PostgreSQL**  | Persistent data storage             | Single replica with PVC         |
| **Vector**      | Log aggregation and forwarding      | Static replicas                 |

---

## Database Migrations

The chart includes two migration job variants that run automatically based on your configuration.

### Migration Decision Tree

```mermaid
flowchart TD
    A[Helm Install/Upgrade] --> B{supabase.enabled?}
    B -->|true| C[Self-Hosted Migration Job]
    B -->|false| D{accessToken provided?}
    D -->|Yes| E[Managed Supabase Setup Job]
    D -->|No| F[No migration job runs]

    C --> G[Wait for Postgres ready]
    G --> H[Extract migrations from app image]
    H --> I[Apply SQL migrations via psql]
    I --> J[Track in schema_migrations table]

    E --> K[Install Supabase CLI]
    K --> L[Authenticate with access token]
    L --> M[Link to project]
    M --> N[Push config.toml]
    N --> O[Run db push]
    O --> P[Enable SSL enforcement]
```

### Self-Hosted Migration Job

**Triggered when:** `supabase.enabled: true`

**Process:**

1. **Init Container** extracts Supabase assets from the Rulebricks app image
2. **Migration Container** uses `postgres:15-alpine` to:
   - Wait for PostgreSQL to be ready
   - Create `schema_migrations` tracking table
   - Apply each `.sql` file in order
   - Record applied migrations to prevent re-runs

**Key Details:**

```yaml
# Job naming pattern
name: {{ .Release.Name }}-db-migrate-{{ .Release.Revision }}

# Runs on
annotations:
  "helm.sh/hook": post-install,post-upgrade
  "helm.sh/hook-delete-policy": before-hook-creation

# Auto-cleanup
spec:
  ttlSecondsAfterFinished: 600  # 10 minutes
```

**Migration Tracking:**

```sql
CREATE TABLE IF NOT EXISTS schema_migrations (
  version VARCHAR(255) PRIMARY KEY,
  applied_at TIMESTAMP DEFAULT NOW()
);
```

Each migration file is tracked by filename. Already-applied migrations are skipped.

### Managed Supabase Setup Job

**Triggered when:** `supabase.enabled: false` AND `global.supabase.accessToken` is provided

**Process:**

1. **Init Container** extracts Supabase project configuration
2. **Setup Container** uses `node:20-alpine` to:
   - Install Supabase CLI
   - Authenticate with your access token
   - Link to your Supabase project
   - Download and configure email templates
   - Push configuration (SMTP, auth settings)
   - Run `supabase db push` to apply schema
   - Enable SSL enforcement

**Configuration Flow:**

```mermaid
flowchart LR
    A[config.example.toml] --> B[Variable Replacement]
    B --> C[config.toml]

    D[Email Template URLs] --> E[Download Templates]
    E --> F[Local Template Files]

    C --> G[supabase config push]
    F --> G
    G --> H[Supabase Project Updated]
```

**Variables Replaced:**

| Placeholder              | Source                              |
| :----------------------- | :---------------------------------- |
| `env(FULL_URL)`          | `https://{global.domain}`           |
| `env(SMTP_HOST)`         | `global.smtp.host`                  |
| `env(SMTP_PORT)`         | `global.smtp.port`                  |
| `env(SMTP_USER)`         | `global.smtp.user`                  |
| `env(SMTP_PASS)`         | `global.smtp.pass`                  |
| `env(EMAIL_SUBJECTS_*)`  | `global.supabase.emails.subjects.*` |
| `env(EMAIL_TEMPLATES_*)` | Downloaded from URLs                |

### Debugging Migrations

**Self-hosted:**

```bash
# Check job status
kubectl get jobs -n rulebricks -l app.kubernetes.io/component=migrations

# View logs
kubectl logs job/rulebricks-db-migrate-1 -n rulebricks

# Check migration table
kubectl exec -it deploy/rulebricks-supabase-db -n rulebricks -- \
  psql -U postgres -c "SELECT * FROM schema_migrations ORDER BY applied_at;"
```

**Managed Supabase:**

```bash
# Check job status
kubectl get jobs -n rulebricks -l app.kubernetes.io/component=managed-supabase-setup

# View logs
kubectl logs job/rulebricks-managed-supabase-setup-1 -n rulebricks
```

---

## DNS and TLS Setup

### DNS Record Requirements

| Scenario             | Records Needed                  |
| :------------------- | :------------------------------ |
| Self-hosted Supabase | `{domain}`, `supabase.{domain}` |
| Managed Supabase     | `{domain}` only                 |

---

## Scaling Considerations

### Horizontal Scaling

| Component   | Scaling Method | Trigger         |
| :---------- | :------------- | :-------------- |
| Traefik     | HPA            | CPU utilization |
| HPS Workers | KEDA           | Kafka lag, CPU  |
| Vector      | Manual         | Log volume      |

### KEDA Scaling Configuration

```mermaid
flowchart LR
    A[Kafka Consumer Lag] --> B{lag > threshold?}
    B -->|Yes| C[Scale Up Workers]
    B -->|No| D{CPU > threshold?}
    D -->|Yes| C
    D -->|No| E[Maintain Current]

    F[Cooldown Period] --> G{No scale triggers<br/>for 5 min?}
    G -->|Yes| H[Scale Down]
    G -->|No| E
```

---

## Troubleshooting

#### Migration Job Failing

```bash
# Check job status
kubectl get jobs -n rulebricks

# Get detailed error
kubectl describe job rulebricks-db-migrate-1 -n rulebricks

# Check pod logs
kubectl logs job/rulebricks-db-migrate-1 -n rulebricks --all-containers
```

**Common causes:**

- Database not ready (increase readiness wait)
- Invalid credentials
- Network policy blocking access

#### HPS Workers Not Scaling

```bash
# Check KEDA
kubectl get scaledobject -n rulebricks
kubectl describe scaledobject rulebricks-hps-workers -n rulebricks

# Check Kafka metrics
kubectl exec -it rulebricks-kafka-0 -n rulebricks -- \
  kafka-consumer-groups.sh --bootstrap-server localhost:9092 \
  --describe --group hps-workers
```

**Common causes:**

- Kafka consumer group not found
- KEDA unable to reach Kafka
- Incorrect threshold configuration

### Log Collection

```bash
# All pods in namespace
kubectl logs -n rulebricks -l app.kubernetes.io/instance=rulebricks --all-containers

# Specific component with follow
kubectl logs -n rulebricks -l app.kubernetes.io/component=hps-worker -f
```

## Configuration Reference
/private-deployment/configuration-reference

Comprehensive reference for all configuration values in the Rulebricks Helm chart.

# Configuration Reference

This document provides a comprehensive reference for all configuration values in the Rulebricks Helm chart. Values are organized by component with detailed explanations of their purpose, defaults, and recommendations.

### Core Configuration

| Parameter                   | Type    | Default                    | Required | Description                                                                     |
| :-------------------------- | :------ | :------------------------- | :------- | :------------------------------------------------------------------------------ |
| `global.domain`             | string  | `""`                       | **Yes**  | The domain name for your Rulebricks instance. Must be a domain you control.     |
| `global.email`              | string  | `"support@rulebricks.com"` | **Yes**  | Email address for Let's Encrypt certificate registration.                       |
| `global.licenseKey`         | string  | `"evaluation"`             | **Yes**  | Your Rulebricks Enterprise license key.                                         |
| `global.tlsEnabled`         | boolean | `false`                    | No       | Enable HTTPS. Set to `true` after DNS is configured or when using external-dns. |
| `global.externalDnsEnabled` | boolean | `false`                    | No       | Enable external-dns annotations on ingresses for automatic DNS management.      |

#### Domain Configuration

Your domain should follow the pattern: `rulebricks.yourdomain.com`

When self-hosting Supabase, an additional subdomain is created: `supabase.rulebricks.yourdomain.com`

```yaml
global:
  domain: 'rulebricks.acme.com'
  email: 'devops@acme.com'
```

<Callout type="warning">
  **Important:** The domain must resolve to your cluster's load balancer before
  enabling TLS. See [DNS Configuration](#dns-external-dns) for automatic setup.
</Callout>

### SMTP Configuration

SMTP is **required** for user authentication flows (invitations, password resets, email verification).

| Parameter              | Type    | Default                     | Description                                        |
| :--------------------- | :------ | :-------------------------- | :------------------------------------------------- |
| `global.smtp.host`     | string  | `"smtp.mailtrap.io"`        | SMTP server hostname                               |
| `global.smtp.port`     | integer | `2525`                      | SMTP server port (typically 25, 465, 587, or 2525) |
| `global.smtp.user`     | string  | `"demo-user"`               | SMTP authentication username                       |
| `global.smtp.pass`     | string  | `"demo-password"`           | SMTP authentication password                       |
| `global.smtp.from`     | string  | `"no-reply@rulebricks.com"` | Sender email address                               |
| `global.smtp.fromName` | string  | `"Rulebricks"`              | Sender display name                                |

#### Production SMTP Providers

| Provider | Host                                | Port | Notes                        |
| :------- | :---------------------------------- | :--- | :--------------------------- |
| AWS SES  | `email-smtp.<region>.amazonaws.com` | 587  | Requires verified domain     |
| SendGrid | `smtp.sendgrid.net`                 | 587  | API key as password          |
| Mailgun  | `smtp.mailgun.org`                  | 587  | Domain verification required |
| Postmark | `smtp.postmarkapp.com`              | 587  | Server token as password     |

```yaml
global:
  smtp:
    host: 'email-smtp.us-east-1.amazonaws.com'
    port: 587
    user: 'AKIAIOSFODNN7EXAMPLE'
    pass: 'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY'
    from: 'no-reply@yourdomain.com'
    fromName: 'Your Company - Rulebricks'
```

### Supabase Keys

These JWT keys are used for authentication between components.

| Parameter                    | Type   | Description                                 |
| :--------------------------- | :----- | :------------------------------------------ |
| `global.supabase.anonKey`    | string | Public/anonymous key for client-side auth   |
| `global.supabase.serviceKey` | string | Service role key for server-side operations |
| `global.supabase.jwtSecret`  | string | JWT signing secret (self-hosted only)       |

<Callout type="info">
  **Security:** For production, generate new keys using Supabase's key generator
  or a secure random string generator. The default keys are for demo purposes
  only.
</Callout>

#### Managed Supabase (Cloud)

When using Supabase Cloud instead of self-hosting:

| Parameter                     | Type   | Description                                        |
| :---------------------------- | :----- | :------------------------------------------------- |
| `global.supabase.url`         | string | Project URL (e.g., `https://abcd1234.supabase.co`) |
| `global.supabase.projectRef`  | string | Project reference ID (derived from URL if empty)   |
| `global.supabase.accessToken` | string | Personal access token for Supabase CLI             |

```yaml
global:
  supabase:
    url: 'https://abcd1234.supabase.co'
    anonKey: '<from-supabase-dashboard>'
    serviceKey: '<from-supabase-dashboard>'
    accessToken: '<personal-access-token>'

supabase:
  enabled: false # Disable self-hosted Supabase
```

### Email Templates

Customize authentication email subjects and templates:

```yaml
global:
  supabase:
    emails:
      subjects:
        invite: 'Join your team on Rulebricks'
        confirmation: 'Confirm Your Email'
        recovery: 'Reset Your Password'
        emailChange: 'Confirm Email Change'
      templates:
        invite: 'https://your-cdn.com/templates/invite.html'
        confirmation: 'https://your-cdn.com/templates/verify.html'
        recovery: 'https://your-cdn.com/templates/password_change.html'
        emailChange: 'https://your-cdn.com/templates/email_change.html'
```

### AI Features

Enable AI-powered rule generation (optional):

| Parameter                | Type    | Default | Description        |
| :----------------------- | :------ | :------ | :----------------- |
| `global.ai.enabled`      | boolean | `false` | Enable AI features |
| `global.ai.openaiApiKey` | string  | `""`    | OpenAI API key     |

```yaml
global:
  ai:
    enabled: true
    openaiApiKey: 'sk-...'
```

### SSO Configuration

Enable Single Sign-On (SSO) via OpenID Connect (OIDC).

| Parameter                 | Type    | Default | Description                                               |
| :------------------------ | :------ | :------ | :-------------------------------------------------------- |
| `global.sso.enabled`      | boolean | `false` | Enable SSO                                                |
| `global.sso.provider`     | string  | `""`    | Provider name (azure, google, okta, keycloak, ory, other) |
| `global.sso.url`          | string  | `""`    | Provider URL (required for all except Google)             |
| `global.sso.clientId`     | string  | `""`    | OAuth client ID                                           |
| `global.sso.clientSecret` | string  | `""`    | OAuth client secret                                       |

#### Provider Types

You will need to go to your Supabase dashboard, and configure your provider in the Authentication tab. If you don't see your provider, use _Keycloak_ – our proxy uses it as a bridge.

- **Native Providers** (`azure`, `google`, `okta`, `keycloak`): Supabase handles authentication directly.
- **Custom Providers** (`ory`, `other`): The app uses a built-in OIDC proxy we manage to translate paths for your IdP.

#### Identity Provider Setup

You must configure your Identity Provider (IdP) with the following settings:

- **Scopes**: `openid`, `email`, `profile`
- **Response Type**: `code`
- **Grant Types**: `authorization_code`, `refresh_token`
- **Auth Method**: `http body`
- **Redirect URIs**:
  1. `https://<your-domain>/api/sso-proxy/callback`
  2. `<your-supabase-url>/auth/v1/callback`

### External Secrets

For enterprise deployments using external secret management:

| Parameter                        | Type   | Description                        |
| :------------------------------- | :----- | :--------------------------------- |
| `global.secrets.secretRef`       | string | Name of existing Kubernetes secret |
| `global.secrets.secretRefKeys.*` | object | Key name mappings                  |

```yaml
global:
  secrets:
    secretRef: 'rulebricks-external-secrets'
    secretRefKeys:
      licenseKey: 'RULEBRICKS_LICENSE'
      smtpUser: 'SMTP_USERNAME'
      smtpPass: 'SMTP_PASSWORD'
      supabaseAnonKey: 'SUPABASE_ANON'
      supabaseServiceKey: 'SUPABASE_SERVICE'
      supabaseAccessToken: 'SUPABASE_TOKEN'
      openaiApiKey: 'OPENAI_KEY'
```

## Rulebricks Application

The core application and high-performance solver (HPS).

### Application Image

| Parameter                         | Type   | Default                            | Description             |
| :-------------------------------- | :----- | :--------------------------------- | :---------------------- |
| `rulebricks.app.image.repository` | string | `"index.docker.io/rulebricks/app"` | Docker image repository |
| `rulebricks.app.image.tag`        | string | `"1.X.X"`                          | Image version tag       |
| `rulebricks.app.image.pullPolicy` | string | `"IfNotPresent"`                   | Image pull policy       |

### Logging Configuration

| Parameter                                   | Type    | Default              | Description                              |
| :------------------------------------------ | :------ | :------------------- | :--------------------------------------- |
| `rulebricks.app.logging.enabled`            | boolean | `true`               | Enable decision logging                  |
| `rulebricks.app.logging.kafkaBrokers`       | string  | `""`                 | Kafka brokers (auto-discovered if empty) |
| `rulebricks.app.logging.kafkaTopic`         | string  | `"logs"`             | Kafka topic for logs                     |
| `rulebricks.app.logging.loggingDestination` | string  | `"Console (stdout)"` | Display label in UI                      |

### Ingress

| Parameter                      | Type    | Default     | Description            |
| :----------------------------- | :------ | :---------- | :--------------------- |
| `rulebricks.ingress.enabled`   | boolean | `true`      | Enable ingress         |
| `rulebricks.ingress.className` | string  | `"traefik"` | Ingress class name     |
| `rulebricks.ingress.paths`     | list    | `[{...}]`   | List of paths to route |

### Redis

Redis is used for caching and session management.

| Parameter                                    | Type    | Default   | Recommendation               |
| :------------------------------------------- | :------ | :-------- | :--------------------------- |
| `rulebricks.redis.resources.requests.cpu`    | string  | `"200m"`  | Increase for high traffic    |
| `rulebricks.redis.resources.requests.memory` | string  | `"256Mi"` | —                            |
| `rulebricks.redis.resources.limits.cpu`      | string  | `"500m"`  | —                            |
| `rulebricks.redis.resources.limits.memory`   | string  | `"4Gi"`   | Increase for large rule sets |
| `rulebricks.redis.persistence.enabled`       | boolean | `true`    | Keep enabled for production  |
| `rulebricks.redis.persistence.size`          | string  | `"4Gi"`   | —                            |
| `rulebricks.redis.persistence.storageClass`  | string  | `"gp3"`   | Match your storage class     |

### High Performance Server (HPS)

HPS handles rule execution with horizontal scaling.

| Parameter                         | Type    | Default | Description                    |
| :-------------------------------- | :------ | :------ | :----------------------------- |
| `rulebricks.hps.enabled`          | boolean | `true`  | Enable HPS                     |
| `rulebricks.hps.replicas`         | integer | `3`     | Number of HPS gateway replicas |
| `rulebricks.hps.workers.enabled`  | boolean | `true`  | Enable worker pods             |
| `rulebricks.hps.workers.replicas` | integer | `4`     | Base worker replica count      |

#### HPS Image

| Parameter                         | Type   | Default                            | Description             |
| :-------------------------------- | :----- | :--------------------------------- | :---------------------- |
| `rulebricks.hps.image.repository` | string | `"index.docker.io/rulebricks/hps"` | Docker image repository |
| `rulebricks.hps.image.tag`        | string | `"1.X.X"`                          | Image version tag       |
| `rulebricks.hps.image.pullPolicy` | string | `"Always"`                         | Image pull policy       |

#### HPS Resources

| Parameter                                  | Type   | Default   |
| :----------------------------------------- | :----- | :-------- |
| `rulebricks.hps.resources.requests.cpu`    | string | `"1000m"` |
| `rulebricks.hps.resources.requests.memory` | string | `"1Gi"`   |
| `rulebricks.hps.resources.limits.cpu`      | string | `"2000m"` |
| `rulebricks.hps.resources.limits.memory`   | string | `"2Gi"`   |

#### KEDA Autoscaling for HPS Workers

| Parameter                                     | Type    | Default | Description                   |
| :-------------------------------------------- | :------ | :------ | :---------------------------- |
| `rulebricks.hps.workers.keda.enabled`         | boolean | `true`  | Enable KEDA autoscaling       |
| `rulebricks.hps.workers.keda.minReplicaCount` | integer | `4`     | Minimum workers               |
| `rulebricks.hps.workers.keda.maxReplicaCount` | integer | `12`    | Maximum workers               |
| `rulebricks.hps.workers.keda.pollingInterval` | integer | `10`    | Seconds between metric checks |
| `rulebricks.hps.workers.keda.cooldownPeriod`  | integer | `300`   | Seconds before scale-down     |
| `rulebricks.hps.workers.keda.lagThreshold`    | integer | `50`    | Kafka lag threshold           |
| `rulebricks.hps.workers.keda.cpuThreshold`    | integer | `25`    | CPU percentage threshold      |

**Tuning Recommendations:**

```yaml
# High-throughput configuration
# Replicas should match partitions
rulebricks:
  hps:
    replicas: 4
    workers:
      replicas: 8
      keda:
        minReplicaCount: 12
        maxReplicaCount: 32
        lagThreshold: 5
        cpuThreshold: 20
```

## Database (Supabase)

### Self-Hosted vs. Managed

| Mode            | `supabase.enabled` | Use Case                               |
| :-------------- | :----------------- | :------------------------------------- |
| Self-hosted     | `true`             | Full control, air-gapped environments  |
| Managed (Cloud) | `false`            | Simplified operations, managed backups |

### Self-Hosted Configuration

| Parameter                            | Type    | Default                          | Description                 |
| :----------------------------------- | :------ | :------------------------------- | :-------------------------- |
| `supabase.enabled`                   | boolean | `true`                           | Deploy self-hosted Supabase |
| `supabase.secret.db.username`        | string  | `"postgres"`                     | Database username           |
| `supabase.secret.db.password`        | string  | `"postgres-password-change-me"`  | **Change this!**            |
| `supabase.secret.db.database`        | string  | `"postgres"`                     | Database name               |
| `supabase.secret.dashboard.username` | string  | `"supabase"`                     | Studio dashboard username   |
| `supabase.secret.dashboard.password` | string  | `"dashboard-password-change-me"` | **Change this!**            |

#### Database Resources

| Parameter                                  | Type    | Default  | Production Recommendation    |
| :----------------------------------------- | :------ | :------- | :--------------------------- |
| `supabase.db.resources.requests.cpu`       | string  | `"500m"` | `"1000m"` or higher          |
| `supabase.db.resources.requests.memory`    | string  | `"1Gi"`  | `"2Gi"` or higher            |
| `supabase.db.persistence.enabled`          | boolean | `true`   | Always `true` for production |
| `supabase.db.persistence.size`             | string  | `"10Gi"` | Based on data volume         |
| `supabase.db.persistence.storageClassName` | string  | `"gp3"`  | Use fast storage             |

### Kong Ingress

| Parameter                         | Type    | Default     | Description                 |
| :-------------------------------- | :------ | :---------- | :-------------------------- |
| `supabase.kong.ingress.enabled`   | boolean | `true`      | Enable Supabase API ingress |
| `supabase.kong.ingress.className` | string  | `"traefik"` | Must match Traefik class    |

## Message Queue (Kafka)

Kafka handles async rule execution and logging.

### Basic Settings

| Parameter                 | Type    | Default | Description                   |
| :------------------------ | :------ | :------ | :---------------------------- |
| `kafka.enabled`           | boolean | `true`  | Deploy Kafka                  |
| `kafka.kraft.enabled`     | boolean | `true`  | Use KRaft mode (no Zookeeper) |
| `kafka.zookeeper.enabled` | boolean | `false` | Disable Zookeeper             |

### Controller/Broker Configuration

| Parameter                                    | Type    | Default              | Description           |
| :------------------------------------------- | :------ | :------------------- | :-------------------- |
| `kafka.controller.replicaCount`              | integer | `1`                  | Number of Kafka nodes |
| `kafka.controller.resources.requests.cpu`    | string  | `"500m"`             | CPU request           |
| `kafka.controller.resources.requests.memory` | string  | `"2Gi"`              | Memory request        |
| `kafka.controller.resources.limits.cpu`      | string  | `"2000m"`            | CPU limit             |
| `kafka.controller.resources.limits.memory`   | string  | `"3Gi"`              | Memory limit          |
| `kafka.controller.persistence.size`          | string  | `"10Gi"`             | Storage size          |
| `kafka.controller.heapOpts`                  | string  | `"-Xmx1g -Xms1g..."` | JVM heap settings     |

### Kafka Tuning

The default configuration includes extensive JVM and Kafka tuning:

```yaml
kafka:
  overrideConfiguration:
    auto.create.topics.enable: 'true'
    log.retention.hours: '24' # Adjust based on log volume
    default.replication.factor: '1' # Increase for HA
    offsets.topic.replication.factor: '1'
    num.partitions: '12' # Increase for parallelism
  controller:
    extraEnvVars:
      - name: KAFKA_JVM_PERFORMANCE_OPTS
        value: '-XX:MaxDirectMemorySize=256M -Djdk.nio.maxCachedBufferSize=262144'
      - name: KAFKA_CFG_QUEUED_MAX_REQUESTS
        value: '10000'
      - name: KAFKA_CFG_NUM_NETWORK_THREADS
        value: '8'
      - name: KAFKA_CFG_NUM_IO_THREADS
        value: '8'
      - name: KAFKA_CFG_SOCKET_SEND_BUFFER_BYTES
        value: '1048576'
      - name: KAFKA_CFG_SOCKET_RECEIVE_BUFFER_BYTES
        value: '1048576'
      - name: KAFKA_CFG_SOCKET_REQUEST_MAX_BYTES
        value: '209715200'
      - name: KAFKA_CFG_LOG_RETENTION_BYTES
        value: '4294967296'
      - name: KAFKA_CFG_LOG_SEGMENT_BYTES
        value: '1073741824'
      - name: KAFKA_CFG_NUM_REPLICA_FETCHERS
        value: '4'
      - name: KAFKA_CFG_REPLICA_SOCKET_RECEIVE_BUFFER_BYTES
        value: '1048576'
      - name: KAFKA_CFG_LOG_CLEANER_DEDUPE_BUFFER_SIZE
        value: '268435456'
      - name: KAFKA_CFG_LOG_CLEANER_IO_BUFFER_SIZE
        value: '1048576'
      - name: KAFKA_CFG_MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION
        value: '10'
  listeners:
    client:
      protocol: PLAINTEXT
    controller:
      protocol: PLAINTEXT
    interbroker:
      protocol: PLAINTEXT
```

**High-Availability Configuration:**

```yaml
kafka:
  controller:
    replicaCount: 3
  overrideConfiguration:
    default.replication.factor: '3'
    min.insync.replicas: '2'
```

## Ingress (Traefik)

Traefik handles all incoming traffic and TLS termination.

| Parameter                         | Type    | Default     | Description        |
| :-------------------------------- | :------ | :---------- | :----------------- |
| `traefik.enabled`                 | boolean | `true`      | Deploy Traefik     |
| `traefik.ingressClass.name`       | string  | `"traefik"` | Ingress class name |
| `traefik.autoscaling.enabled`     | boolean | `true`      | Enable HPA         |
| `traefik.autoscaling.minReplicas` | integer | `1`         | Minimum replicas   |
| `traefik.autoscaling.maxReplicas` | integer | `2`         | Maximum replicas   |

### Resources

| Parameter                           | Type   | Default   | High-Traffic |
| :---------------------------------- | :----- | :-------- | :----------- |
| `traefik.resources.requests.cpu`    | string | `"100m"`  | `"500m"`     |
| `traefik.resources.requests.memory` | string | `"256Mi"` | `"512Mi"`    |
| `traefik.resources.limits.cpu`      | string | `"1000m"` | `"2000m"`    |
| `traefik.resources.limits.memory`   | string | `"2Gi"`   | `"4Gi"`      |

### Ports

| Parameter                             | Default | Description         |
| :------------------------------------ | :------ | :------------------ |
| `traefik.ports.web.port`              | `8000`  | Internal HTTP port  |
| `traefik.ports.web.exposedPort`       | `80`    | External HTTP port  |
| `traefik.ports.websecure.port`        | `8443`  | Internal HTTPS port |
| `traefik.ports.websecure.exposedPort` | `443`   | External HTTPS port |

### Persistence

| Parameter                     | Type    | Default | Description        |
| :---------------------------- | :------ | :------ | :----------------- |
| `traefik.persistence.enabled` | boolean | `false` | Enable persistence |

## Autoscaling (KEDA)

KEDA provides event-driven autoscaling for HPS workers.

| Parameter           | Type    | Default | Description                  |
| :------------------ | :------ | :------ | :--------------------------- |
| `keda.enabled`      | boolean | `true`  | Deploy KEDA                  |
| `keda.crds.install` | boolean | `false` | CRDs managed by parent chart |

<Callout type="info">
  **Note:** KEDA CRDs are included in the `crds/` directory and installed
  automatically.
</Callout>

## Certificates (cert-manager)

cert-manager provisions TLS certificates from Let's Encrypt.

| Parameter                  | Type    | Default | Description                  |
| :------------------------- | :------ | :------ | :--------------------------- |
| `cert-manager.enabled`     | boolean | `true`  | Deploy cert-manager          |
| `cert-manager.installCRDs` | boolean | `false` | CRDs managed by parent chart |

The chart creates:

- A `ClusterIssuer` for Let's Encrypt production
- `Certificate` resources for your domain(s)

## Logging (Vector)

Vector aggregates logs from Kafka and forwards them to configured sinks.

| Parameter         | Type    | Default                  | Description        |
| :---------------- | :------ | :----------------------- | :----------------- |
| `vector.enabled`  | boolean | `true`                   | Deploy Vector      |
| `vector.role`     | string  | `"Stateless-Aggregator"` | Vector role        |
| `vector.replicas` | integer | `2`                      | Number of replicas |

### Resources

| Parameter                          | Type   | Default   |
| :--------------------------------- | :----- | :-------- |
| `vector.resources.requests.cpu`    | string | `"50m"`   |
| `vector.resources.requests.memory` | string | `"128Mi"` |
| `vector.resources.limits.cpu`      | string | `"200m"`  |
| `vector.resources.limits.memory`   | string | `"256Mi"` |

### Service

| Parameter                | Type    | Default   | Description           |
| :----------------------- | :------ | :-------- | :-------------------- |
| `vector.service.enabled` | boolean | `true`    | Enable Vector service |
| `vector.service.ports`   | list    | `[{...}]` | Service ports         |

### Environment Variables

| Parameter    | Type | Default   | Description                                           |
| :----------- | :--- | :-------- | :---------------------------------------------------- |
| `vector.env` | list | `[{...}]` | Environment variables (e.g., KAFKA_BOOTSTRAP_SERVERS) |

### Custom Sinks

Configure log destinations in `vector.customConfig.sinks`:

```yaml
vector:
  customConfig:
    sources:
      kafka:
        type: kafka
        bootstrap_servers: '${KAFKA_BOOTSTRAP_SERVERS:-rulebricks-kafka:9092}'
        topics:
          - logs
        group_id: vector-consumers
        auto_offset_reset: latest
    sinks:
      # Console output (default)
      console:
        type: console
        inputs: [kafka]
        encoding:
          codec: json

      # S3 sink example
      s3:
        type: aws_s3
        inputs: [kafka]
        bucket: 'your-logs-bucket'
        region: 'us-east-1'
        key_prefix: 'rulebricks/logs/%Y/%m/%d/'
        compression: gzip
        encoding:
          codec: json
```

## DNS (external-dns)

external-dns automatically creates DNS records for your ingresses.

| Parameter                    | Type    | Default         | Description                  |
| :--------------------------- | :------ | :-------------- | :--------------------------- |
| `external-dns.enabled`       | boolean | `false`         | Deploy external-dns          |
| `external-dns.provider`      | string  | `"route53"`     | DNS provider                 |
| `external-dns.sources`       | list    | `["ingress"]`   | Resource types to watch      |
| `external-dns.domainFilters` | list    | `[]`            | Restrict to specific domains |
| `external-dns.policy`        | string  | `"upsert-only"` | Record management policy     |

### Provider Configuration

#### AWS Route53

```yaml
external-dns:
  enabled: true
  provider: route53
  # Uses IRSA - ensure service account has Route53 permissions
```

#### Cloudflare

```yaml
external-dns:
  enabled: true
  provider: cloudflare
  extraEnvVars:
    - name: CF_API_TOKEN
      valueFrom:
        secretKeyRef:
          name: cloudflare-api-token
          key: api-token
```

#### Google Cloud DNS

```yaml
external-dns:
  enabled: true
  provider: google
  google:
    project: 'your-gcp-project'
```

#### Azure DNS

```yaml
external-dns:
  enabled: true
  provider: azure
  azure:
    resourceGroup: 'your-resource-group'
    subscriptionId: 'your-subscription-id'
```

## Monitoring (Prometheus)

Optional Prometheus stack for metrics collection.

| Parameter                                    | Type    | Default | Description         |
| :------------------------------------------- | :------ | :------ | :------------------ |
| `monitoring.enabled`                         | boolean | `false` | Enable monitoring   |
| `kube-prometheus-stack.alertmanager.enabled` | boolean | `false` | Deploy Alertmanager |
| `kube-prometheus-stack.grafana.enabled`      | boolean | `false` | Deploy Grafana      |

### Prometheus Storage

```yaml
kube-prometheus-stack:
  prometheus:
    prometheusSpec:
      retention: 30d
      storageSpec:
        volumeClaimTemplate:
          spec:
            storageClassName: gp3
            resources:
              requests:
                storage: 50Gi
```

## Storage

### StorageClass

The chart can create a gp3 StorageClass for AWS EBS:

| Parameter                           | Type    | Default                  | Description         |
| :---------------------------------- | :------ | :----------------------- | :------------------ |
| `storageClass.create`               | boolean | `true`                   | Create StorageClass |
| `storageClass.name`                 | string  | `"gp3"`                  | StorageClass name   |
| `storageClass.provisioner`          | string  | `"ebs.csi.aws.com"`      | CSI provisioner     |
| `storageClass.type`                 | string  | `"gp3"`                  | EBS volume type     |
| `storageClass.fsType`               | string  | `"ext4"`                 | File system type    |
| `storageClass.reclaimPolicy`        | string  | `"Delete"`               | Reclaim policy      |
| `storageClass.volumeBindingMode`    | string  | `"WaitForFirstConsumer"` | Binding mode        |
| `storageClass.allowVolumeExpansion` | boolean | `true`                   | Allow expansion     |

For non-AWS clusters, set `storageClass.create: false` and ensure a compatible StorageClass exists.

## values.yaml
/private-deployment/deployment

This guide covers common deployment patterns and the minimum configuration values you need to provide for various Rulebricks deployment scenarios.

## Deployment Modes

This guide describes the minimum configuration values you need to provide to deploy Rulebricks.

In any case, we recommend consulting the [Changelog](/changelog), and using the `rulebricks/app` tag containing the latest fixes/features. The `rulebricks/hps` tag should also match.

### Quick Start (Development/Testing)

Minimal configuration for evaluation purposes. Self-hosts Supabase.

```yaml
# values.yaml
global:
  domain: '<domain-you-control.com>
  email: '<valid-email>'
  licenseKey: '<valid-license-key>'
  smtp:
    <valid-information>

# Everything else uses defaults
```

```bash
helm install rulebricks oci://ghcr.io/rulebricks/charts/stack \
  --namespace rulebricks \
  --create-namespace \
  -f dev-values.yaml
```

### Production with Supabase Cloud

Automatic DNS, external database.

```yaml
# production-values.yaml
global:
  domain: '<domain-you-control.com>
  email: '<valid-email>'
  licenseKey: '<valid-license-key>'
  tlsEnabled: true
  externalDnsEnabled: true

  smtp:
    <valid-information>

  supabase:
    url: 'https://abcd1234.supabase.co'
    projectRef: 'abcd1234'
    anonKey: 'from-supabase-dashboard'
    serviceKey: 'from-supabase-dashboard'
    # Account > Settings > Access Tokens
    accessToken: '${SUPABASE_ACCESS_TOKEN}'

supabase:
  enabled: false # Don't deploy self-hosted

# Ensure this is configured properly
external-dns:
  enabled: true
  provider: route53
```

## Cloud-Specific Values

### AWS EKS

```yaml
# AWS-specific settings
storageClass:
  create: true
  provisioner: ebs.csi.aws.com
  type: gp3

external-dns:
  enabled: true
  provider: route53
  # Uses IRSA - create IAM role and service account
# Recommended: Use IRSA for all AWS integrations
# eksctl create iamserviceaccount ...
```

**Prerequisites:**

- EBS CSI driver installed
- IRSA configured for external-dns and Vector (if using S3)
- ALB/NLB annotations if not using Traefik

### Google GKE

```yaml
storageClass:
  create: true
  provisioner: pd.csi.storage.gke.io
  type: pd-ssd

external-dns:
  enabled: true
  provider: google
  google:
    project: 'your-gcp-project'
# GKE uses Workload Identity
# Annotate service accounts accordingly
```

### Azure AKS

```yaml
storageClass:
  create: true
  provisioner: disk.csi.azure.com
  type: Premium_LRS

external-dns:
  enabled: true
  provider: azure
  azure:
    resourceGroup: 'your-resource-group'
    subscriptionId: 'your-subscription-id'
```

## 1. Create your values file
/private-deployment/quick-start

Deploy Rulebricks to your Kubernetes cluster using our official Helm charts.

![Rulebricks Cloud Banner](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/private-deployment/rb-cloud-banner.png)

Our unified Helm chart deploys Rulebricks and all its dependencies to your Kubernetes cluster in a single command. You'll need:

- **Kubernetes 1.19+** (EKS, GKE, AKS, or self-managed)
- **Helm 3.2.0+**
- **kubectl** configured for your cluster
- A **domain name** you control

<Callout type="info">
  The chart handles all service dependencies, configurations, and migrations
  automatically. You provide a values file with your settings, and Helm
  coordinates the rest.
</Callout>

### Quick Start

```bash
# 1. Create your values file
# 2. Install the chart
helm install rulebricks oci://ghcr.io/rulebricks/charts/stack \
  --namespace rulebricks \
  --create-namespace \
  -f your-values.yaml

# 3. Follow the on-screen instructions for DNS setup
# 4. Enable TLS once DNS is configured
helm upgrade rulebricks oci://ghcr.io/rulebricks/charts/stack \
  --namespace rulebricks \
  --reuse-values \
  --set global.tlsEnabled=true
```

### Single-Phase Installation (with external-dns)

If you're on AWS, GCP, or Azure and want fully automated DNS:

```bash
helm install rulebricks oci://ghcr.io/rulebricks/charts/stack \
  --namespace rulebricks \
  --create-namespace \
  -f your-values.yaml \
  --set external-dns.enabled=true \
  --set global.externalDnsEnabled=true \
  --set global.tlsEnabled=true
```

See [Deployment Modes](/private-deployment/deployment) for minimal configurations required for different deployment scenarios, and visit [Configuration Reference](/private-deployment/configuration-reference) for a complete breakdown of all available options in `values.yaml`.

---

## What am I deploying?

You're deploying a complete Rulebricks stack to your existing Kubernetes cluster. The chart installs multiple integrated services, pre-configured for production workloads.

| Component        | Purpose                                      | Enabled by Default |
| :--------------- | :------------------------------------------- | :----------------: |
| **Rulebricks**   | Core application and high-performance solver |         ✓          |
| **Supabase**     | PostgreSQL database and authentication       |         ✓          |
| **Kafka**        | Message queue for async rule execution       |         ✓          |
| **Traefik**      | Ingress controller with automatic TLS        |         ✓          |
| **cert-manager** | Let's Encrypt certificate provisioning       |         ✓          |
| **KEDA**         | Event-driven autoscaling for workers         |         ✓          |
| **Vector**       | Log aggregation and forwarding               |         ✓          |
| **external-dns** | Automatic DNS record management              |         ✗          |
| **Prometheus**   | Metrics collection and alerting              |         ✗          |

### Database Options

**Self-hosted (default):** PostgreSQL runs in your cluster with persistent storage. You have full control and data never leaves your infrastructure.

**Managed Supabase:** Use Supabase Cloud instead. Set `supabase.enabled: false` and provide your project credentials. The chart automatically configures your managed project. We are also able to manage your database for you, should you prefer a hybrid deployment configuration.

## Troubleshooting

### Check Database Migration

```bash
# Check migration job status
kubectl get jobs -n rulebricks
kubectl logs job/rulebricks-db-migrate-1 -n rulebricks
```

### Clean Reinstall

```bash
# Full cleanup including data
helm uninstall rulebricks -n rulebricks
kubectl delete pvc --all -n rulebricks
kubectl delete namespace rulebricks

# Reinstall
helm install rulebricks oci://ghcr.io/rulebricks/charts/stack \
  --namespace rulebricks \
  -f your-values.yaml
```

## Caveats & Limits

### Cluster Requirements

The Helm chart deploys to your **existing** Kubernetes cluster. You're responsible for:

- Cluster provisioning and scaling
- Node pool configuration
- Storage provisioner (e.g., AWS EBS CSI driver)
- Network policies and security

See [example-min-cluster.yaml](https://github.com/rulebricks/helm/blob/main/example-min-cluster.yaml) for minimum EKS cluster specifications.

### Air-Gapped Deployments

Rulebricks can run nearly air-gapped with these exceptions:

| Feature          | External Dependency       | Can Disable?                       |
| :--------------- | :------------------------ | :--------------------------------- |
| Managed Supabase | Supabase Cloud API        | Yes—use self-hosted                |
| AI Features      | OpenAI API                | Yes—set `global.ai.enabled: false` |
| Log Forwarding   | External sinks (S3, etc.) | Yes—use console sink only          |
| TLS Certificates | Let's Encrypt             | Yes—bring your own certs           |
| Fonts            | Google Fonts              | Requires customization             |
| Analytics        | Sentry                    | Requires customization             |

### Installing Updates

Rule engines usually take critical roles, so we don't release updates continuously. We make upgrades easy with zero downtime, but you control when they happen:

First, visit our [Changelog](/changelog), and find the `rulebricks/app` tag containing the fixes/features you need in your upgrade.

Then, edit `rulebricks.app.image.tag` in your `values.yaml` file accordingly.

Finally, run:

```bash
# Upgrade to latest version
helm upgrade rulebricks oci://ghcr.io/rulebricks/charts/stack \
  --namespace rulebricks \
  -f your-values.yaml
```

## Releases in Rulebricks
/releases

Structured version-controlled deployments for your Rulebricks rules and flows. Learn how releases separate development from production deployment.

# Releases in Rulebricks

Building business logic is only half the story. The rules and flows you create in Rulebricks represent critical decision-making processes—pricing calculations, eligibility checks, fraud detection, compliance validation—that drive real outcomes in your applications. But between the moment you finish building a rule and the moment it starts serving production traffic, there exists a gap that many teams overlook until it becomes a problem.

Releases in Rulebricks enable structured, version-controlled deployments for your rules and flows.

Rather than having changes take effect the moment you click "publish," Releases creates a deliberate separation between ongoing development work and production deployments.

## The Releases Tab

When you navigate to the Releases tab in your Rulebricks workspace, you encounter a unified view of your deployment landscape. The interface organizes your assets—both rules and flows—into two distinct categories that reflect their current deployment status.

![The Releases tab provides a central view of pending and active releases across your environments](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/releases/releases-tab-entry.png)

At the top of the screen, you can toggle between viewing rules and flows, and filter by environment using the dropdown selector. This environment-centric view is intentional: rather than asking "what state is this rule in?" you ask "what is deployed to staging?" or "what is live in production?" This subtle shift in perspective mirrors how operations teams actually think about deployments.

The interface divides releases into two sections. The Pending section shows releases that have been requested but not yet approved—these represent changes that are in flight, awaiting review before they go live. Below that, the Releases section displays assets that have successfully been released to the selected environment, showing you exactly what version is currently active and when it was deployed.

## Creating and Managing Releases
/releases/creating-and-managing-releases

Learn how to create, approve, and promote releases in Rulebricks. Manage the complete release lifecycle from staging to production.

# Creating and Managing Releases

With environments configured, you can begin the actual work of releasing your business logic. A release in Rulebricks represents a specific version of a rule or flow that has been tagged for deployment to a particular environment. Creating a release does not immediately deploy anything—instead, it opens a request that must be approved before the release becomes active. This two-step process separates the intent to deploy from the actual deployment, creating space for review and validation.

## Starting a New Release

<Steps>

### Open the new release modal

Click the "New Release" button in the Releases tab. The modal that appears guides you through the essential decisions.

![Creating a new release requires selecting an environment, a published asset, and a specific version](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/releases/new-release-modal.png)

### Select your target environment

The environment selection determines where this release will go and, consequently, who needs to approve it. Only environments that allow direct releases appear in this dropdown—if an environment is configured for "promotion only," you cannot create releases directly into it and must instead promote from a lower-level environment.

### Choose your asset and version

The asset selection shows only published rules and flows. This constraint exists because releases target stable, versioned snapshots of your business logic, not work in progress. If the rule or flow you want to release does not appear in the dropdown, return to the Rules or Flows tab and publish it first.

The version selection lets you choose which specific published version to release. This is particularly important when you have made multiple iterations on a rule and want to release a specific checkpoint rather than the latest version.

### Add release notes

The notes field provides an opportunity to document why this release is being created, what changes it contains, or what the approvers should pay attention to during review. These notes become part of the release's permanent record and appear in the activity feed.

</Steps>

## Navigating Releases by Environment

The Releases tab organizes everything by environment because that is how most teams think about deployments. When you select an environment from the dropdown, the view updates to show only releases relevant to that specific deployment target.

![Filtering releases by environment helps you focus on what matters for each deployment target](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/releases/select-release-environment.png)

The pending section shows releases that have been created but not yet approved. Each pending release displays key information: the asset name, the version number, when the release was opened, how many approvals are still needed, and how many comments have been added. This at-a-glance view helps you quickly identify which releases need attention and their current status in the approval workflow.

Below the pending releases, the released section shows assets that have been successfully deployed to this environment. Each entry indicates the version that is currently active and confirms that the release is live. This serves as a source of truth for what is actually running in each environment.

## The Approval Workflow

When you open a pending release, you enter the detailed view where the actual approval workflow takes place. This screen presents all the information approvers need to make an informed decision, along with tools for collaboration and action.

![The release detail view shows approval status, the release asset, and a collaborative activity feed](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/releases/comment-markdown.png)

The header area displays the current approval status—"Pending Approval" for releases still awaiting sign-off, or "Released" for approved deployments. Action buttons allow approvers to approve the release, update the version target if needed, or cancel the release entirely if circumstances have changed.

The approval status panel shows who has approved the release and who is still pending. The scheme indicator reminds everyone whether a single approval is sufficient or if all designated approvers must sign off. As approvals come in, the panel updates in real time, providing clear visibility into how close the release is to going live.

The release asset section shows exactly what is being released—the rule or flow card displays the same information you would see in the Rules or Flows tab, making it easy to review what this release contains without navigating away. You can click through to view the full rule details if needed.

The activity feed on the right captures the complete history of the release: when it was created, who commented, what notes were added, and when approvals were given. Comments support rich formatting and mentions, allowing you to tag specific team members for input or flag concerns that need addressing before approval.

## Promoting Releases

Once a release has been approved in one environment, you may want to advance it to the next stage of your deployment pipeline. Rather than creating a new release from scratch, you can promote the existing release to a higher-level environment. This action preserves the connection between the releases, making it clear that what is running in production came from what was tested in staging.

<Callout type="info">
  The promote action appears on released assets and shows only environments at the next level in your hierarchy. Promotion creates a new release in the target environment that references its origin, providing a clear audit trail of how changes flow through your deployment pipeline.
</Callout>

The promoted release still requires approval according to the target environment's configuration, ensuring that each stage maintains its own governance.

## Notifications and Collaboration
/releases/notifications-and-collaboration

Configure release notifications in Rulebricks via email, Slack, Discord, or webhooks. Keep your team informed about pending approvals and deployments.

# Notifications and Collaboration

A release workflow is only as effective as the team's awareness of it. The best-designed approval process fails if approvers do not know releases are waiting for their attention, or if stakeholders learn about deployments only after something goes wrong. Rulebricks addresses this through configurable notifications that keep your team informed at the moments that matter, without overwhelming them with noise.

## Configuring Notifications for Each Environment

Notification settings are configured per environment, recognizing that different deployment stages warrant different levels of attention. A staging environment might need minimal notifications since changes there are routine, while production releases might warrant immediate alerts across multiple channels.

To configure notifications, open the Release Environments modal and locate the notifications column. Each environment shows a bell icon that indicates whether notifications are enabled. Clicking this icon opens the notification configuration for that specific environment.

![Each environment has its own notification settings, accessible from the environments list](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/releases/setup-release-notifications-1.png)

The notifications button appears alongside other environment properties, making it easy to audit which environments have alerting configured and which do not. This visibility helps ensure that your production environment does not accidentally go unmonitored while less critical environments have elaborate notification setups.

## Choosing What to Notify On

The notification settings screen presents two dimensions of configuration: which events trigger notifications, and which channels receive them. The events tab lets you toggle notifications for each type of release activity, giving you fine-grained control over what your team hears about.

![The events tab allows you to enable or disable notifications for specific release activities](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/releases/release-events.png)

The available events cover the complete release lifecycle:

| Event                      | Description                                                                                                                   |
| -------------------------- | ----------------------------------------------------------------------------------------------------------------------------- |
| **Release Created**        | Fires when someone opens a new release request, alerting approvers that their attention is needed                             |
| **Release Commented**      | Notifies when discussion happens on a release, keeping everyone aware of the conversation                                     |
| **Release Updated**        | Triggers when someone changes the version target of an existing release                                                       |
| **Release Cancelled**      | Notifies when a release is cancelled                                                                                          |
| **Release Approved**       | Notifies when an approver gives their approval                                                                                |
| **Release Fully Approved** | Fires when a release meets all approval requirements and goes live—the moment when API traffic begins serving the new version |

<Callout type="info">
  The "Release Fully Approved" event is distinct from individual approvals. In
  an "all approvers required" environment, individual approvals might not be
  significant on their own, but the final approval that tips the release into
  active status is worth calling out.
</Callout>

The **direct mentions** setting deserves special attention. When enabled, team members who are mentioned in release comments receive email notifications about that specific mention. This creates a lightweight way to pull someone into a discussion without adding them as a formal approver or sending notifications about every release event.

## Notification Channels

The channels tab determines how notifications reach your team. Rulebricks supports multiple delivery mechanisms, and you can enable any combination that fits your workflow.

**Email notifications** go directly to specified addresses. You can add individual recipients or quickly add all environment approvers with a single click. Email works well for ensuring notifications reach people even when they are not monitoring real-time communication tools.

**Slack and Discord integrations** allow notifications to flow into your team's existing communication channels. By providing a webhook URL for your Slack or Discord workspace, release events can post messages directly to a dedicated channel. This keeps release activity visible alongside other team discussions and makes it easy to react quickly without context-switching to the Rulebricks interface.

**Custom webhooks** provide maximum flexibility for teams with existing notification infrastructure or specialized requirements. Any URL that can receive a POST request with release event data can be configured as a notification destination, enabling integration with paging systems, custom dashboards, or internal tools.

<Callout>
  The power of channel configuration lies in combination. A production
  environment might send emails to the on-call engineer, post to a dedicated
  Slack channel for visibility, and trigger a webhook that logs the event to
  your observability platform. The same release event can fan out to multiple
  destinations, ensuring that the right people get informed through the channels
  they actually monitor.
</Callout>

## Release URLs and API Access
/releases/release-urls-and-api-access

Understand the difference between Preview URLs and Release URLs in Rulebricks API. Learn integration patterns for production and staging environments.

# Release URLs and API Access

The practical integration of releases into your applications comes down to URLs. When you call a rule or flow via the Rulebricks API, the URL you use determines which version of the logic gets executed. Understanding the distinction between preview URLs and release URLs is essential for building robust applications that take full advantage of the release system.

## Two Ways to Access Your Rules

Every rule and flow in Rulebricks can be accessed through the API using two different URL patterns. The first pattern uses a version number at the end of the URL, directly targeting a specific published version. The second pattern uses an environment slug, which dynamically resolves to whatever version is currently released in that environment.

When you view a pending release, both URL patterns are displayed together, making the distinction clear.

![A pending release shows both the Preview URL (version-specific) and Release URL (environment-specific)](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/releases/release-url-zoom-in.png)

The **Preview URL** follows the pattern `/api/v1/solve/{rule-slug}/{version-number}`. This URL always returns results from the exact version you specify, regardless of what has been released. It provides a stable, predictable endpoint that never changes behavior unless you explicitly change the version number in the URL. Use this URL for testing specific versions or when you need guaranteed consistency.

The **Release URL** follows the pattern `/api/v1/solve/{rule-slug}/{environment-slug}`. This URL resolves to whatever version is currently active in the specified environment. When you approve a new release, the Release URL automatically starts serving the newly released version without any changes to your application code. This dynamic resolution is what makes releases powerful—your production systems can point to the release URL, and deployments happen by approving releases rather than updating configurations.

## Before and After Approval

The relationship between these URLs and the approval workflow is where releases provide their real value. Before a release is approved, the Release URL still points to the previous released version—or returns an error if nothing has ever been released to that environment. The pending release exists in a preparatory state, visible in the Rulebricks interface but not yet affecting API traffic.

<Callout type="warning">
  Notice the amber warning message beneath the Release URL in a pending release:
  "This endpoint will be active/updated after the release is approved." This
  indicator makes clear that creating a release does not immediately change what
  your API consumers receive.
</Callout>

Once the release is approved, the situation changes. The Release URL now resolves to the newly approved version, and the status indicator turns green.

![After approval, the Release URL actively serves the released version](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/releases/released-url-zoom-in.png)

The green confirmation message—"This endpoint is active and can be used in production"—signals that this version is now live. Any API call to the Release URL will execute this version of the rule. The transition from pending to released happens atomically when the final required approval is given, ensuring there is no ambiguous intermediate state.

## Practical Integration Patterns

Though quite simple, understanding these URL patterns genuinely enables several familiar integration strategies:

**Production systems with controlled updates:** Configure your application to use the Release URL. Your code always calls the same endpoint, and updates happen through the approval workflow rather than code deployments. This separation means you can update business logic without touching your application infrastructure.

**Staging and testing environments:** Use the Preview URL to pin to a specific version while you validate behavior. This ensures your tests run against known logic even if someone approves a new release while your test suite is executing.

**Multi-environment applications:** Some teams use different Release URLs for different parts of their application. A customer-facing pricing service might call the production Release URL, while an internal analytics pipeline calls the staging Release URL. Both are calling the same rule, but they receive different versions based on what has been released to each environment.

**Emergency rollback:** The version-specific Preview URL also serves as a safety mechanism. If something goes wrong with a newly released version, you can temporarily point critical systems to the Preview URL of the previous version while you investigate. This provides an immediate escape hatch that does not require rushing through a new release approval.

<Callout type="info">
  Whichever pattern you choose, the key insight is that Rulebricks gives you
  control over the relationship between your API calls and the particular
  logic/version of decision assets that get executed. Releases are merely a
  mechanism for managing that relationship in a deliberate, auditable way.
</Callout>

## Setting Up Environments
/releases/setting-up-environments

Configure release environments in Rulebricks to define deployment targets, approval workflows, and promotion hierarchies for your rules and flows.

# Setting Up Environments

Before you can begin releasing rules and flows, you need to define the environments through which your changes will travel. An environment in Rulebricks represents a deployment target—a conceptual space like "staging" or "production" where a particular version of your business logic will run. The configuration of these environments determines not just where releases can go, but how they get there and who has the authority to approve them.

The design of your environment structure should reflect your organization's actual deployment practices. A small team might operate with a simple two-environment setup: a staging environment for testing and a production environment for live traffic. Larger organizations often require more nuanced hierarchies, perhaps with multiple staging environments for different testing purposes, or regional production environments that receive releases at different times.

## Creating Your First Environment

To configure environments, click the "Release Environments" button in the Releases tab. This opens a modal where you can view existing environments and create new ones. The environment list displays key information at a glance: the environment name, its level in the promotion hierarchy, the number of designated approvers, the approval scheme, and whether notifications are configured.

![The environments modal displays all configured environments with their levels, approvers, and approval schemes](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/releases/new-environment-modal.png)

When creating or editing an environment, you define several critical properties. The environment name serves as its identifier throughout the system—choose something meaningful like "Staging" or "Production EU" rather than cryptic abbreviations. The description field allows you to document the environment's purpose and its place in your release workflow, which proves invaluable when onboarding new team members or auditing your processes months later.

## Understanding Environment Levels

The level setting deserves particular attention because it governs the promotion path for your releases. Environments with lower level numbers are considered earlier in the release pipeline, and releases can only be promoted from a lower level to the next higher level. This constraint is intentional: it prevents releases from skipping stages in your workflow, ensuring that every change passes through the appropriate validation steps before reaching production.

![Environment configuration showing level settings and approver selection](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/releases/environment-levels-important.png)

Consider a typical three-environment setup. Your staging environment might be level 1, a pre-production environment level 2, and production level 3. A release created in staging cannot jump directly to production—it must first be promoted to pre-production, approved there, and only then can it advance to production. This sequential progression creates natural checkpoints where your team can validate changes before they move closer to live traffic.

You can also have multiple environments at the same level. This is useful when you have parallel deployment targets, such as regional production environments or multiple staging environments for different feature teams. Releases from a lower-level environment can be promoted to any environment at the next level, giving you flexibility while maintaining the overall progression structure.

## Configuring Approvers and Approval Schemes

Each environment requires at least one approver—a team member authorized to approve releases into that environment. The approvers you designate should align with who has responsibility for changes reaching that stage of deployment. Your staging environment might allow any developer to approve releases, while production might require sign-off from a senior engineer or technical lead.

The approval scheme determines how many approvers must give their consent before a release goes live. With the "Any approver" scheme, a single approval from any designated approver is sufficient. The "All approvers" scheme requires every designated approver to provide explicit approval. Choose based on the risk profile of each environment: staging might use "any approver" for agility, while production might require consensus from all approvers for safety.

<Callout type="warning">
  The approval scheme and the release creation settings are locked after an environment is created. This design prevents accidental or untracked changes to your approval criteria after releases have begun flowing through the system. If you need to change these settings, you would need to create a new environment with the desired configuration. Plan your environment structure thoughtfully before committing to it.
</Callout>

## Service Level Agreement
/security/service-level-agreement

Rulebricks offers a common SLA with varying minimum response and resolution times for two levels of issues– low, and high severity. Learn more about this agreement here.

## Basic SLA

Rulebricks offers a common SLA with varying minimum response and resolution times for two levels of issues: low, and high severity.

We define "high severity" issues as bugs/errors that prevent the development and correct execution of rule or flow assets on our platform, directly impeding your team from gaining value from our software.

<Callout type="info" emoji="🚥">
  Please note the response and resolution times provided below are maximums, and
  you can often expect faster progress, particularly during business hours
  within **Pacific Standard Time**.
</Callout>

#### **Low Severity**

- 48 hour maximum response time
- 10 day resolution time

#### **High Severity**

- 24 hour maximum response time
- 3 day resolution time

If Rulebricks breaks the SLA in two consecutive months or over three months in any 12-month period, then Customer may, as its only remedy, terminate this Order Form upon notice and receive a prorated refund of prepaid fees for the remainder of the Subscription Period.

## High SLA

Our High SLA is available to customers of our Embedded (Enterprise) plans and offers response & resolution times at the extremes of what we are able to support, including 24/7 direct on-call lines, 4-8 hour response times, and significant service credits for violations.

Rule engines require a great degree of trust & vendor responsibility. Our High SLA is our word that- should anything go wrong– we'll be online.

---

We have a CommonPaper (https://commonpaper.com/) Cloud Services Agreement template for Rulebricks containing what you see on this page you may request access to for closer review should you wish to move forward.

## Rulebricks Subprocessors
/security/subprocessor-list

Rulebricks subprocessors are third-party services that Rulebricks uses to provide its core functionality. Learn more about them here.

# Rulebricks Subprocessors

| Subprocessor | Technology             | Description                                                                                                                                                                                                                 | Website                          |
| ------------ | ---------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------- |
| Vercel (AWS) | Hosting & Edge Caching | Provides cloud hosting and edge caching services. Vercel is used for hosting the Next.js application, which includes React and Node.js environments. They also manage the Edge Cache to enhance content delivery speeds.    | [Vercel](https://vercel.com)     |
| Supabase     | Cloud Database         | Acts as a backend service. Supabase offers a PostgreSQL database service, authentication, real-time subscriptions, and storage capabilities. It is used to manage and store all the application data in the cloud securely. | [Supabase](https://supabase.com) |
| Upstash      | Redis Cache            | Provides managed Redis services. Upstash is used for caching frequently accessed data to reduce latency and improve the performance of database operations.                                                                 | [Upstash](https://upstash.com)   |

## Details

- **Next.js**: A React framework that enables server-side rendering and static site generation, which is hosted on Vercel. _Region – Vercel – IAD1 (Washington, D.C.)_
- **Node 22**: Handles all server-side logic.
- **Vercel Edge Cache**: Utilizes Vercel's global network to cache and serve static and dynamic content at the edge, closest to the users, for faster performance.
- **Supabase (Cloud)**: A cloud-hosted backend-as-a-service that provides not only database solutions but also handles authentication and real-time data functionality. _Region – Supabase – US East (N. Virginia)_
- **Redis (Upstash)**: Rulebricks uses Upstash to manage user rate limits, and temporarily store compressed asset data for increased API performance.

## System Architecture
/security/system-architecture

Rulebricks' system architecture is built on JS, Postgres, and Redis. Our cloud infrastructure is hosted on Vercel, Supabase, and Upstash. Learn more about our technology stack here.

## Technology Overview

Rulebricks is built using Next JS, Postgres, and Redis, **all of which can be run on your own infrastructure via Kubernetes** if you choose to deploy Rulebricks privately.

Our cloud infrastructure is respectively hosted on Vercel, Supabase, and Upstash. You can find more information about our subprocessors [here](/security/subprocessor-list), including the technology they provide, and the regions we operate over them in.

All cloud data is backed up every few hours and retained for 30 days.

For our AI features, we use OpenAI. We do not store any data with OpenAI, and only send data to them when you explicitly take an AI action in the Rulebricks interface.

### Private Hosting

All private deployments are HTTPS and require certification, _provided DNS records are updated immediately after deployment._

Currently we support terraform based deployment AWS and GCP, with Azure support coming soon.

All private deployments use Helm charts to spin up and run occasional upgrades against the requisite services. We publish upgrades to our application quite often (2-3 times a day), and you can choose to upgrade your private deployment at your convenience, or opt into notifications about major upgrades we recommend you apply.

Most third party services are disabled or re-configured in private deployments, particularly certain logging, user analytics, and AI features.

## Terms Of Service
/security/terms-of-service

Rulebricks' Terms of Service, including our Privacy Policy and other legal information.

## Legal Information

You can find our Terms of Service on our website [here](https://www.rulebricks.com/legal/terms-of-service), along with our Privacy Policy [here](https://www.rulebricks.com/legal/privacy-policy).

Signing up for Rulebricks means you agree to these terms, so do read them before you get started.

## Video Introduction
/video-introduction

A brief video overview of Rulebricks to get you started building and using rules right away.

### A Brief Overview

There're a lot of pages here. Don't want to read through all of them? Here's a short video to give you a bird's eye view of our platform to get you started working with Rulebricks right away.

<Callout type="info" emoji="">
  You can also find this video at any time within Rulebricks by clicking the
  Question Mark icon in the top right corner of the rule editor.
</Callout>

<div
  style={{
    position: 'relative',
    paddingBottom: '62.5%',
    marginTop: '2rem',
    height: 0,
  }}
>
  <iframe
    src="https://www.loom.com/embed/f9f3371774894fc9a5393a932d804e7a?sid=dea2534d-5423-4f01-919c-1ae415f991aa"
    frameBorder="0"
    allowFullScreen
    className="overview-video"
    style={{
      position: 'absolute',
      top: 0,
      left: 0,
      width: '100%',
      height: '100%',
      borderRadius: '4px',
    }}
  ></iframe>
</div>

## Rule Warnings
/warnings

Rulebricks automatically analyzes your decision tables and warns you about potential issues before they cause problems in production.

# Rule Warnings

Rulebricks analyzes your decision tables and warns you about structural issues—rows that can never be reached, conditions that shadow later rows, gaps where inputs might fall through.

Warning detection is fairly powerful and can identify situations where conditions are structured in ways that overlap in strange and ambiguous ways, encouraging rule developers to write clearer rules.

![Warning Detection](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/warnings/warning-detection.png)

Warnings appear in the rule editor footer. Click to see details and jump to the affected rows.

<Callout type="info">
  Warnings use **static analysis**—they examine your rule structure without
  needing production data. For runtime analysis based on actual traffic, use
  [Analysis Tools](/analysis-tools).
</Callout>

## Severity Levels

**Error (Red)** — Definite problems that will cause incorrect behavior. Unreachable rows, catch-alls blocking everything below them. Fix these before publishing.

**Warning (Yellow)** — Likely issues that deserve attention. Partial overlaps, coverage gaps, unhandled boundary values. Review to ensure the behavior is intentional.

**Info (Blue)** — Informational notices. Missing catch-all row, incomplete coverage suggestions. Consider whether these apply to your use case.

## Common Issues

**Catch-All Blocking:** A row with "any" for all conditions matches everything, blocking all rows below it. Move catch-alls to the bottom.

**Unreachable Rows:** Every input that would match a row is already caught by an earlier row. Reorder so more specific conditions come first.

**Coverage Gaps:** A range of values won't match any row. Add handling for the missing range, or verify your catch-all covers it.

See **[Warning Types](/warnings/warning-types)** for detailed explanations and fixes for each warning.

## Warning Types
/warnings/warning-types

Detailed explanations of each warning type in Rulebricks, including what causes them and how to fix them.

# Warning Types

## Errors

### Catch-All Blocking

**Message:** "Row X is a catch-all. Rows Y, Z will never be reached."

A row with "any" for all conditions matches everything, blocking all rows below it.

```
Row 1: If tier = "gold" → Discount 20%
Row 2: If any → Discount 0%  ← Catch-all
Row 3: If tier = "platinum" → Discount 30%  ← Never reached!
```

**Fix:** Move the catch-all to the bottom.

```
Row 1: If tier = "gold" → Discount 20%
Row 2: If tier = "platinum" → Discount 30%
Row 3: If any → Discount 0%  ← Now at the bottom
```

### Unreachable Row

**Message:** "Row X is unreachable because it is fully covered by Row Y."

Every input that would match Row X is already caught by an earlier row.

```
Row 1: If score >= 700 → Approved
Row 2: If score >= 750 → Premium  ← Unreachable!
```

Any score >= 750 also satisfies >= 700, so Row 1 catches it first.

**Fix:** Reorder so the more specific condition comes first:

```
Row 1: If score >= 750 → Premium
Row 2: If score >= 700 → Approved
```

## Warnings

### Partial Overlap

**Message:** "Row X partially overlaps with Row Y."

Some inputs match both rows, but not all. The earlier row wins for the overlap.

```
Row 1: If tier = "gold" AND score > 600 → Plan A
Row 2: If score > 700 → Plan B
```

A gold-tier customer with score 750 matches both, but gets Plan A.

**Fix:** If unintentional, make conditions mutually exclusive. If intentional, document why and ignore the warning.

<Callout>
  Partial overlaps aren't always bugs—sometimes you want earlier rows to take
  precedence.
</Callout>

### Coverage Gap

**Message:** "Column 'X' has a coverage gap: values in [a, b] have no explicit handling."

There's a range of values that won't match any row.

```
Row 1: If age < 18 → Minor rate
Row 2: If age > 65 → Senior rate
← Gap: Ages 18-65 have no explicit handling
```

**Fix:** Add a row for the missing range, or verify your catch-all handles it correctly.

### Boundary Gap

**Message:** "Exact value X = 100 has no explicit handling."

Adjacent conditions leave a specific value unhandled.

```
Row 1: If score < 100 → Fail
Row 2: If score > 100 → Pass
← Gap: Exactly 100 falls through!
```

**Fix:** Use inclusive operators:

```
Row 1: If score < 100 → Fail
Row 2: If score >= 100 → Pass
```

## Info

### Incomplete Coverage

**Message:** "No catch-all row exists. Some inputs may not match any row."

Without a catch-all, unmatched inputs return an error.

**Fix:** Add a final row with "any" for all conditions if you want a default result. Leave it out if you want unhandled cases to error.

<Callout>
  This is informational—intentionally omitting a catch-all is valid when you
  want unhandled cases flagged as errors.
</Callout>

---

<Callout type="error">
  It is important to note that warnings aren't always available. Warnings don't
  appear when your rule uses row groups with priorities, individual row
  priorities, or OR rows. These features change evaluation semantics in ways
  static analysis can't predict—use [Reachability
  Analysis](/analysis-tools/reachability-analysis) for runtime validation
  instead.
</Callout>

## Assigning Roles
/workspace-management/assigning-roles

Control workspace access with system roles and custom roles with fine-grained permissions.

# Assigning Roles

Roles control what users can access and modify. Assign them from the **Team** tab by clicking the pencil icon next to any user's current role.

![Assigning Roles](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/roles/assigning-roles.png)

## System Roles

**Developer** — Full access to rules, flows, API keys, logs, Dynamic Values, and settings. Cannot edit team membership or billing.

**Editor** — Can view and edit existing rules. Cannot create/delete rules, access API keys, logs, flows, or settings.

**Administrator** — Complete control including team management and billing. Reserved for the workspace owner.

## Custom Roles

For granular control, create custom roles with exactly the permissions you need.

<Steps>

### Create the role

Go to **Team → Roles** and click **Create Custom Role**.

![Create Custom Roles](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/roles/create-custom-roles.png)

### Configure permissions

Select which capabilities this role should have:

![Fine-Grained Permissions](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/roles/fine-grained.png)

**Rules & Flows** — View, edit, create, delete, publish

**Data & Settings** — API keys, logs, Dynamic Values, settings

**Team** — View members, invite members, manage roles

### Save

Name it descriptively and save.

</Steps>

<Callout type="info">
  Custom roles combine with [User
  Groups](/workspace-management/creating-tenants) for precise scoping– roles
  control what Rulebricks functionality they can use, and user groups control
  what data they see.
</Callout>

## User Groups
/workspace-management/creating-tenants

Partition your workspace into isolated User Groups for different teams, clients, or projects.

# User Groups

User Groups partition your workspace into isolated sections. Users only see rules and flows in their assigned groups—useful for multi-team organizations, client isolation, or separating environments.

![Team Tenants Tab](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/creating-tenants/team-tenants-tab.png)

<Steps>

### Create a group

Go to **Team → User Groups** and click **Create User Group**. Give it a name and description.

### Assign users

Add users to the group. Users can belong to multiple groups. Their [role permissions](/workspace-management/assigning-roles) apply within their group scope.

</Steps>

Administrators & Developers, by default, see all groups and data within. Everyone else sees only their assigned groups, and data explicitly assigned to that group.

<Callout type="info">
  User Groups are unlimited on all plans—create as many as you need at no
  additional cost.
</Callout>

## Managing Subscriptions
/workspace-management/customer-portal

Manage your Rulebricks subscription, payment information, and billing from the customer portal.

# Managing Subscriptions

<Steps>

### Open account menu

Click **Account** in the top right corner of the dashboard.

![Account Tab](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/workspace-management/workspace-customer-portal-account.png)

### Open billing

Click the **Billing** tab to launch the customer portal (powered by Stripe). From here you can update payment info, view invoices, and change your plan.

![Billing Tab](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/workspace-management/workspace-launch-portal.png)

</Steps>

If you don't have an active subscription, you'll be redirected to the pricing page instead.

## Inviting Collaborators
/workspace-management/inviting-collaborators

Invite team members to your Rulebricks workspace and manage their access levels.

# Inviting Collaborators

Navigate to the **Team** tab to see your current team members and invite new ones.

![View Team](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/inviting-collaborators/view-team.png)

<Steps>

### Click Invite

Click the **Invite** button to open the invitation dialog.

![Invite Modal](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/revisions/inviting-collaborators/invite-modal.png)

### Enter email and select role

Enter their email address and choose a role:

- **Developer** — Full access to rules, flows, API keys, logs, and settings
- **Editor** — Can view and edit existing rules only

### Send invitation

They'll receive an email with instructions to join. Once accepted, they appear in your team list and can immediately access your workspace.

</Steps>

<Callout type="info">
For more granular control, create [custom roles](/workspace-management/assigning-roles) with specific permissions.
</Callout>

Collaborators cannot edit team membership, view billing, or remove the workspace owner—those are admin-only.

## Updating Your Account
/workspace-management/updating-your-account

Update your email, password, and team name from the Account tab.

# Updating Your Account

<Steps>

### Open account menu

Click **Account** in the top right corner of the dashboard.

![Account Tab](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/workspace-management/workspace-customer-portal-account.png)

### Edit your info

Update your email address, password, or team name.

![Account Info](https://d1zic6dm9txw4h.cloudfront.net/rulebricks-docs-assets/static/images/workspace-management/updating-account-info.png)

</Steps>

